// #define DEBUG 1
{#
NeuronClass.jinja2

This file is part of NEST.

Copyright (C) 2004 The NEST Initiative

NEST is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 2 of the License, or
(at your option) any later version.

NEST is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with NEST.  If not, see <http://www.gnu.org/licenses/>.
#}
{%- import 'directives_cpp/BufferInitialization.jinja2' as buffer_initialization with context %}
{%- import 'directives_cpp/FunctionDeclaration.jinja2' as function_declaration with context %}
{%- import 'directives_cpp/VectorSizeParameter.jinja2' as vector_size_parameter with context %}
{%- import 'directives_cpp/RportToBufferIndexEntry.jinja2' as rport_to_port_map_entry with context %}

{%- if tracing %}/* generated by {{self._TemplateReference__context.name}} */{% endif -%}
/*
 *  {{neuronName}}.cpp
 *
 *  This file is part of NEST.
 *
 *  Copyright (C) 2004 The NEST Initiative
 *
 *  NEST is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 2 of the License, or
 *  (at your option) any later version.
 *
 *  NEST is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with NEST.  If not, see <http://www.gnu.org/licenses/>.
 *
 *  Generated from NESTML at time: {{now}}
**/

// C++ includes:
#include <limits>

// Includes from libnestutil:
#include "numerics.h"

// Includes from nestkernel:
#include "exceptions.h"
#include "kernel_manager.h"
#include "nest_impl.h"
#include "universal_data_logger_impl.h"

// Includes from sli:
#include "dict.h"
#include "dictutils.h"
#include "doubledatum.h"
#include "integerdatum.h"
#include "lockptrdatum.h"

#include "{{neuronName}}.h"

{%- if not (nest_version.startswith("v2") or nest_version.startswith("v3.0") or nest_version.startswith("v3.1") or nest_version.startswith("v3.2")
        or nest_version.startswith("v3.3") or nest_version.startswith("v3.4") or nest_version.startswith("v3.5") or nest_version.startswith("v3.6")) %}
void
register_{{ neuronName }}( const std::string& name )
{
  nest::register_node_model< {{ neuronName }} >( name );
}
{%- endif %}

// ---------------------------------------------------------------------------
//   Recordables map
// ---------------------------------------------------------------------------
{%- if not has_state_vectors %}
nest::RecordablesMap<{{neuronName}}> {{neuronName}}::recordablesMap_;
{%- endif %}
namespace nest
{

  // Override the create() method with one call to RecordablesMap::insert_()
  // for each quantity to be recorded.
{%- if has_state_vectors %}
template <> void DynamicRecordablesMap<{{neuronName}}>::create({{neuronName}}& host)
{%- else %}
template <> void RecordablesMap<{{neuronName}}>::create()
{%- endif %}
  {

{%- if recordable_state_variables|length > 0 %}
{%- if has_state_vectors %}
{%-   for variable in recordable_state_variables %}
{%-     if not variable.has_vector_parameter() %}
    insert("{{variable.get_complete_name()}}", host.get_data_access_functor( {{neuronName}}::State_::{{ printer_no_origin.print(utils.get_state_variable_by_name(astnode, variable.get_complete_name())).upper() }} ));
{%-     endif %}
{%-   endfor %}
{%- else %}
    // add state variables to recordables map
{%-   for variable in recordable_state_variables %}
   insert_({{names_namespace}}::_{{ variable.get_complete_name() }}, &{{ neuronName }}::get_{{ printer_no_origin.print(variable) }});
{%-   endfor %}
{%- endif %}
{%- endif %}

{%- if recordable_inline_expressions|length > 0 %}
    // add recordable inline expressions to recordables map
{%- for variable_symbol in recordable_inline_expressions %}
{%-     set variable = utils.get_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
	insert_({{ names_namespace }}::_{{ variable_symbol.get_symbol_name() }}, &{{ neuronName }}::{{ printer_no_origin.print(variable)[:-2] }});
{%- endfor %}
{%- endif %}

    // Add vector variables
{%- filter indent(2,True) %}
{%- if has_state_vectors %}
    host.insert_recordables();
{%- endif %}
{%- endfilter %}
  }
}

{%- if neuron.get_spike_input_ports()|length > 1 or neuron.is_multisynapse_spikes() %}
std::vector< std::tuple< int, int > > {{neuronName}}::rport_to_nestml_buffer_idx =
{
{%-   for key, ports in utils.get_spike_input_ports_in_pairs(neuron).items() %}
{%-   set ns = namespace(rport=key) %}
{%-     if ports[0].has_vector_parameter() %}
{%-     set size = utils.get_numeric_vector_size(ports[0]) %}
{%-         for i in range(size) %}
  {{ rport_to_port_map_entry.RportToBufferIndexEntry(ports, ns.rport, index=i+1) }}
{%-         set ns.rport = ns.rport + 1 %}
{%-         endfor %}
{%-     else %}
  {{ rport_to_port_map_entry.RportToBufferIndexEntry(ports, ns.rport) }}
{%-     endif %}
{%-   endfor %}
};
{%- endif %}

{%- if has_state_vectors %}
  std::string {{neuronName}}::get_var_name(size_t elem, std::string var_name)
  {
    std::stringstream n;
    n << var_name << elem + 1;
    return n.str();
  }

  void {{neuronName}}::insert_recordables(size_t first)
  {
{%- for variable in neuron.get_vector_state_symbols() %}
{%-   set node = utils.get_state_variable_by_name(astnode, variable.get_symbol_name()) %}
      for (size_t i = 0; i < {{vector_size_parameter.VectorSizeParameter(variable, true)}}; i++)
      {
        size_t elem = {{neuronName}}::State_::{{ printer_no_origin.print(node).upper() }} + i;
        recordablesMap_.insert(get_var_name(i, "{{ printer_no_origin.print(node).upper() }}_"), this->get_data_access_functor(elem));
      }
{%- endfor %}
  }

  nest::DataAccessFunctor< {{neuronName}} >
  {{neuronName}}::get_data_access_functor( size_t elem )
  {
    return nest::DataAccessFunctor< {{neuronName}} >( *this, elem );
  }
{%- endif %}

// ---------------------------------------------------------------------------
//   Default constructors defining default parameters and state
//   Note: the implementation is empty. The initialization is of variables
//   is a part of {{neuronName}}'s constructor.
// ---------------------------------------------------------------------------

{{neuronName}}::Parameters_::Parameters_()
{
}

{{neuronName}}::State_::State_()
{
}

// ---------------------------------------------------------------------------
//   Parameter and state extractions and manipulation functions
// ---------------------------------------------------------------------------

{{neuronName}}::Buffers_::Buffers_({{neuronName}} &n):
  logger_(n)
{%- if neuron.get_spike_input_ports()|length > 0 %}
  , spike_inputs_( std::vector< nest::RingBuffer >( NUM_SPIKE_RECEPTORS ) )
  , spike_inputs_grid_sum_( std::vector< double >( NUM_SPIKE_RECEPTORS ) )
{%- endif %}
{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}
  , __s( nullptr ), __c( nullptr ), __e( nullptr )
{%-     endif %}
{%- endif %}
{
  // Initialization of the remaining members is deferred to init_buffers_().
}

{{neuronName}}::Buffers_::Buffers_(const Buffers_ &, {{neuronName}} &n):
  logger_(n)
{%- if neuron.get_spike_input_ports()|length > 0 %}
  , spike_inputs_( std::vector< nest::RingBuffer >( NUM_SPIKE_RECEPTORS ) )
  , spike_inputs_grid_sum_( std::vector< double >( NUM_SPIKE_RECEPTORS ) )
{%- endif %}
{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}
  , __s( nullptr ), __c( nullptr ), __e( nullptr )
{%-     endif %}
{%- endif %}
{
  // Initialization of the remaining members is deferred to init_buffers_().
}

// ---------------------------------------------------------------------------
//   Default constructor for node
// ---------------------------------------------------------------------------

{{neuronName}}::{{neuronName}}():{{neuron_parent_class}}(), P_(), S_(), B_(*this)
{
  init_state_internal_();

{%- if has_state_vectors %}
  recordablesMap_.create(*this);
{%- else %}
  recordablesMap_.create();
{%- endif %}

{%- if nest_version.startswith("v2") or nest_version.startswith("v3.0") or nest_version.startswith("v3.1") or nest_version.startswith("v3.2") or nest_version.startswith("v3.3") %}
  calibrate();
{%- else %}
  pre_run_hook();
{%- endif %}
}

// ---------------------------------------------------------------------------
//   Copy constructor for node
// ---------------------------------------------------------------------------

{{neuronName}}::{{neuronName}}(const {{neuronName}}& __n):
  {{neuron_parent_class}}(), P_(__n.P_), S_(__n.S_), B_(__n.B_, *this) {

  // copy parameter struct P_
{%- for parameter in neuron.get_parameter_symbols() %}
{%-   set node = utils.get_parameter_variable_by_name(astnode, parameter.get_symbol_name()) %}
  P_.{{ printer_no_origin.print(node) }} = __n.P_.{{ printer_no_origin.print(node) }};
{%- endfor %}

  // copy state struct S_
{%- for init in neuron.get_state_symbols() %}
{%-   if not is_delta_kernel(neuron.get_kernel_by_name(init.name)) %}
{%-   set node = utils.get_state_variable_by_name(astnode, init.get_symbol_name()) %}
  {{ nest_codegen_utils.print_symbol_origin(init, node) % printer_no_origin.print(node) }} = __n.{{ nest_codegen_utils.print_symbol_origin(init, node) % printer_no_origin.print(node) }};
{%-   endif %}
{%- endfor %}

  // copy internals V_
{%- for internal in neuron.get_internal_symbols() %}
{%-   set node = utils.get_internal_variable_by_name(astnode, internal.get_symbol_name()) %}
  V_.{{ printer_no_origin.print(node) }} = __n.V_.{{ printer_no_origin.print(node) }};
{%- endfor %}

{%- if has_state_vectors %}
  recordablesMap_.create(*this);
{%- endif %}
{%- if paired_synapse is defined %}
  n_incoming_ = __n.n_incoming_;
  max_delay_ = __n.max_delay_;
  last_spike_ = __n.last_spike_;

  // cache initial values
{%- for var_name in transferred_variables %}
{%-     set var = utils.get_variable_by_name(astnode, var_name) %}
{%-     set variable_symbol = transferred_variables_syms[var_name] %}
{%-     if not var_name == variable_symbol.get_symbol_name() %}
{{ raise('Error in resolving variable to symbol') }}
{%-     endif %}
  {{var_name}}__iv = {{printer.print(var)}};
{%- endfor %}
{%- endif %}
}

// ---------------------------------------------------------------------------
//   Destructor for node
// ---------------------------------------------------------------------------

{{neuronName}}::~{{neuronName}}()
{
{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}
  // GSL structs may not have been allocated, so we need to protect destruction

  if (B_.__s)
  {
    gsl_odeiv_step_free( B_.__s );
  }

  if (B_.__c)
  {
    gsl_odeiv_control_free( B_.__c );
  }

  if (B_.__e)
  {
    gsl_odeiv_evolve_free( B_.__e );
  }
{%-     endif %}
{%- endif %}
}

// ---------------------------------------------------------------------------
//   Node initialization functions
// ---------------------------------------------------------------------------

{%- if nest_version.startswith("v2") %}
void {{neuronName}}::init_state_(const Node& proto)
{
  const {{neuronName}}& pr = downcast<{{neuronName}}>(proto);
  S_ = pr.S_;
}
{%- endif %}

{%- if not nest_version.startswith("v2") %}
void {{neuronName}}::calibrate_time( const nest::TimeConverter& tc )
{
  LOG( nest::M_WARNING,
    "{{neuronName}}",
    "Simulation resolution has changed. Internal state and parameters of the model have been reset!" );

  init_state_internal_();
}

{%- endif %}
void {{neuronName}}::init_state_internal_()
{
#ifdef DEBUG
  std::cout << "{{neuronName}}::init_state_internal_()" << std::endl;
#endif

  const double __resolution = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the resolution() function

{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}

  // use a default "good enough" value for the absolute error. It can be adjusted via `node.set()`
  P_.__gsl_error_tol = 1e-3;
{%-     endif %}
{%- endif %}

{%- if parameter_vars_with_iv|length > 0 %}
  // initial values for parameters
{%- filter indent(2) %}
{%- for variable in parameter_vars_with_iv %}
{%-     set variable_symbol = variable.get_scope().resolve_to_symbol(variable.get_complete_name(), SymbolKind.VARIABLE) %}
{%-     include "directives_cpp/MemberInitialization.jinja2" %}
{%- endfor %}
{%- endfilter %}
{%- endif %}

  recompute_internal_variables();

{%- if neuron.get_state_symbols()|length > 0 %}
  // initial values for state variables
{%- filter indent(2) %}
{%- for variable_symbol in neuron.get_state_symbols() %}
{%-     set variable = utils.get_state_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     include "directives_cpp/MemberInitialization.jinja2" %}
{%- endfor %}
{%- endfilter %}
{%- endif %}


{%- if paired_synapse is defined %}
  // state variables for archiving state for paired synapse
  n_incoming_ = 0;
  max_delay_ = 0;
  last_spike_ = -1.;

  // cache initial values
{%- for var_name in transferred_variables %}
{%-     set var = utils.get_variable_by_name(astnode, var_name) %}
{%-     set variable_symbol = transferred_variables_syms[var_name] %}
{%-     if not var_name == variable_symbol.get_symbol_name() %}
{{ raise('Error in resolving variable to symbol') }}
{%-     endif %}
  {{var_name}}__iv = {{printer.print(var)}};
{%- endfor %}
{%- endif %}
}

void {{neuronName}}::init_buffers_()
{
#ifdef DEBUG
  std::cout << "{{neuronName}}::init_buffers_()" << std::endl;
#endif

{%- if use_gap_junctions %}
  // resize interpolation_coefficients depending on interpolation order
  const size_t buffer_size =
    nest::kernel().connection_manager.get_min_delay() * ( nest::kernel().simulation_manager.get_wfr_interpolation_order() + 1 );

  B_.interpolation_coefficients.resize( buffer_size, 0.0 );

  B_.last_y_values.resize( nest::kernel().connection_manager.get_min_delay(), 0.0 );

  B_.sumj_g_ij_ = 0.0;
{%- endif %}

{%- if neuron.get_spike_input_ports() | length > 0 %}
  // spike input buffers
  get_spike_inputs_().clear();
  get_spike_inputs_grid_sum_().clear();
{%- endif %}
{%- if neuron.get_continuous_input_ports() | length > 0 %}

  // continuous time input buffers
{%-   filter indent(2,True) %}
{%-     for inputPort in neuron.get_continuous_input_ports() %}
{{ buffer_initialization.BufferInitialization(inputPort) }}
{%-     endfor %}
{%-   endfilter %}
{%- endif %}

  B_.logger_.reset();

{% if has_delay_variables %}

  // Initialize helper variables for delay-based variables
{%-   for variable in neuron.get_state_symbols() %}
{%-     if variable.has_delay_parameter() %}
{%-       include "directives_cpp/DelayVariablesInitialization.jinja2" %}
{%-     endif %}
{%-   endfor %}
{%- endif %}
{%- if paired_neuron is defined %}

  clear_history();
{%- endif %}
{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}

  if ( not B_.__s )
  {
    B_.__s = gsl_odeiv_step_alloc( gsl_odeiv_step_rkf45, State_::STATE_VEC_SIZE );
  }
  else
  {
    gsl_odeiv_step_reset( B_.__s );
  }

  if ( not B_.__c )
  {
    B_.__c = gsl_odeiv_control_y_new( P_.__gsl_error_tol, 0.0 );
  }
  else
  {
    gsl_odeiv_control_init( B_.__c, P_.__gsl_error_tol, 0.0, 1.0, 0.0 );
  }

  if ( not B_.__e )
  {
    B_.__e = gsl_odeiv_evolve_alloc( State_::STATE_VEC_SIZE );
  }
  else
  {
    gsl_odeiv_evolve_reset( B_.__e );
  }

  B_.__sys.function = {{neuronName}}_dynamics;
  B_.__sys.jacobian = nullptr;
  B_.__sys.dimension = State_::STATE_VEC_SIZE;
  B_.__sys.params = reinterpret_cast< void* >( this );
  B_.__step = nest::Time::get_resolution().get_ms();
  B_.__integration_step = nest::Time::get_resolution().get_ms();
{%-     endif %}
{%- endif %}
}

void {{neuronName}}::recompute_internal_variables(bool exclude_timestep) {
  const double __resolution = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the resolution() function

  if (exclude_timestep) {
{%- filter indent(4,True) %}
{%- for internals_block in neuron.get_internals_blocks() %}
{%-     for decl in internals_block.get_declarations() %}
{%-         for variable in decl.get_variables() %}
{%-             if variable.get_complete_name() != "__h" %}
{%-                 set variable_symbol = variable.get_scope().resolve_to_symbol(variable.get_complete_name(), SymbolKind.VARIABLE) %}
{%-                 include "directives_cpp/MemberInitialization.jinja2" %}
{%-             endif %}
{%-         endfor %}
{%-     endfor %}
{%- endfor %}
{%- endfilter %}
  }
  else {
{%- filter indent(4,True) %}
{%- for internals_block in neuron.get_internals_blocks() %}
{%-     for decl in internals_block.get_declarations() %}
{%-         for variable in decl.get_variables() %}
{%-             set variable_symbol = variable.get_scope().resolve_to_symbol(variable.get_complete_name(), SymbolKind.VARIABLE) %}
{%-             include "directives_cpp/MemberInitialization.jinja2" %}
{%-         endfor %}
{%-     endfor %}
{%- endfor %}
{%- endfilter %}
  }
}

{%- if nest_version.startswith("v2") or nest_version.startswith("v3.0") or nest_version.startswith("v3.1") or nest_version.startswith("v3.2") or nest_version.startswith("v3.3") %}
void {{neuronName}}::calibrate() {
{%- else %}
void {{neuronName}}::pre_run_hook() {
{%- endif %}
  B_.logger_.init();

  // parameters might have changed -- recompute internals
  recompute_internal_variables();

  // buffers B_
{%- if ((neuron.get_spike_input_ports())|length > 0) %}
  B_.spike_inputs_.resize(NUM_SPIKE_RECEPTORS);
  B_.spike_inputs_grid_sum_.resize(NUM_SPIKE_RECEPTORS);
{%-   endif %}
}
{%- if neuron.get_functions()|length > 0 %}

// ---------------------------------------------------------------------------
//   Functions defined in the NESTML model
// ---------------------------------------------------------------------------

{%- for function in neuron.get_functions() %}
{{ function_declaration.FunctionDeclaration(function, neuronName + "::") }}
{
{%-   filter indent(2,True) %}
{%-   with ast = function.get_block() %}
{%-     include "directives_cpp/Block.jinja2" %}
{%-   endwith %}
{%-   endfilter %}
}
{%- endfor %}
{%- endif %}

// ---------------------------------------------------------------------------
//   Update and spike handling functions
// ---------------------------------------------------------------------------

{% if uses_numeric_solver %}
{%- include "directives_cpp/GSLDifferentiationFunction.jinja2" %}
{% endif %}

{%- if has_delay_variables %}
void {{neuronName}}::update_delay_variables()
{
{%-   for variable_symbol in neuron.get_state_symbols() %}
{%-     if variable_symbol.has_delay_parameter() %}
{%-       set variable = utils.get_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-       include "directives_cpp/UpdateDelayVariables.jinja2" %}
{%-     endif %}
{%-   endfor %}
}

{%-   for variable in neuron.get_state_symbols() %}
{%-     if variable.has_delay_parameter() %}
double {{neuronName}}::get_delayed_{{variable.get_symbol_name()}}() const
{
    return DV_.delayed_{{variable.get_symbol_name()}}[ DV_.delayed_{{variable.get_symbol_name()}}_idx ];
}
{%-     endif %}
{%-   endfor %}

{%- endif %}

{%- if use_gap_junctions %}
bool {{neuronName}}::update_( nest::Time const& origin, const long from, const long to, const bool called_from_wfr_update )
{%- else %}
void {{neuronName}}::update(nest::Time const & origin,const long from, const long to)
{%- endif %}
{
  const double __resolution = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the resolution() function

{%- if use_gap_junctions %}
  const size_t interpolation_order = nest::kernel().simulation_manager.get_wfr_interpolation_order();
  const double wfr_tol = nest::kernel().simulation_manager.get_wfr_tol();
  bool wfr_tol_exceeded = false;

  // allocate memory to store the new interpolation coefficients
  // to be sent by gap event
  const size_t buffer_size = nest::kernel().connection_manager.get_min_delay() * ( interpolation_order + 1 );
  std::vector< double > new_coefficients( buffer_size, 0.0 );

  // parameters needed for piecewise interpolation
  double y_i = 0.0, y_ip1 = 0.0, hf_i = 0.0, hf_ip1 = 0.0;
{%- endif %}

{% if propagators_are_state_dependent %}
  // the propagators are state dependent; update them!
  recompute_internal_variables();
{%- endif %}

  for ( long lag = from ; lag < to ; ++lag )
  {
    auto get_t = [origin, lag](){ return nest::Time( nest::Time::step( origin.get_steps() + lag + 1) ).get_ms(); };

{%- if use_gap_junctions %}
    // B_.lag is needed by GSL stepping function to determine the current section
    B_.lag_ = lag;






{%- if not gap_junction_membrane_potential_variable_is_numeric %}
{#      in case V_m is solved analytically, need to compute __I_gap here so dV_m/dt can be computed below #}
  // set I_gap depending on interpolation order
  double __I_gap = 0.0;

  const double __t_gap = gap_junction_step / nest::Time::get_resolution().get_ms();

  switch ( nest::kernel().simulation_manager.get_wfr_interpolation_order() )
  {
  case 0:
    __I_gap = -B_.sumj_g_ij_ * {{ gap_junction_membrane_potential_variable_cpp }} + B_.interpolation_coefficients[ B_.lag_ ];
    break;

  case 1:
    __I_gap = -B_.sumj_g_ij_ * {{ gap_junction_membrane_potential_variable_cpp }} + B_.interpolation_coefficients[ B_.lag_ * 2 + 0 ]
      + B_.interpolation_coefficients[ B_.lag_ * 2 + 1 ] * __t_gap;
    break;

  case 3:
    __I_gap = -B_.sumj_g_ij_ * {{ gap_junction_membrane_potential_variable_cpp }} + B_.interpolation_coefficients[ B_.lag_ * 4 + 0 ]
      + B_.interpolation_coefficients[ B_.lag_ * 4 + 1 ] * __t_gap
      + B_.interpolation_coefficients[ B_.lag_ * 4 + 2 ] * __t_gap * __t_gap
      + B_.interpolation_coefficients[ B_.lag_ * 4 + 3 ] * __t_gap * __t_gap * __t_gap;
    break;

  default:
    throw nest::BadProperty( "Interpolation order must be 0, 1, or 3." );
  }
{%- endif %}







    if ( called_from_wfr_update )
    {
      y_i = {{ gap_junction_membrane_potential_variable_cpp }};
      if ( interpolation_order == 3 )
      {
        // find dV_m/dt
        gap_junction_step = 0;
        double __I_gap = 0;
{%-     if gap_junction_membrane_potential_variable_is_numeric %}
{#          solved using a numeric solver #}
        double f_temp[ State_::STATE_VEC_SIZE ];
        {{neuronName}}_dynamics( get_t(), S_.ode_state, f_temp, reinterpret_cast< void* >( this ) );
        hf_i = nest::Time::get_resolution().get_ms() * f_temp[ State_::{{ gap_junction_membrane_potential_variable }} ];
{%-     else %}
{#        solved using an analytic solver #}

{#        the following statements will only assign to temporary variables and not edit the internal state of the neuron #}
{%-         with analytic_state_variables_ = analytic_state_variables %}
{%-             include "directives_cpp/AnalyticIntegrationStep_begin.jinja2" %}
{%-         endwith %}

        hf_i = ({{ gap_junction_membrane_potential_variable }}__tmp - y_i) / nest::Time::get_resolution().get_ms();
{%-     endif %}
      }
    }

{%- endif %}

    for (long i = 0; i < NUM_SPIKE_RECEPTORS; ++i)
    {
        get_spike_inputs_grid_sum_()[i] = get_spike_inputs_()[i].get_value(lag);
    }

{%- for inputPort in neuron.get_continuous_input_ports() %}
{%-   if use_gap_junctions %}
    if ( called_from_wfr_update )
    {
      B_.{{ inputPort.name }}_grid_sum_ = get_{{ inputPort.name }}().get_value_wfr_update(lag);
    }
    else
    {
      B_.{{ inputPort.name }}_grid_sum_ = get_{{ inputPort.name }}().get_value(lag);
    }
{%-   else %}
    B_.{{ inputPort.name }}_grid_sum_ = get_{{ inputPort.name }}().get_value(lag);
{%-   endif %}
{%- endfor %}

{%- if has_delay_variables %}
    update_delay_variables();
{%- endif %}

    // NESTML generated code for the update block

{%- if neuron.get_update_blocks() %}
{%-     filter indent(2) %}
{%-         for block in neuron.get_update_blocks() %}
{%-             set ast = block.get_block() %}
{%-             if ast.print_comment('*')|length > 1 %}
/*
 {{ast.print_comment('*')}}
 */
{%-             endif %}
{%-             include "directives_cpp/Block.jinja2" %}
{%-         endfor %}
{%-     endfilter %}
{%- endif %}


{%- if use_gap_junctions %}
    if ( called_from_wfr_update )
    {
      // check if deviation from last iteration exceeds wfr_tol
      wfr_tol_exceeded = wfr_tol_exceeded or fabs( {{ gap_junction_membrane_potential_variable_cpp }} - B_.last_y_values[ lag ] ) > wfr_tol;
      B_.last_y_values[ lag ] = {{ gap_junction_membrane_potential_variable_cpp }};

      // update different interpolations

      // constant term is the same for each interpolation order
      new_coefficients[ lag * ( interpolation_order + 1 ) + 0 ] = y_i;

      switch ( interpolation_order )
      {
        case 0:
          break;

        case 1:
          y_ip1 = {{ gap_junction_membrane_potential_variable_cpp }};

          new_coefficients[ lag * ( interpolation_order + 1 ) + 1 ] = y_ip1 - y_i;
          break;

        case 3:
          // find dV_m/dt
          {
            gap_junction_step = __resolution;
            y_ip1 = {{ gap_junction_membrane_potential_variable_cpp }};
{%-     if gap_junction_membrane_potential_variable_is_numeric %}
            double f_temp[ State_::STATE_VEC_SIZE ];
            {{ neuronName }}_dynamics( get_t(), S_.ode_state, f_temp, reinterpret_cast< void* >( this ) );
            hf_ip1 = nest::Time::get_resolution().get_ms() * f_temp[ State_::{{ gap_junction_membrane_potential_variable }} ];
{%-     else %}
{#          solved using an analytic solver #}

            const double __t_gap = gap_junction_step / nest::Time::get_resolution().get_ms();

            double __I_gap = -B_.sumj_g_ij_ * {{ gap_junction_membrane_potential_variable_cpp }} + B_.interpolation_coefficients[ B_.lag_ * 4 + 0 ]
              + B_.interpolation_coefficients[ B_.lag_ * 4 + 1 ] * __t_gap
              + B_.interpolation_coefficients[ B_.lag_ * 4 + 2 ] * __t_gap * __t_gap
              + B_.interpolation_coefficients[ B_.lag_ * 4 + 3 ] * __t_gap * __t_gap * __t_gap;

{#        the following statements will only assign to temporary variables and not edit the internal state of the neuron #}
{%-         with analytic_state_variables_ = analytic_state_variables %}
{%-             include "directives_cpp/AnalyticIntegrationStep_begin.jinja2" %}
{%-         endwith %}

            hf_ip1 = ({{ gap_junction_membrane_potential_variable }}__tmp - y_ip1) / nest::Time::get_resolution().get_ms();
{%-     endif %}
          }

          new_coefficients[ lag * ( interpolation_order + 1 ) + 1 ] = hf_i;
          new_coefficients[ lag * ( interpolation_order + 1 ) + 2 ] = -3 * y_i + 3 * y_ip1 - 2 * hf_i - hf_ip1;
          new_coefficients[ lag * ( interpolation_order + 1 ) + 3 ] = 2 * y_i - 2 * y_ip1 + hf_i + hf_ip1;
          break;

        default:
          throw nest::BadProperty( "Interpolation order must be 0, 1, or 3." );
      }
    }

    if ( not called_from_wfr_update )
    {
      // voltage logging
      B_.logger_.record_data(origin.get_steps() + lag);
    }
{%-     else %}
    // voltage logging
    B_.logger_.record_data(origin.get_steps() + lag);
{%-     endif %}
  }

{%- if use_gap_junctions %}
  // if not called_from_wfr_update perform constant extrapolation and reset last_y_values
  if ( not called_from_wfr_update )
  {
    for ( long temp = from; temp < to; ++temp )
    {
      new_coefficients[ temp * ( interpolation_order + 1 ) + 0 ] = {{ gap_junction_membrane_potential_variable_cpp }};
    }

    std::vector< double >( nest::kernel().connection_manager.get_min_delay(), 0.0 ).swap( B_.last_y_values );
  }

  // Send gap-event
  nest::GapJunctionEvent ge;
  ge.set_coeffarray( new_coefficients );
  nest::kernel().event_delivery_manager.send_secondary( *this, ge );

  // Reset variables
  B_.sumj_g_ij_ = 0.0;
  std::vector< double >( buffer_size, 0.0 ).swap( B_.interpolation_coefficients );

  return wfr_tol_exceeded;
{%- endif %}
}

// Do not move this function as inline to h-file. It depends on
// universal_data_logger_impl.h being included here.
void {{neuronName}}::handle(nest::DataLoggingRequest& e)
{
  B_.logger_.handle(e);
}

{% if has_spike_input %}
void {{neuronName}}::handle(nest::SpikeEvent &e)
{
  assert(e.get_delay_steps() > 0);
  assert( e.get_rport() < B_.spike_inputs_.size() );

  double weight = e.get_weight();
  size_t nestml_buffer_idx = 0;
{%- if neuron.get_spike_input_ports()|length > 1 or neuron.is_multisynapse_spikes() %}
  if ( weight >= 0.0 )
  {
    nestml_buffer_idx = std::get<0>(rport_to_nestml_buffer_idx[e.get_rport()]);
  }
  else
  {
    nestml_buffer_idx = std::get<1>(rport_to_nestml_buffer_idx[e.get_rport()]);
    if ( nestml_buffer_idx == {{neuronName}}::PORT_NOT_AVAILABLE )
    {
      nestml_buffer_idx = std::get<0>(rport_to_nestml_buffer_idx[e.get_rport()]);
    }
    weight = -weight;
  }
{%- endif %}
  B_.spike_inputs_[ nestml_buffer_idx - MIN_SPIKE_RECEPTOR ].add_value(
    e.get_rel_delivery_steps( nest::kernel().simulation_manager.get_slice_origin() ),
    weight * e.get_multiplicity() );
}
{%- endif %}

{%- if has_continuous_input %}

void {{neuronName}}::handle(nest::CurrentEvent& e)
{
  assert(e.get_delay_steps() > 0);

  const double current = e.get_current();     // we assume that in NEST, this returns a current in pA
  const double weight = e.get_weight();

{%- for port in neuron.get_continuous_input_ports() %}
  get_{{port.get_symbol_name()}}().add_value(
               e.get_rel_delivery_steps( nest::kernel().simulation_manager.get_slice_origin()),
               weight * current );
{%- endfor %}
}
{%- endif %}



{%- if paired_synapse is defined %}


inline double
{{neuronName}}::get_spiketime_ms() const
{
  return last_spike_;
}


void
{{neuronName}}::register_stdp_connection( double t_first_read, double delay )
{
  // Mark all entries in the deque, which we will not read in future as read by
  // this input input, so that we safely increment the incoming number of
  // connections afterwards without leaving spikes in the history.
  // For details see bug #218. MH 08-04-22

  for ( std::deque< histentry__{{neuronName}} >::iterator runner = history_.begin();
        runner != history_.end() and ( t_first_read - runner->t_ > -1.0 * nest::kernel().connection_manager.get_stdp_eps() );
        ++runner )
  {
    ( runner->access_counter_ )++;
  }

  n_incoming_++;

  max_delay_ = std::max( delay, max_delay_ );
}


void
{{neuronName}}::get_history__( double t1,
  double t2,
  std::deque< histentry__{{neuronName}} >::iterator* start,
  std::deque< histentry__{{neuronName}} >::iterator* finish )
{
  *finish = history_.end();
  if ( history_.empty() )
  {
    *start = *finish;
    return;
  }
  std::deque< histentry__{{neuronName}} >::reverse_iterator runner = history_.rbegin();
  const double t2_lim = t2 + nest::kernel().connection_manager.get_stdp_eps();
  const double t1_lim = t1 + nest::kernel().connection_manager.get_stdp_eps();
  while ( runner != history_.rend() and runner->t_ >= t2_lim )
  {
    ++runner;
  }
  *finish = runner.base();
  while ( runner != history_.rend() and runner->t_ >= t1_lim )
  {
    runner->access_counter_++;
    ++runner;
  }
  *start = runner.base();
}

void
{{neuronName}}::set_spiketime( nest::Time const& t_sp, double offset )
{
    {{neuron_parent_class}}::set_spiketime( t_sp, offset );

    unsigned int num_transferred_variables = 0;
{%- for var in transferred_variables %}
    ++num_transferred_variables;
{%- endfor %}

    const double t_sp_ms = t_sp.get_ms() - offset;

    if ( n_incoming_ )
    {
        // prune all spikes from history which are no longer needed
        // only remove a spike if:
        // - its access counter indicates it has been read out by all connected
        //     STDP synapses, and
        // - there is another, later spike, that is strictly more than
        //     (min_global_delay + max_delay_ + eps) away from the new spike (at t_sp_ms)
        while ( history_.size() > 1 )
        {
            const double next_t_sp = history_[ 1 ].t_;
            if ( history_.front().access_counter_ >= n_incoming_ * num_transferred_variables
                 and t_sp_ms - next_t_sp > max_delay_ + nest::Time::delay_steps_to_ms(nest::kernel().connection_manager.get_min_delay()) + nest::kernel().connection_manager.get_stdp_eps() )
            {
                history_.pop_front();
            }
            else
            {
                break;
            }
        }

        if (history_.size() > 0) {
            assert(history_.back().t_ == last_spike_);

{%- for var in purely_numeric_state_variables_moved|sort %}
            {{ printer.print(utils.get_state_variable_by_name(astnode, var)) }} = history_.back().{{var}}_;
{%- endfor %}
{%- for var in analytic_state_variables_moved|sort %}
            {{ printer.print(utils.get_state_variable_by_name(astnode, var)) }} = history_.back().{{var}}_;
{%- endfor %}
        }
        else {
{%- for var in purely_numeric_state_variables_moved|sort %}
            {{ printer.print(utils.get_state_variable_by_name(astnode, var)) }} = 0.; // initial value for convolution is always 0
{%- endfor %}
{%- for var in analytic_state_variables_moved|sort %}
            {{ printer.print(utils.get_state_variable_by_name(astnode, var)) }} = 0.; // initial value for convolution is always 0
{%- endfor %}
        }


        /**
         * update state variables transferred from synapse from `last_spike_` to `t_sp_ms`
        **/

        const double old___h = V_.__h;
        V_.__h = t_sp_ms - last_spike_;
        if (V_.__h > 1E-12) {
          recompute_internal_variables(true);
{#
  Generates a series of C++ statements which perform one integration step of all ODEs that are solved by the analytic integrator.
#}

{%- filter indent(6, True) %}
{%- with analytic_state_variables_ = analytic_state_variables_moved|sort %}
{%-     include "directives_cpp/AnalyticIntegrationStep_begin.jinja2" %}
{%- endwith %}

{%- if uses_numeric_solver %}
// update only synapse->neuron moved variables; back-up and restore the rest
double ode_state_bak[State_::STATE_VEC_SIZE];

{%-   for variable_name in numeric_state_variables %}
  ode_state_bak[State_::{{variable_name}}] = S_.ode_state[State_::{{variable_name}}];
{%-     endfor %}

{%- if uses_numeric_solver %}
{%-     include "directives_cpp/GSLIntegrationStep.jinja2" %}
{%- endif %}

// restore non-synapse->neuron-moved variables
{%-   for variable_name in numeric_state_variables %}
S_.ode_state[State_::{{variable_name}}] = ode_state_bak[State_::{{variable_name}}];
{%-     endfor %}

// restore variables solved analytically
{%-   for variable_name in numeric_state_variables %}
S_.ode_state[State_::{{variable_name}}] = ode_state_bak[State_::{{variable_name}}];
{%-     endfor %}
{%- endif %}

{%- with analytic_state_variables_ = analytic_state_variables_moved|sort %}
{%-     include "directives_cpp/AnalyticIntegrationStep_end.jinja2" %}
{%- endwith %}

{%- endfilter %}
        V_.__h = old___h;
        recompute_internal_variables(true);
      }

        /**
         * apply spike updates
        **/

{%- for stmt in spike_update_stmts %}
        {{printer.print(stmt)}};
{%- endfor %}

{%- for _, spike_update in post_spike_updates.items() %}
        {{ printer.print(utils.get_variable_by_name(astnode, spike_update.get_variable().get_complete_name())) }} += 1.;
{%- endfor %}

    last_spike_ = t_sp_ms;
    history_.push_back( histentry__{{neuronName}}( last_spike_
{%- for var in purely_numeric_state_variables_moved|sort %}
    , get_{{var}}()
{%- endfor %}
{%- for var in analytic_state_variables_moved|sort %}
    , get_{{var}}()
{%- endfor %}
, 0
 ) );
  }
  else
  {
    last_spike_ = t_sp_ms;
  }
}


void
{{neuronName}}::clear_history()
{
  last_spike_ = -1.0;
  history_.clear();
}


{#
	generate getter functions for the transferred variables
#}

{%- for var in transferred_variables %}
{%- with variable_symbol = transferred_variables_syms[var] %}

{%- if not var == variable_symbol.get_symbol_name() %}
{{ raise('Error in resolving variable to symbol') }}
{%- endif %}

double
{{neuronName}}::get_{{var}}( double t, const bool before_increment )
{
#ifdef DEBUG
  std::cout << "{{neuronName}}::get_{{var}}: getting value at t = " << t << std::endl;
#endif

  // case when the neuron has not yet spiked
  if ( history_.empty() )
  {
#ifdef DEBUG
    std::cout << "{{neuronName}}::get_{{var}}: \thistory empty, returning initial value = " << {{var}}__iv << std::endl;
#endif
    // return initial value
    return {{var}}__iv;
  }

  // search for the latest post spike in the history buffer that came strictly before `t`
  int i = history_.size() - 1;
  double eps = 0.;
  if ( before_increment ) {
   eps = nest::kernel().connection_manager.get_stdp_eps();
  }
  while ( i >= 0 )
  {
    if ( t - history_[ i ].t_ >= eps )
    {
#ifdef DEBUG
      std::cout<<"{{neuronName}}::get_{{var}}: \tspike occurred at history[i].t_ = " << history_[i].t_ << std::endl;
#endif

{%- for var_ in purely_numeric_state_variables_moved %}
      {{ printer.print(utils.get_variable_by_name(astnode, var_)) }} = history_[ i ].{{var_}}_;
{%- endfor %}
{%- for var_ in analytic_state_variables_moved %}
      {{ printer.print(utils.get_variable_by_name(astnode, var_)) }} = history_[ i ].{{var_}}_;
{%- endfor %}

      /**
       * update state variables transferred from synapse from `history[i].t_` to `t`
      **/

      if ( t - history_[ i ].t_ >= nest::kernel().connection_manager.get_stdp_eps() )
      {
        const double old___h = V_.__h;
        V_.__h = t - history_[i].t_;
        assert(V_.__h > 0);
        recompute_internal_variables(true);
{#
  Generates a series of C++ statements which perform one integration step of all ODEs that are solved by the analytic integrator.
#}

{%- filter indent(6, True) %}
{%- with analytic_state_variables_ = analytic_state_variables_moved|sort %}
{%-     include "directives_cpp/AnalyticIntegrationStep_begin.jinja2" %}
{%- endwith %}

{%- if purely_numeric_state_variables_moved|length > 0 %}
double ode_state_tmp[STATE_VEC_SIZE];

for (int i = 0; i < STATE_VEC_SIZE; ++i) {
  ode_state_tmp[i] = S_.ode_state[i];
}

{%- if uses_numeric_solver %}
{%-     include "directives_cpp/GSLIntegrationStep.jinja2" %}
{%- endif %}

{%- for variable_name in numeric_state_variables_moved|sort %}
{%- if not variable_name in analytic_state_variables_moved %}
S_.ode_state[State_::{{variable_name}}] = ode_state_tmp[State_::{{variable_name}}];
{%- endif %}
{%- endfor %}
{%- endif %}

{%- with analytic_state_variables_ = analytic_state_variables_moved|sort %}
{%-     include "directives_cpp/AnalyticIntegrationStep_end.jinja2" %}
{%- endwith %}
{%- endfilter %}

        V_.__h = old___h;
        recompute_internal_variables(true);
      }

#ifdef DEBUG
      std::cout << "{{neuronName}}::get_{{var}}: \treturning " << {{ printer.print(utils.get_variable_by_name(astnode, var)) }} << std::endl;
#endif
      return {{ printer.print(utils.get_variable_by_name(astnode, var)) }};       // type: {{declarations.print_variable_type(variable_symbol)}}
    }
    --i;
  }

  // this case occurs when the trace was requested at a time precisely at that of the first spike in the history
  if ( (!before_increment) and t == history_[ 0 ].t_)
  {
{%- for var_ in purely_numeric_state_variables_moved %}
    {{ printer.print(utils.get_state_variable_by_name(astnode, var_)) }} = history_[ 0 ].{{var_}}_;
{%- endfor %}
{%- for var_ in analytic_state_variables_moved %}
    {{ printer.print(utils.get_state_variable_by_name(astnode, var_)) }} = history_[ 0 ].{{var_}}_;
{%- endfor %}

#ifdef DEBUG
    std::cout << "{{neuronName}}::get_{{var}}: \ttrace requested at exact time of history entry 0, returning " << {{ printer.print(utils.get_variable_by_name(astnode, variable_symbol.get_symbol_name())) }} << std::endl;
#endif
    return {{ printer.print(utils.get_variable_by_name(astnode, variable_symbol.get_symbol_name())) }};
  }

  // this case occurs when the trace was requested at a time before the first spike in the history
  // return initial value propagated in time
#ifdef DEBUG
  std::cout << "{{neuronName}}::get_{{var}}: \tfall-through, returning initial value = " << {{var}}__iv << std::endl;
#endif

  if (t == 0.) {
    return 0.;  // initial value for convolution is always 0
  }

  // set to initial value
{%- for var_ in purely_numeric_state_variables_moved %}
  {{ printer.print(utils.get_state_variable_by_name(astnode, var_)) }} = 0.;  // initial value for convolution is always 0
{%- endfor %}
{%- for var_ in analytic_state_variables_moved %}
  {{ printer.print(utils.get_state_variable_by_name(astnode, var_)) }} = 0.;  // initial value for convolution is always 0
{%- endfor %}

  // propagate in time
  const double old___h = V_.__h;
  V_.__h = t;   // from time 0 to the requested time
  assert(V_.__h > 0);
  recompute_internal_variables(true);
{#
  Generates a series of C++ statements which perform one integration step of all ODEs that are solved by the analytic integrator.
#}
{%- filter indent(2, True) %}
{%- with analytic_state_variables_ = analytic_state_variables_moved|sort %}
{%-     include "directives_cpp/AnalyticIntegrationStep_begin.jinja2" %}
{%- endwith %}

{%- if purely_numeric_state_variables_moved|length > 0 %}
double ode_state_tmp[STATE_VEC_SIZE];

for (int i = 0; i < STATE_VEC_SIZE; ++i) {
    ode_state_tmp[i] = S_.ode_state[i];
}

{%- if uses_numeric_solver %}
{%-     include "directives_cpp/GSLIntegrationStep.jinja2" %}
{%- endif %}

{%- for variable_name in numeric_state_variables_moved|sort %}
{%- if not variable_name in analytic_state_variables_moved %}
  S_.ode_state[State_::{{variable_name}}] = ode_state_tmp[State_::{{variable_name}}];
{%- endif %}
{%- endfor %}
{%- endif %}

{%- with analytic_state_variables_ = analytic_state_variables_moved|sort %}
{%-     include "directives_cpp/AnalyticIntegrationStep_end.jinja2" %}
{%- endwith %}

{%- endfilter %}
  V_.__h = old___h;
  recompute_internal_variables(true);

  return {{ printer.print(utils.get_variable_by_name(astnode, var)) }};
}
{%- endwith -%}
{%- endfor %}

{%- endif %}



{%- if use_gap_junctions %}
void {{neuronName}}::handle( nest::GapJunctionEvent& e )
{
#ifdef DEBUG
  std::cout << "Handling GapJunctionEvent\n";
#endif

  const double weight = e.get_weight();

  B_.sumj_g_ij_ += weight;

  size_t i = 0;
  std::vector< unsigned int >::iterator it = e.begin();
  // The call to get_coeffvalue( it ) in this loop also advances the iterator it
  while ( it != e.end() )
  {
    B_.interpolation_coefficients[ i ] += weight * e.get_coeffvalue( it );
    ++i;
  }
}
{%- endif %}

{# leave this comment here to ensure newline is generated at end of file -#}
