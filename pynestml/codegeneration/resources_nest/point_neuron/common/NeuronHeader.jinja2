{#-
NeuronHeader.jinja2

This file is part of NEST.

Copyright (C) 2004 The NEST Initiative

NEST is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 2 of the License, or
(at your option) any later version.

NEST is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with NEST.  If not, see <http://www.gnu.org/licenses/>.
#}
{%- if tracing %}/* generated by {{self._TemplateReference__context.name}} */ {% endif -%}
{%- import 'directives_cpp/SpikeBufferGetter.jinja2' as buffer_getter with context %}
{%- import 'directives_cpp/ContinuousInputBufferGetter.jinja2' as continuous_buffer_getter with context %}
{%- import 'directives_cpp/BufferDeclaration.jinja2' as buffer_declaration with context %}
{%- import 'directives_cpp/BufferDeclarationValue.jinja2' as buffer_declaration_value with context %}
{%- import 'directives_cpp/FunctionDeclaration.jinja2' as function_declaration with context %}
{%- import 'directives_cpp/OutputEvent.jinja2' as output_event with context %}
/**
 *  {{neuronName}}.h
 *
 *  This file is part of NEST.
 *
 *  Copyright (C) 2004 The NEST Initiative
 *
 *  NEST is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 2 of the License, or
 *  (at your option) any later version.
 *
 *  NEST is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with NEST.  If not, see <http://www.gnu.org/licenses/>.
 *
 *  Generated from NESTML at time: {{now}}
**/
#ifndef {{neuronName.upper()}}
#define {{neuronName.upper()}}

#ifndef HAVE_LIBLTDL
#error "NEST was compiled without support for dynamic loading. Please install libltdl and recompile NEST."
#endif

// C++ includes:
#include <cmath>

#include "config.h"
{%- if norm_rng %}

// Includes for random number generator
{%- if nest_version.startswith("v2") %}
#include "normal_randomdev.h"
#include "poisson_randomdev.h"
#include "uniform_randomdev.h"
{%- else %}
#include <random>
{%- endif %}
{%- endif %}
{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}

#ifndef HAVE_GSL
#error "The GSL library is required for the Runge-Kutta solver."
#endif

// External includes:
#include <gsl/gsl_errno.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_odeiv.h>
{%-     endif %}
{%- endif %}

// Includes from nestkernel:
#include "{{neuron_parent_class_include}}"
#include "connection.h"
{%- if not nest_version.startswith("v2") %}
#include "dict_util.h"
{%- endif %}
#include "event.h"
#include "nest_types.h"
#include "ring_buffer.h"
#include "universal_data_logger.h"

// Includes from sli:
#include "dictdatum.h"

// uncomment the next line to enable printing of detailed debug information
// #define DEBUG

namespace nest
{
namespace {{names_namespace}}
{
{%- if neuron.get_state_symbols()|length > 0 %}
{%- for sym in neuron.get_state_symbols() %}
    const Name _{{sym.get_symbol_name()}}( "{{sym.get_symbol_name()}}" );
{%- endfor %}
{%- endif %}
{%- if recordable_inline_expressions|length > 0 %}
{%- for sym in recordable_inline_expressions %}
    const Name _{{sym.get_symbol_name()}}( "{{sym.get_symbol_name()}}" );
{%- endfor %}
{%- endif %}
{%- if neuron.get_parameter_symbols()|length > 0 %}
{%- for sym in neuron.get_parameter_symbols() %}
    const Name _{{sym.get_symbol_name()}}( "{{sym.get_symbol_name()}}" );
{%- endfor %}
{%- endif %}

    const Name gsl_abs_error_tol("gsl_abs_error_tol");
    const Name gsl_rel_error_tol("gsl_rel_error_tol");
}
}


{%  if uses_numeric_solver %}

{%-     for s in utils.create_integrate_odes_combinations(astnode) %}
/**
 * Function computing right-hand side of ODE for GSL solver.
 * @note Must be declared here so we can befriend it in class.
 * @note Must have C-linkage for passing to GSL. Internally, it is
 *       a first-class C++ function, but cannot be a member function
 *       because of the C-linkage.
 * @note No point in declaring it inline, since it is called
 *       through a function pointer.
 * @param void* Pointer to model neuron instance.
 *
 * Integrate the variables: {{ s }}
**/
extern "C" inline int {{neuronName}}_dynamics{% if s | length > 0 %}_{{ s }}{% endif %}( double, const double ode_state[], double f[], void* pnode );
{%-     endfor %}

{%-     if paired_synapse is defined and (purely_numeric_state_variables_moved + analytic_state_variables_moved) | length > 0 %}
{#  for neuron-synapse co-generation: separate integrator for the emulated/dummy integrate_odes() below in NeuronClass.jinja2 #}
{%-         set args = utils.resolve_variables_to_expressions(astnode, purely_numeric_state_variables_moved + analytic_state_variables_moved) %}
{%-         set ast = ASTNodeFactory.create_ast_function_call("integrate_odes", args) %}
{%-         set s = utils.integrate_odes_args_str_from_function_call(ast) %}
extern "C" inline int {{neuronName}}_dynamics{% if s | length > 0 %}_{{ s }}{% endif %}( double, const double ode_state[], double f[], void* pnode );
{%-     endif %}

{%- endif %}

#include "nest_time.h"


{%- if not (nest_version.startswith("v2") or nest_version.startswith("v3.0") or nest_version.startswith("v3.1") or nest_version.startswith("v3.2") or nest_version.startswith("v3.3") or nest_version.startswith("v3.4")) %}
  typedef size_t nest_port_t;
  typedef size_t nest_rport_t;
{%- else %}
  typedef nest::port nest_port_t;
  typedef nest::rport nest_rport_t;
{%- endif %}


{%- if paired_synapse is defined %}

/**
 * entry in the spiking history
**/
class histentry__{{ neuronName }}
{
public:
  histentry__{{ neuronName }}( double t
      , size_t access_counter
{%- for var in purely_numeric_state_variables_moved|sort %}
      , double {{ var }}
{%- endfor %}
{%- for var in analytic_state_variables_moved|sort %}
      , double {{ var }}
{%- endfor %}
{%- if state_vars_that_need_continuous_buffering | length > 0 and continuous_state_buffering_method == "post_spike_based" %}
{%-     for state_var in state_vars_that_need_continuous_buffering | sort %}
      , double {{ state_var }}
{%-     endfor %}
{%- endif %}
  )
  : t_( t )
  , access_counter_( access_counter )
{%- for var in (purely_numeric_state_variables_moved + analytic_state_variables_moved) | sort %}
  , {{ var }}_( {{ var }} )
{%- endfor %}
{%- if state_vars_that_need_continuous_buffering | length > 0 and continuous_state_buffering_method == "post_spike_based" %}
{%-     for state_var in state_vars_that_need_continuous_buffering | sort %}
  , {{ state_var }}_( {{ state_var }} )
{%-     endfor %}
{%- endif %}
  {
  }

  double t_;              //!< point in time when spike occurred (in ms)
  size_t access_counter_; //!< access counter to enable removal of the entry, once all neurons read it

{%- for var in (purely_numeric_state_variables_moved + analytic_state_variables_moved) | sort %}
  double {{ var }}_;

{%-     set inline = utils.get_inline_expression_by_constructed_rhs_name(paired_synapse_original_model, var) %}
{%-     if inline and utils.inline_aliases_convolution(inline) %}
  double get_{{ inline.get_variable_name() + "__for_" + paired_synapse_original_model.get_name() }}() const     // getter for an inline expression
{%-     else %}
  double get_{{ var }}() const
{%-     endif %}
  {
    return {{ var }}_;
  }

{%- endfor %}

{%- if state_vars_that_need_continuous_buffering | length > 0 and continuous_state_buffering_method == "post_spike_based" %}
{%-     for state_var in state_vars_that_need_continuous_buffering %}
  double {{ state_var }}_;
{%-     endfor %}
{%- endif %}
};
{%- if state_vars_that_need_continuous_buffering | length > 0 and continuous_state_buffering_method == "continuous_time_buffer" %}

class continuous_variable_histentry_{{ neuronName }}
{
public:
  continuous_variable_histentry_{{ neuronName }}( double t,
{%-     for state_var in state_vars_that_need_continuous_buffering %}
      double {{ state_var }}{% if not loop.last %}, {% endif %}
{%-     endfor %} );

  double t_;              //!< point in time for history entry
  size_t access_counter_;

{%-     for state_var in state_vars_that_need_continuous_buffering %}
  double {{ state_var }};
{%-     endfor %}
};
{%- endif %}
{%- endif %}

/* BeginDocumentation
  Name: {{neuronName}}

  Description:
{% filter indent(2) %}
  {{neuron.print_comment()}}
{%- endfilter %}

  Parameters:
  The following parameters can be set in the status dictionary.
{% for parameter in neuron.get_parameter_symbols() -%}
{% if parameter.has_comment() -%}
    {{parameter.get_symbol_name()}} [{{parameter.get_type_symbol().print_symbol()}}] {{parameter.print_comment()}}
{% endif -%}
{% endfor %}

  Dynamic state variables:
{% for state in neuron.get_state_symbols() -%}
{% if state.has_comment() -%}
    {{state.get_symbol_name()}} [{{state.get_type_symbol().print_symbol()}}] {{state.print_comment()}}
{% endif -%}
{% endfor %}

  Sends: {{ output_event.OutputEvent() }}

  Receives: {% if has_spike_input %}Spike, {% endif %}{% if has_continuous_input %}Current,{% endif %} DataLoggingRequest
*/

// Register the neuron model
{%- if not (nest_version.startswith("v2") or nest_version.startswith("v3.0") or nest_version.startswith("v3.1") or nest_version.startswith("v3.2")
        or nest_version.startswith("v3.3") or nest_version.startswith("v3.4") or nest_version.startswith("v3.5") or nest_version.startswith("v3.6")) %}
void register_{{ neuronName }}( const std::string& name );
{%- endif %}

class {{neuronName}} : public nest::{{neuron_parent_class}}
{
public:
  /**
   * The constructor is only used to create the model prototype in the model manager.
  **/
  {{neuronName}}();

  /**
   * The copy constructor is used to create model copies and instances of the model.
   * @node The copy constructor needs to initialize the parameters and the state.
   *       Initialization of buffers and interal variables is deferred to
   *       @c init_buffers_() and @c pre_run_hook() (or calibrate() in NEST 3.3 and older).
  **/
  {{neuronName}}(const {{neuronName}} &);

  /**
   * Destructor.
  **/
  ~{{neuronName}}() override;

  // -------------------------------------------------------------------------
  //   Import sets of overloaded virtual functions.
  //   See: Technical Issues / Virtual Functions: Overriding, Overloading,
  //        and Hiding
  // -------------------------------------------------------------------------

  using nest::Node::handles_test_event;
  using nest::Node::handle;

{%- if use_gap_junctions %}
  using nest::Node::sends_secondary_event;

  void
  sends_secondary_event( nest::GapJunctionEvent& ) override
  {
  }
{%- endif %}

  /**
   * Used to validate that we can send {{ output_event.OutputEvent() }} to desired target:port.
  **/
  nest_port_t send_test_event(nest::Node& target, nest_rport_t receptor_type, nest::synindex, bool) override;


  // -------------------------------------------------------------------------
  //   Functions handling incoming events.
  //   We tell nest that we can handle incoming events of various types by
  //   defining handle() for the given event.
  // -------------------------------------------------------------------------

{% if has_spike_input %}
  void handle(nest::SpikeEvent &) override;        //! accept spikes
{%- endif %}

{%- if has_continuous_input %}
  void handle(nest::CurrentEvent &) override;      //! accept input current
{%- endif %}

  void handle(nest::DataLoggingRequest &) override;//! allow recording with multimeter

{%- if has_spike_input %}
  nest_port_t handles_test_event(nest::SpikeEvent&, nest_port_t) override;
{%- endif %}

{%- if has_continuous_input %}
  nest_port_t handles_test_event(nest::CurrentEvent&, nest_port_t) override;
{%- endif %}
  nest_port_t handles_test_event(nest::DataLoggingRequest&, nest_port_t) override;

{%- if use_gap_junctions %}
  void handle( nest::GapJunctionEvent& ) override;
  nest_port_t handles_test_event( nest::GapJunctionEvent&, nest_rport_t ) override;
  bool wfr_update( nest::Time const&, const long, const long ) override;

  double gap_junction_step;

{%- endif %}

  // -------------------------------------------------------------------------
  //   Functions for getting/setting parameters and state values.
  // -------------------------------------------------------------------------

  void get_status(DictionaryDatum &) const override;
  void set_status(const DictionaryDatum &) override;

{% if paired_synapse is defined %}
  // support for spike archiving

  /**
   * Return the spike times (in steps) of spikes which occurred in the range (t1,t2].
   *
   * Two underscores in the name to differentiate it from nest::Node::get_history().
   */
  void get_history__( double t1,
    double t2,
    std::deque< histentry__{{neuronName}} >::iterator* start,
    std::deque< histentry__{{neuronName}} >::iterator* finish );

  /**
   * Register a new incoming STDP connection.
   *
   * t_first_read: The newly registered synapse will read the history entries
   * with t > t_first_read.
   */
  void register_stdp_connection( double t_first_read, double delay );

{%- if state_vars_that_need_continuous_buffering | length > 0 and continuous_state_buffering_method == "continuous_time_buffer" %}

  /**
   * write_continuous_variable_history
  **/
  void write_continuous_variable_history(nest::Time const &t,
{%-     for state_var in state_vars_that_need_continuous_buffering %}
      const double {{ state_var }}{% if not loop.last %}, {% endif %}
{%-     endfor %});

  void get_continuous_variable_history( double t1,
    double t2,
    std::deque< continuous_variable_histentry_{{ neuronName }} >::iterator* start,
    std::deque< continuous_variable_histentry_{{ neuronName }} >::iterator* finish );

  std::deque< continuous_variable_histentry_{{ neuronName }} > continuous_variable_history_;
{%- endif %}
{%- endif %}
{%- if neuron.get_state_symbols()|length > 0 %}
  // -------------------------------------------------------------------------
  //   Getters/setters for state block
  // -------------------------------------------------------------------------

{%      filter indent(2, True) -%}
{%-         for variable_symbol in neuron.get_state_symbols() %}
{%-             if not is_delta_kernel(neuron.get_kernel_by_name(variable_symbol.name)) %}
{%-                 set variable = utils.get_state_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-                 include "directives_cpp/MemberVariableGetterSetter.jinja2" %}
{%              endif %}
{%          endfor %}
{%-     endfilter %}
{%- endif %}

{%- if neuron.get_parameter_symbols()|length > 0 %}
  // -------------------------------------------------------------------------
  //   Getters/setters for parameters
  // -------------------------------------------------------------------------

{%      filter indent(2, True) -%}
{%-         for variable_symbol in neuron.get_parameter_symbols() %}
{%-             set variable = utils.get_parameter_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-             include "directives_cpp/MemberVariableGetterSetter.jinja2" %}

{%          endfor %}
{%-     endfilter %}
{%- endif %}

{%-  if neuron.get_internal_symbols() | length > 0 %}
  // -------------------------------------------------------------------------
  //   Getters/setters for internals
  // -------------------------------------------------------------------------

{%      filter indent(2, True) -%}
{%-         for variable_symbol in neuron.get_internal_symbols() %}
{%-             with variable = utils.get_internal_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-                 include "directives_cpp/MemberVariableGetterSetter.jinja2" %}
{%-             endwith %}
{%          endfor %}
{%-     endfilter %}
{%- endif %}

{%- if paired_synapse is defined %}

  // -------------------------------------------------------------------------
  //   Getters/setters for variables transferred from synapse
  // -------------------------------------------------------------------------

{%-     for var in transferred_variables %}
  double get_{{ var }}( double t, const bool before_increment = true );
{%-     endfor %}

{%-     if state_vars_that_need_continuous_buffering | length > 0 %}

  // -------------------------------------------------------------------------
  //   Getters/setters for variables that need continuous time buffering
  // -------------------------------------------------------------------------

{%-         for var in state_vars_that_need_continuous_buffering %}
  double get_{{ var }}( double t, const bool before_increment = true );
{%-         endfor %}
{%-     endif %}
{%- endif %}

  // -------------------------------------------------------------------------
  //   Methods corresponding to event handlers
  // -------------------------------------------------------------------------

{%  filter indent(2, True) -%}
{%-     for blk in neuron.get_on_receive_blocks() %}
    void on_receive_block_{{ blk.get_port_name() }}();
{%-     endfor %}
{%- endfilter %}

  // -------------------------------------------------------------------------
  //   Initialization functions
  // -------------------------------------------------------------------------

{%- if not nest_version.startswith("v2") %}
  void calibrate_time( const nest::TimeConverter& tc ) override;
{%- endif %}

protected:
{%- if paired_synapse is defined %}
  // support for spike archiving

  /**
   * record spike history
   */
  void set_spiketime( nest::Time const& t_sp, double offset = 0.0 );

  /**
   * return most recent spike time in ms
   */
  inline double get_spiketime_ms() const;

  /**
   * clear spike history
   */
  void clear_history();
{%- endif %}

private:
  void recompute_internal_variables(bool exclude_timestep=false);


{%- if paired_synapse is defined %}
  // support for spike archiving

  // number of incoming connections from stdp connectors.
  // needed to determine, if every incoming connection has
  // read the spikehistory for a given point in time
  size_t n_incoming_;

  double max_delay_;

  double last_spike_;

  // spiking history needed by stdp synapses
  std::deque< histentry__{{neuronName}} > history_;

  // cache for initial values
{%- for var in transferred_variables + state_vars_that_need_continuous_buffering %}
  double {{var}}__iv;
{%- endfor %}


{%- endif %}

private:
{% if has_multiple_synapses -%}
  /**
   * Synapse types to connect to
   * @note Excluded lower and upper bounds are defined as MIN_, MAX_.
   *       Excluding port 0 avoids accidental connections.
  **/
  static const nest_port_t MIN_SPIKE_RECEPTOR = 1;
{%-   set ns = namespace(count=1) %}
{%- else %}
  static const nest_port_t MIN_SPIKE_RECEPTOR = 0;
{%-   set ns = namespace(count=0) %}
{%- endif %}
  static const nest_port_t PORT_NOT_AVAILABLE = -1;

  enum SynapseTypes
  {
{%- for port in neuron.get_spike_input_ports() %}
{%-   if port.has_vector_parameter() -%}
{%      set size = utils.get_numeric_vector_size(port) | int %}
{%-     for i in range(size) %}
    {{port.get_symbol_name().upper()}}_{{i}} = {{ns.count}},
{%-       set ns.count = ns.count + 1 -%}
{%-     endfor %}
{%-   else %}
    {{port.get_symbol_name().upper()}} = {{ns.count}},
{%-     set ns.count = ns.count + 1 -%}
{%-   endif -%}
{%- endfor %}
    MAX_SPIKE_RECEPTOR = {{ns.count}}
  };

  static const size_t NUM_SPIKE_RECEPTORS = MAX_SPIKE_RECEPTOR - MIN_SPIKE_RECEPTOR;

{% if neuron.get_spike_input_ports()|length > 1 or neuron.is_multisynapse_spikes() -%}
  static std::vector< std::tuple< int, int > > rport_to_nestml_buffer_idx;
{%- endif %}

  /**
   * Reset state of neuron.
  **/
{%- if nest_version.startswith("v2") %}
  void init_state_(const Node& proto) override;
{%- endif %}

  void init_state_internal_();

  /**
   * Reset internal buffers of neuron.
  **/
  void init_buffers_() override;

  /**
   * Initialize auxiliary quantities, leave parameters and state untouched.
  **/
{%- if nest_version.startswith("v2") or nest_version.startswith("v3.0") or nest_version.startswith("v3.1") or nest_version.startswith("v3.2") or nest_version.startswith("v3.3") %}
  void calibrate() override;
{%- else %}
  void pre_run_hook() override;
{%- endif %}

  /**
   * Take neuron through given time interval
  **/

{%- if use_gap_junctions %}
  /** This is the actual update function. The additional boolean parameter
   * determines if the function is called by update (false) or wfr_update (true)
   */
  bool update_( nest::Time const&, const long, const long, const bool );

  inline void
  update( nest::Time const& origin, const long from, const long to )
  {
    update_( origin, from, to, false );
  }
{%- else %}
  void update(nest::Time const &, const long, const long) override;
{%- endif %}

  // The next two classes need to be friends to access the State_ class/member
{%- if (has_state_vectors) %}
  friend class nest::DynamicRecordablesMap< {{neuronName}} >;
  friend class nest::DynamicUniversalDataLogger< {{neuronName}} >;
  friend class nest::DataAccessFunctor< {{neuronName}} >;
{%- else %}
  friend class nest::RecordablesMap<{{neuronName}}>;
  friend class nest::UniversalDataLogger<{{neuronName}}>;
{%- endif %}

  /**
   * Free parameters of the neuron.
   *
{% for block in neuron.get_parameters_blocks() %}
{{ block.print_comment() }}
{%- endfor %}
   *
   * These are the parameters that can be set by the user through @c `node.set()`.
   * They are initialized from the model prototype when the node is created.
   * Parameters do not change during calls to @c update() and are not reset by
   * @c ResetNetwork.
   *
   * @note Parameters_ need neither copy constructor nor @c operator=(), since
   *       all its members are copied properly by the default copy constructor
   *       and assignment operator. Important:
   *       - If Parameters_ contained @c Time members, you need to define the
   *         assignment operator to recalibrate all members of type @c Time . You
   *         may also want to define the assignment operator.
   *       - If Parameters_ contained members that cannot copy themselves, such
   *         as C-style arrays, you need to define the copy constructor and
   *         assignment operator to copy those members.
  **/
  struct Parameters_
  {
{%- filter indent(4,True) %}
{%- for variable_symbol in neuron.get_parameter_symbols() %}
{%-     set variable = utils.get_parameter_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     include 'directives_cpp/MemberDeclaration.jinja2' %}
{%- endfor %}
{%- endfilter %}
{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}

    double __gsl_abs_error_tol;
    double __gsl_rel_error_tol;
{%-     endif %}
{%- endif %}

    /**
     * Initialize parameters to their default values.
    **/
    Parameters_();
  };

  /**
   * Dynamic state of the neuron.
   *
{%- for state_block in neuron.get_state_blocks() %}
   {{ state_block.print_comment('*') }}
{%- endfor %}
   *
   * These are the state variables that are advanced in time by calls to
   * @c update(). In many models, some or all of them can be set by the user
   * through @c `node.set()`. The state variables are initialized from the model
   * prototype when the node is created. State variables are reset by @c ResetNetwork.
   *
   * @note State_ need neither copy constructor nor @c operator=(), since
   *       all its members are copied properly by the default copy constructor
   *       and assignment operator. Important:
   *       - If State_ contained @c Time members, you need to define the
   *         assignment operator to recalibrate all members of type @c Time . You
   *         may also want to define the assignment operator.
   *       - If State_ contained members that cannot copy themselves, such
   *         as C-style arrays, you need to define the copy constructor and
   *         assignment operator to copy those members.
  **/
  struct State_
  {
{%- if not uses_numeric_solver %}
{%-   if has_state_vectors %}
{%      include "directives_cpp/StateVariablesEnum.jinja2" %}
{%-   endif %}
{%-   filter indent(4,True) %}
{%-   for variable_symbol in neuron.get_state_symbols() %}
{%-     set variable = utils.get_state_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     include "directives_cpp/MemberDeclaration.jinja2" %}
{%-   endfor %}
{%-   endfilter %}
{%- else %}

    // non-ODE state variables
{%-   for variable_name in non_equations_state_variables %}
{%-     set variable_symbol = astnode.get_scope().resolve_to_symbol(variable_name, SymbolKind.VARIABLE) %}
{%-     set variable = utils.get_state_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     include "directives_cpp/MemberDeclaration.jinja2" %}
{%-   endfor %}

{%-   if has_state_vectors %}
{%-     include "directives_cpp/VectorVariablesEnum.jinja2" %}
{%-   endif %}
    //! Symbolic indices to the elements of the state vector y
    enum StateVecElems
    {
{#- N.B. numeric solver contains all state variables, including those that will be solved by analytic solver #}
{%-   if uses_numeric_solver %}
{%-     for variable_name in numeric_state_variables %}
      {{variable_name}},
{%-     endfor %}
      // moved state variables from synapse (numeric)
{%-     for variable_name in purely_numeric_state_variables_moved|sort %}
      {{variable_name}},
{%-     endfor %}
      // moved state variables from synapse (analytic)
{%-     for variable_name in analytic_state_variables_moved|sort %}
      {{variable_name}},
{%-     endfor %}
{%-   else %}
{#-     analytic solver only #}
      // analytic state variables
{%-     for variable_name in analytic_state_variables %}
      {{variable_name}},
{%-     endfor %}
{%-   endif %}
      // final entry to easily get the vector size
      STATE_VEC_SIZE
    };

    //! state vector, must be C-array for GSL solver
    double ode_state[STATE_VEC_SIZE];
{%- endif %}

    State_();
  };

  struct DelayedVariables_
  {
{%- if has_delay_variables %}
    // Declare helper variables for variables with delay
{%-   for variable in neuron.get_state_symbols() %}
{%-     if variable.has_delay_parameter() %}
{%-       include "directives_cpp/DelayVariablesDeclaration.jinja2" %}
{%-     endif %}
{%-   endfor %}
{%- endif %}
  };

  /**
   * Internal variables of the neuron.
   *
{%- for internals_block in neuron.get_internals_blocks() %}
   {{ internals_block.print_comment('*') }}
{%- endfor %}
   *
   * These variables must be initialized by @c pre_run_hook (or calibrate in NEST 3.3 and older), which is called before
   * the first call to @c update() upon each call to @c Simulate.
   * @node Variables_ needs neither constructor, copy constructor or assignment operator,
   *       since it is initialized by @c pre_run_hook() (or calibrate() in NEST 3.3 and older). If Variables_ has members that
   *       cannot destroy themselves, Variables_ will need a destructor.
  **/
  struct Variables_
  {
{%- for variable_symbol in neuron.get_internal_symbols() %}
{%-     set variable = utils.get_internal_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     filter indent(4) %}
{%-         include "directives_cpp/MemberDeclaration.jinja2" %}
{%-     endfilter %}
{%- endfor %}
  };

  /**
   * Buffers of the neuron.
   * Usually buffers for incoming spikes and data logged for analog recorders.
   * Buffers must be initialized by @c init_buffers_(), which is called before
   * @c pre_run_hook() (or calibrate() in NEST 3.3 and older) on the first call to @c Simulate after the start of NEST,
   * ResetKernel or ResetNetwork.
   * @node Buffers_ needs neither constructor, copy constructor or assignment operator,
   *       since it is initialized by @c init_nodes_(). If Buffers_ has members that
   *       cannot destroy themselves, Buffers_ will need a destructor.
  **/
  struct Buffers_
  {
    Buffers_({{neuronName}} &);
    Buffers_(const Buffers_ &, {{neuronName}} &);

    /**
     * Logger for all analog data
    **/
{%- if has_state_vectors %}
    nest::DynamicUniversalDataLogger<{{neuronName}}> logger_;
{%- else %}
    nest::UniversalDataLogger<{{neuronName}}> logger_;
{%- endif %}

    // -----------------------------------------------------------------------
    //   Spike buffers and sums of incoming spikes/currents per timestep
    // -----------------------------------------------------------------------

{%- filter indent(4, True) -%}
{{ buffer_getter.SpikeBufferGetter(true) }}
{%- endfilter %}

    // -----------------------------------------------------------------------
    //   Continuous-input buffers
    // -----------------------------------------------------------------------

{% filter indent(4, True) %}
{%-     for inputPort in neuron.get_continuous_input_ports() %}
{{ buffer_declaration.BufferDeclaration(inputPort) }}
{{ continuous_buffer_getter.ContinuousInputBufferGetter(inputPort, true) }}
{{ buffer_declaration_value.BufferDeclarationValue(inputPort) }}
{%-     endfor %}
{%- endfilter %}

{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}

    // -----------------------------------------------------------------------
    //   GSL ODE solver data structures
    // -----------------------------------------------------------------------

    gsl_odeiv_step* __s;    //!< stepping function
    gsl_odeiv_control* __c; //!< adaptive stepsize control function
    gsl_odeiv_evolve* __e;  //!< evolution function
    gsl_odeiv_system __sys; //!< struct describing system

    // __integration_step should be reset with the neuron on ResetNetwork,
    // but remain unchanged during calibration. Since it is initialized with
    // step_, and the resolution cannot change after nodes have been created,
    // it is safe to place both here.
    double __step;             //!< step size in ms
    double __integration_step; //!< current integration time step, updated by GSL
{%-     endif %}
{%- endif %}

{%- if use_gap_junctions %}
    // -----------------------------------------------------------------------
    //   Gap junctions
    // -----------------------------------------------------------------------

    // remembers current lag for piecewise interpolation
    long lag_;
    // remembers y_values from last wfr_update
    std::vector< double > last_y_values;
    // summarized gap weight
    double sumj_g_ij_;
    // summarized coefficients of the interpolation polynomial
    std::vector< double > interpolation_coefficients;
{%- endif %}
  };

  // -------------------------------------------------------------------------
  //   Getters/setters for inline expressions
  // -------------------------------------------------------------------------

{%  filter indent(2, True) -%}
{%- for equations_block in neuron.get_equations_blocks() %}
{%-     for inline_expr in equations_block.get_inline_expressions() %}
{%-         set variable = ast_node_factory.create_ast_variable(inline_expr.get_variable_name(), differential_order=0, scope=inline_expr.scope) %}
{%-         set variable_symbol = equations_block.get_scope().resolve_to_symbol(inline_expr.get_variable_name(), SymbolKind.VARIABLE) %}
{%-         include "directives_cpp/MemberVariableGetterSetter.jinja2" %}

{%     endfor %}
{%- endfor %}
{%- endfilter %}

  // -------------------------------------------------------------------------
  //   Getters/setters for input buffers
  // -------------------------------------------------------------------------

{%- filter indent(2, True) %}
{{ buffer_getter.SpikeBufferGetter(false) }}
{%- endfilter %}

{%- for inputPort in neuron.get_continuous_input_ports() %}
{{ continuous_buffer_getter.ContinuousInputBufferGetter(inputPort, false) }}
{%- endfor %}

{%- if neuron.get_functions()|length > 0 %}
  // -------------------------------------------------------------------------
  //   Function declarations
  // -------------------------------------------------------------------------

{%  filter indent(2) -%}
{%- for function in neuron.get_functions() %}
{{ function_declaration.FunctionDeclaration(function, "") }};
{%- endfor %}
{%- endfilter %}
{%- endif %}

  // -------------------------------------------------------------------------
  //   Member variables of neuron model.
  //   Each model neuron should have precisely the following four data members,
  //   which are one instance each of the parameters, state, buffers and variables
  //   structures. Experience indicates that the state and variables member should
  //   be next to each other to achieve good efficiency (caching).
  //   Note: Devices require one additional data member, an instance of the
  //   ``Device`` child class they belong to.
  // -------------------------------------------------------------------------


  Parameters_       P_;        //!< Free parameters.
  State_            S_;        //!< Dynamic state.
  DelayedVariables_ DV_;       //!< Delayed state variables.
  Variables_        V_;        //!< Internal Variables
  Buffers_          B_;        //!< Buffers.

  //! Mapping of recordables names to access functions
{%- if has_state_vectors %}
  nest::DynamicRecordablesMap<{{neuronName}}> recordablesMap_;
  nest::DataAccessFunctor< {{neuronName}} > get_data_access_functor( size_t elem );
  std::string get_var_name(size_t elem, std::string var_name);
  void insert_recordables(size_t first=0);

{% include "directives_cpp/DynamicStateElement.jinja2" %}

{%- else %}
  static nest::RecordablesMap<{{neuronName}}> recordablesMap_;
{%- endif %}

{%- if uses_numeric_solver %}
{%-     for s in utils.create_integrate_odes_combinations(astnode) %}
  friend int {{neuronName}}_dynamics{% if s | length > 0 %}_{{ s }}{% endif %}( double, const double ode_state[], double f[], void* pnode );
{%-     endfor %}

{%-     if paired_synapse is defined %}
{#  for neuron-synapse co-generation: separate integrator for the emulated/dummy integrate_odes() below in NeuronClass.jinja2 #}
{%-         set args = utils.resolve_variables_to_expressions(astnode, purely_numeric_state_variables_moved + analytic_state_variables_moved) %}
{%-         set ast = ASTNodeFactory.create_ast_function_call("integrate_odes", args) %}
{%-         set s = utils.integrate_odes_args_str_from_function_call(ast) %}
  friend int {{neuronName}}_dynamics{% if s | length > 0 %}_{{ s }}{% endif %}( double, const double ode_state[], double f[], void* pnode );
{%-     endif %}
{%- endif %}


{%- if norm_rng %}

{%- if nest_version.startswith("v2") %}
  librandom::NormalRandomDev normal_dev_; //!< random deviate generator
  librandom::PoissonRandomDev poisson_dev_; //!< random deviate generator
{%- else %}
  nest::normal_distribution normal_dev_; //!< random deviate generator
  nest::poisson_distribution poisson_dev_; //!< random deviate generator
{%- endif %}
{%- endif %}
{%- if has_delay_variables %}
  void update_delay_variables();

  // Getters for the delayed variables
  // These are obtained from the vector helper variables defined
  // for the state variable that is used with a delay parameter
{%-   for variable in neuron.get_state_symbols() %}
{%-     if variable.has_delay_parameter() %}
  double get_delayed_{{variable.get_symbol_name()}}() const;
{%-     endif %}
{%-   endfor %}
{%- endif %}

}; /* neuron {{neuronName}} */

inline nest_port_t {{neuronName}}::send_test_event(nest::Node& target, nest_rport_t receptor_type, nest::synindex, bool)
{
  // You should usually not change the code in this function.
  // It confirms that the target of connection @c c accepts @c {{ output_event.OutputEvent() }} on
  // the given @c receptor_type.
  {{ output_event.OutputEvent() }} e;
  e.set_sender(*this);
  return target.handles_test_event(e, receptor_type);
}
{%- if has_spike_input %}

inline nest_port_t {{neuronName}}::handles_test_event(nest::SpikeEvent&, nest_port_t receptor_type)
{
{%- if (neuron.get_multiple_receptors())|length > 1 or neuron.is_multisynapse_spikes() %}
    assert( B_.spike_inputs_.size() == NUM_SPIKE_RECEPTORS );
    if ( receptor_type < MIN_SPIKE_RECEPTOR or receptor_type >= MAX_SPIKE_RECEPTOR )
    {
      throw nest::UnknownReceptorType( receptor_type, get_name() );
    }
    return receptor_type - MIN_SPIKE_RECEPTOR;
{%- else %}
    // You should usually not change the code in this function.
    // It confirms to the connection management system that we are able
    // to handle @c SpikeEvent on port 0. You need to extend the function
    // if you want to differentiate between input ports.
    if (receptor_type != 0)
    {
      throw nest::UnknownReceptorType(receptor_type, get_name());
    }
    return 0;
{%- endif %}
}
{%- endif %}
{%- if has_continuous_input %}

inline nest_port_t {{neuronName}}::handles_test_event(nest::CurrentEvent&, nest_port_t receptor_type)
{
  // You should usually not change the code in this function.
  // It confirms to the connection management system that we are able
  // to handle @c CurrentEvent on port 0. You need to extend the function
  // if you want to differentiate between input ports.
  if (receptor_type != 0)
  {
    throw nest::UnknownReceptorType(receptor_type, get_name());
  }
  return 0;
}
{%- endif %}

inline nest_port_t {{neuronName}}::handles_test_event(nest::DataLoggingRequest& dlr, nest_port_t receptor_type)
{
  // You should usually not change the code in this function.
  // It confirms to the connection management system that we are able
  // to handle @c DataLoggingRequest on port 0.
  // The function also tells the built-in UniversalDataLogger that this node
  // is recorded from and that it thus needs to collect data during simulation.
  if (receptor_type != 0)
  {
    throw nest::UnknownReceptorType(receptor_type, get_name());
  }

  return B_.logger_.connect_logging_device(dlr, recordablesMap_);
}

inline void {{neuronName}}::get_status(DictionaryDatum &__d) const
{
  // parameters
{%- for variable_symbol in neuron.get_parameter_symbols() %}
{%-     set variable = utils.get_parameter_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     filter indent(2) %}
{%-         include "directives_cpp/WriteInDictionary.jinja2" %}
{%-     endfilter %}
{%- endfor %}

  // initial values for state variables in ODE or kernel
{%- for variable_symbol in neuron.get_state_symbols() %}
{%-     set variable = utils.get_state_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     if not is_delta_kernel(neuron.get_kernel_by_name(variable_symbol.name)) %}
{%-     filter indent(2) %}
{%-             include "directives_cpp/WriteInDictionary.jinja2" %}
{%-     endfilter %}
{%-     endif -%}
{%- endfor %}

  {{neuron_parent_class}}::get_status( __d );

{%- if (neuron.get_multiple_receptors())|length > 1 or neuron.is_multisynapse_spikes() %}
  DictionaryDatum __receptor_type = new Dictionary();
{%-   for key, ports in utils.get_spike_input_ports_in_pairs(neuron).items() %}
{%-   set ns = namespace(rport=key) %}
{%-     for port in ports  %}
{%-       if not port.has_vector_parameter() %}
    ( *__receptor_type )[ "{{port.get_symbol_name().upper()}}" ] = {{ns.rport + 1}};
{%-       else %}
{%-       set size = utils.get_numeric_vector_size(port) %}
{%-         for i in range(size)  %}
    ( *__receptor_type )[ "{{port.get_symbol_name().upper()}}_{{i}}" ] = {{ns.rport + i + 1}},
{%-         endfor %}
{%-       endif %}
{%-     endfor %}
{%-   endfor %}
    ( *__d )[ "receptor_types" ] = __receptor_type;
{%- endif %}

  (*__d)[nest::names::recordables] = recordablesMap_.get_list();
{%- if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}
  def< double >(__d, nest::{{ neuronName }}_names::gsl_abs_error_tol, P_.__gsl_abs_error_tol);
  if ( P_.__gsl_abs_error_tol <= 0. ){
    throw nest::BadProperty( "The gsl_abs_error_tol must be strictly positive." );
  }
  def< double >(__d, nest::{{ neuronName }}_names::gsl_rel_error_tol, P_.__gsl_rel_error_tol);
  if ( P_.__gsl_rel_error_tol < 0. ){
    throw nest::BadProperty( "The gsl_rel_error_tol must be zero or positive." );
  }
{%-     endif %}
{%- endif %}
}

inline void {{neuronName}}::set_status(const DictionaryDatum &__d)
{
  // parameters
{%- for variable_symbol in neuron.get_parameter_symbols() %}
{%-     set variable = utils.get_parameter_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     filter indent(2) %}
{%-         include "directives_cpp/ReadFromDictionaryToTmp.jinja2" %}
{%-     endfilter %}
{%- endfor %}

  // initial values for state variables in ODE or kernel
{%- for variable_symbol in neuron.get_state_symbols() %}
{%-     set variable = utils.get_state_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     if not is_delta_kernel(neuron.get_kernel_by_name(variable_symbol.name)) %}
{%-         filter indent(2) %}
{%-             include "directives_cpp/ReadFromDictionaryToTmp.jinja2" %}
{%-         endfilter %}
{%-     endif %}
{%- endfor %}

  // We now know that (ptmp, stmp) are consistent. We do not
  // write them back to (P_, S_) before we are also sure that
  // the properties to be set in the parent class are internally
  // consistent.
  {{neuron_parent_class}}::set_status(__d);

  // if we get here, temporaries contain consistent set of properties
{%- for variable_symbol in neuron.get_parameter_symbols() -%}
{%-     set variable = utils.get_parameter_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     filter indent(2) %}
{%-         include "directives_cpp/AssignTmpDictionaryValue.jinja2" -%}
{%-     endfilter %}
{%- endfor -%}

{%- for variable_symbol in neuron.get_state_symbols() -%}
{%-     set variable = utils.get_state_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
{%-     if not is_delta_kernel(neuron.get_kernel_by_name(variable_symbol.name)) %}
{%-         filter indent(2) %}
{%-             include "directives_cpp/AssignTmpDictionaryValue.jinja2" %}
{%-         endfilter %}
{%-     endif %}
{%- endfor %}

{% for invariant in neuron.get_parameter_invariants() %}
  if ( !({{ printer.print(invariant) }}) )
  {
    throw nest::BadProperty("The constraint '{{ nestml_printer.print(invariant) }}' is violated!");
  }
{%- endfor %}

{% if uses_numeric_solver %}
{%-     if numeric_solver == "rk45" %}
  updateValue< double >(__d, nest::{{ neuronName }}_names::gsl_abs_error_tol, P_.__gsl_abs_error_tol);
  if ( P_.__gsl_abs_error_tol <= 0. )
  {
    throw nest::BadProperty( "The gsl_abs_error_tol must be strictly positive." );
  }
  updateValue< double >(__d, nest::{{ neuronName }}_names::gsl_rel_error_tol, P_.__gsl_rel_error_tol);
  if ( P_.__gsl_rel_error_tol < 0. )
  {
    throw nest::BadProperty( "The gsl_rel_error_tol must be zero or positive." );
  }
{%-     endif %}
{%- endif %}

  // recompute internal variables in case they are dependent on parameters or state that might have been updated in this call to set_status()
  recompute_internal_variables();
};



{%- if use_gap_junctions %}
inline bool
{{neuronName}}::wfr_update( nest::Time const& origin, const long from, const long to )
{
  State_ old_state = S_; // save state before wfr_update
  const bool wfr_tol_exceeded = update_( origin, from, to, true );
  S_ = old_state; // restore old state

  return not wfr_tol_exceeded;
}

inline nest_port_t
{{neuronName}}::handles_test_event( nest::GapJunctionEvent&, nest_rport_t receptor_type )
{
  if ( receptor_type != 0 )
  {
    throw nest::UnknownReceptorType( receptor_type, get_name() );
  }
  return 0;
}
{%- endif %}



#endif /* #ifndef {{neuronName.upper()}} */
{# leave this comment here to ensure newline is generated at end of file -#}
