{#-
SynapseHeader.h.jinja2

This file is part of NEST.

Copyright (C) 2004 The NEST Initiative

NEST is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 2 of the License, or
(at your option) any later version.

NEST is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with NEST.  If not, see <http://www.gnu.org/licenses/>.
#}
{%- if tracing %}/* generated by {{self._TemplateReference__context.name}} */ {% endif -%}
/**
 *  {{synapseName}}.h
 *
 *  This file is part of NEST.
 *
 *  Copyright (C) 2004 The NEST Initiative
 *
 *  NEST is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 2 of the License, or
 *  (at your option) any later version.
 *
 *  NEST is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with NEST.  If not, see <http://www.gnu.org/licenses/>.
 *
 *  Generated from NESTML at time: {{now}}
**/

#ifndef {{synapseName.upper()}}_H
#define {{synapseName.upper()}}_H

// C++ includes:
#include <cmath>

// Includes from nestkernel:
#include "common_synapse_properties.h"
#include "connection.h"
#include "connector_model.h"
#include "event.h"
{%- if norm_rng %}

// Includes for random number generator
#if NEST2_COMPAT
#include "normal_randomdev.h"
#include "uniform_randomdev.h"
#else
#include <random>
#endif
{%- endif %}
{%- if vt_ports is defined and vt_ports|length > 0  %}
// Includes for volume transmitter
#include "volume_transmitter.h"
{%- endif %}


// Includes from sli:
#include "dictdatum.h"
#include "dictutils.h"

/** @BeginDocumentation
{{ synapse.print_comment() }}
**/

#define POST_NEURON_TYPE {{ paired_neuron }}

//#define DEBUG

namespace nest
{

namespace {{names_namespace}}
{
{%- if synapse.get_state_symbols()|length > 0 %}
{%- for sym in synapse.get_state_symbols() %}
    const Name _{{sym.get_symbol_name()}}( "{{sym.get_symbol_name()}}" );
{%- endfor %}
{%- endif %}
{%- if synapse.get_parameter_symbols()|length > 0 %}
{%- for sym in synapse.get_parameter_symbols() %}
    const Name _{{sym.get_symbol_name()}}( "{{sym.get_symbol_name()}}" );
{%- endfor %}
{%- endif %}
}

class {{synapseName}}CommonSynapseProperties : public CommonSynapseProperties {
public:

    {{synapseName}}CommonSynapseProperties()
    : CommonSynapseProperties()
    {
{%- filter indent(width=8) %}
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-     if isHomogeneous %}
{%-         with variable = parameter %}
{%-             include "directives/CommonPropertiesDictionaryMemberInitialization.jinja2" %}
{%-         endwith %}
{%-     endif %}
{%- endfor %}
{%- endfilter %}
    }

    /**
     * Get all properties and put them into a dictionary.
     */
    void get_status( DictionaryDatum& d ) const
    {
        CommonSynapseProperties::get_status( d );

{%- filter indent(width=8) %}
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-     if isHomogeneous %}
{%-         set namespaceName = parameter.get_namespace_decorator("nest") %}
{%-         if namespaceName == '' %}
{{ raise('nest::names decorator is required for parameter "%s" when used in a common properties class' % names.name(parameter)) }}
{%-         endif %}
{%-         with variable = parameter %}
{%-             include "directives/CommonPropertiesDictionaryWriter.jinja2" %}
{%-         endwith %}
{%-     endif %}
{%- endfor %}
{%- endfilter %}
    }


    /**
     * Set properties from the values given in dictionary.
     */
    void set_status( const DictionaryDatum& d, ConnectorModel& cm )
    {
      CommonSynapseProperties::set_status( d, cm );

{%- filter indent(width=8) %}
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-     if isHomogeneous %}
{%-         set namespaceName = parameter.get_namespace_decorator("nest") %}
{%-         if (namespaceName == '') %}
        {{ raise('nest::names decorator is required for parameter "%s" when used in a common properties class' % names.name(parameter)) }}
{%-         endif %}
{%-         with variable = parameter %}
{%-             include "directives/CommonPropertiesDictionaryReader.jinja2" %}
{%-         endwith %}
{%-     endif %}
{%- endfor %}
{%- endfilter %}

{%- if vt_ports is defined and vt_ports|length > 0  %}
      long vtnode_id;
      if ( updateValue< long >( d, names::vt, vtnode_id ) )
      {
        const thread tid = kernel().vp_manager.get_thread_id();
        Node* vt = kernel().node_manager.get_node_or_proxy( vtnode_id, tid );
        vt_ = dynamic_cast< volume_transmitter* >( vt );
        if ( vt_ == 0 )
        {
          throw BadProperty( "Neuromodulatory source must be volume transmitter" );
        }
      }
{%- endif %}
    }

    // N.B.: we define all parameters as public for easy reference conversion later on.
    // This may or may not benefit performance (TODO: compare with inline getters/setters)

{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-     if (isHomogeneous) %}
{%-         set parameterName = names.name(parameter) %}
    {{declarations.print_variable_type(parameter)}} {{parameter.get_symbol_name()}};
{%-     endif %}
{%- endfor %}

{%- if vt_ports is defined and vt_ports|length > 0  %}
    volume_transmitter* vt_;

    inline long get_vt_node_id() const
    {
      if ( vt_ != 0 )
      {
        return vt_->get_node_id();
      }
      else
      {
        return -1;
      }
    }

{%- endif %}
};


template < typename targetidentifierT >
class {{synapseName}} : public Connection< targetidentifierT >
{
{%- if vt_ports is defined and vt_ports|length > 0  %}
public:
  void trigger_update_weight( thread t,
    const std::vector< spikecounter >& vt_spikes,
    double t_trig,
    const {{synapseName}}CommonSynapseProperties& cp );
{%- endif %}
private:

//  double *weight_;
  double t_lastspike_;
{%- if vt_ports is defined and vt_ports|length > 0  %}
  // time of last update, which is either time of last presyn. spike or
  // time-driven update
  double t_last_update_;

  // vt_spikes_idx_ refers to the vt spike that has just been processes
  // after trigger_update_weight a pseudo vt spike at t_trig is stored at
  // index 0 and vt_spikes_idx_ = 0
  index vt_spikes_idx_;
{%- endif %}



  /**
  * Dynamic state of the synapse.
  *
  *
  * These are the state variables that are advanced in time by calls to
  * @c update(). In many models, some or all of them can be set by the user
  * through @c SetStatus. The state variables are initialized from the model
  * prototype when the node is created. State variables are reset by @c ResetNetwork.
  *
  * @note State_ need neither copy constructor nor @c operator=(), since
  *       all its members are copied properly by the default copy constructor
  *       and assignment operator. Important:
  *       - If State_ contained @c Time members, you need to define the
  *         assignment operator to recalibrate all members of type @c Time . You
  *         may also want to define the assignment operator.
  *       - If State_ contained members that cannot copy themselves, such
  *         as C-style arrays, you need to define the copy constructor and
  *         assignment operator to copy those members.
  */
  struct State_{
{%- if not uses_numeric_solver %}
{%-   filter indent(4,True) %}
{%-   for variable in synapse.get_state_symbols() %}
{%-     include "directives/MemberDeclaration.jinja2" %}
{%-   endfor %}
{%-   endfilter %}
{%- else %}
    //! Symbolic indices to the elements of the state vector y
    enum StateVecElems{
{# N.B. numeric solver contains all state variables, including those that will be solved by analytic solver#}
{%-   if uses_numeric_solver %}
      // numeric solver state variables
{%-     for variable_name in numeric_state_variables: %}
      {{variable_name}},
{%-     endfor %}
{%-   endif %}
      STATE_VEC_SIZE
    };
    //! state vector, must be C-array for GSL solver
    double ode_state[STATE_VEC_SIZE];

    // state variables from state block
{%-   filter indent(4,True) %}
{%-   for variable in synapse.get_state_symbols() %}
{%-     include "directives/MemberDeclaration.jinja2" %}
{%-   endfor %}
{%-   endfilter %}
{%- endif %}

    State_() {};
  };

  // -------------------------------------------------------------------------
  //   Getters/setters for state block
  // -------------------------------------------------------------------------

{% filter indent(2, True) -%}
{%- for state in synapse.get_state_symbols() %}
{%-    with variable = state %}
{%-       include "directives/MemberVariableGetterSetter.jinja2" %}
{%-    endwith %}
{%- endfor %}
{%- endfilter %}
  // -------------------------------------------------------------------------
  //   Getters/setters for parameters
  // -------------------------------------------------------------------------




{% filter indent(2, True) -%}
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-     if (not isHomogeneous) %}
{%-     with variable = parameter %}
{%-        include "directives/MemberVariableGetterSetter.jinja2" %}
{%-     endwith %}
{%-     endif %}
{%- endfor %}
{%- endfilter %}
  // -------------------------------------------------------------------------
  //   Getters/setters for inline expressions
  // -------------------------------------------------------------------------
{% filter indent(2, True) -%}
{%- for funcsym in synapse.get_inline_expression_symbols() %}
{%-    with variable = funcsym %}
{%-        include "directives/MemberVariableGetterSetter.jinja2" %}
{%-    endwith %}
{%- endfor %}
{%- endfilter %}
  // -------------------------------------------------------------------------
  //   Function declarations
  // -------------------------------------------------------------------------

{% filter indent(2) -%}
{% for function in synapse.get_functions() %}
  {{printer.print_function_declaration(function)}};
{% endfor %}
{%- endfilter %}

  /**
  * Free parameters of the synapse.
  *
  {{synapse.print_parameter_comment("*")}}
  *
  * These are the parameters that can be set by the user through @c SetStatus.
  * They are initialized from the model prototype when the node is created.
  * Parameters do not change during calls to @c update() and are not reset by
  * @c ResetNetwork.
  *
  * @note Parameters_ need neither copy constructor nor @c operator=(), since
  *       all its members are copied properly by the default copy constructor
  *       and assignment operator. Important:
  *       - If Parameters_ contained @c Time members, you need to define the
  *         assignment operator to recalibrate all members of type @c Time . You
  *         may also want to define the assignment operator.
  *       - If Parameters_ contained members that cannot copy themselves, such
  *         as C-style arrays, you need to define the copy constructor and
  *         assignment operator to copy those members.
  */
  struct Parameters_{
{%- filter indent(4,True) %}
{%- for variable in synapse.get_parameter_symbols() %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in variable.get_decorators() %}
{%-     if (not isHomogeneous) %}
{%-   include 'directives/MemberDeclaration.jinja2' %}
{%-     else %}
    // N.B. the parameter `{{names.name(variable)}}` is defined in the common properties class
{%-     endif %}
{%- endfor %}
{%- endfilter %}

{% if uses_numeric_solver %}
    double __gsl_error_tol;
{% endif %}

    /** Initialize parameters to their default values. */
    Parameters_() {};
  };

  /**
  * Internal variables of the synapse.
  *
  {{synapse.print_internal_comment('*')}}
  *
  * These variables must be initialized by @c calibrate, which is called before
  * the first call to @c update() upon each call to @c Simulate.
  * @node Variables_ needs neither constructor, copy constructor or assignment operator,
  *       since it is initialized by @c calibrate(). If Variables_ has members that
  *       cannot destroy themselves, Variables_ will need a destructor.
  */
  struct Variables_ {
{%- for variable in synapse.get_internal_symbols() %}
{%-     filter indent(4,True) %}
{%-     include "directives/MemberDeclaration.jinja2" %}
{%-     endfilter %}
{%- endfor %}
  };

  Parameters_ P_;  //!< Free parameters.
  State_      S_;  //!< Dynamic state.
  Variables_  V_;  //!< Internal Variables
{#
  /**
   * All parameters marked as homogeneous will go into a CommonPropertiesDictionary
  **/

  {% for parameter in synapse.get_parameter_symbols() %}
    {%- set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
    {%- if (isHomogeneous) %}
    // {-{ assert ( decl.get_variables()|length == 1 ) }-}
    {%- set parameterName = names.name(parameter) %}
    !!! homeogensou decl -->> {{parameterName}}
    {%- endif %}
  {%- endfor %}

    {%- set isHeterogeneous = PyNestMLLexer["DECORATOR_HETEROGENEOUS"] in parameter.get_decorators() %}
    {%- if (isHeterogeneous) %}
    {%- set parameterName = decl.get_variables()[0].name %}
  heterogen decl -->> {{parameterName}}
    {%- endif %}
#}

public:

  // this line determines which common properties to use
  typedef {{synapseName}}CommonSynapseProperties CommonPropertiesType;

  typedef Connection< targetidentifierT > ConnectionBase;

  /**
  * Default constructor.
  *
  * Sets default values for all parameters (skipping common properties).
  *
  * Needed by GenericConnectorModel.
  */
  {{synapseName}}();


  /**
  * Copy constructor from a property object.
  *
  * Sets default values for all parameters (skipping common properties).
  *
  * Needs to be defined properly in order for GenericConnector to work.
  */
  {{synapseName}}( const {{synapseName}}& rhs );


{%- if vt_ports is defined and vt_ports|length > 0  %}
{%- set vt_port = vt_ports[0] %}
  void process_{{vt_port}}_spikes_( const std::vector< spikecounter >& vt_spikes,
      double t0,
      double t1,
      const {{synapseName}}CommonSynapseProperties& cp );

  inline void
  update_internal_state_(double t_start, double timestep, const {{synapseName}}CommonSynapseProperties& cp);
{%- endif %}

    void init_internals_block_symbols();

  // Explicitly declare all methods inherited from the dependent base
  // ConnectionBase. This avoids explicit name prefixes in all places these
  // functions are used. Since ConnectionBase depends on the template parameter,
  // they are not automatically found in the base class.
  using ConnectionBase::get_delay_steps;
  using ConnectionBase::set_delay_steps;
  using ConnectionBase::get_delay;
  using ConnectionBase::set_delay;
  using ConnectionBase::get_rport;
  using ConnectionBase::get_target;


  class ConnTestDummyNode : public ConnTestDummyNodeBase
  {
  public:
    // Ensure proper overriding of overloaded virtual functions.
    // Return values from functions are ignored.
    using ConnTestDummyNodeBase::handles_test_event;
    port
    handles_test_event( SpikeEvent&, rport )
    {
      return invalid_port_;
    }
    port
    handles_test_event( RateEvent&, rport )
    {
      return invalid_port_;
    }
    port
    handles_test_event( DataLoggingRequest&, rport )
    {
      return invalid_port_;
    }
    port
    handles_test_event( CurrentEvent&, rport )
    {
      return invalid_port_;
    }
    port
    handles_test_event( ConductanceEvent&, rport )
    {
      return invalid_port_;
    }
    port
    handles_test_event( DoubleDataEvent&, rport )
    {
      return invalid_port_;
    }
    port
    handles_test_event( DSSpikeEvent&, rport )
    {
      return invalid_port_;
    }
    port
    handles_test_event( DSCurrentEvent&, rport )
    {
      return invalid_port_;
    }
  };


  /**
   * Get named parameter from the `Parameter_` struct
  **/
/*  template < typename T >
  T* get_named_parameter(const Name &n) {
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set namespaceName = parameter.get_namespace_decorator("nest") %}
    if (n == names::{{namespaceName}}) {
      return &{{printer.print_origin(parameter)}}{{names.name(parameter)}}; // type: {- {declarations.print_variable_type(parameter)} -}
    }
{%- endfor %}

    assert(false);    // unknown name requested
  }
*/
  /**
   *  special case for weights in NEST: only in case a NESTML state variable was decorated by @nest::weight
  **/
  inline void set_weight(double w) {
{%- for init in synapse.get_state_symbols() %}
{%-     with variable = init %}
{%-         if variable.get_namespace_decorator("nest")|length > 0 %}
    // special case for variable marked with @nest::weight decorator
{%-             set nest_namespace_name = variable.get_namespace_decorator("nest") %}
{%-             if nest_namespace_name == "weight" %}
    {{names.setter(variable)}}(w);
    return;
{%-             endif %}
{%-         endif %}
{%-     endwith %}
{%- endfor %}

    // no variable was decorated by @nest::weight, so no "weight" defined from the NEST perspective
    assert(0);
  }
{#
/*

  {{printer.print_origin(weight_parameter)}}{{names.name(weight_parameter)}} = w; // type: {{declarations.print_variable_type(weight_parameter)}}

{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set namespaceName = parameter.get_namespace_decorator('nest') %}
{%-     if (namespaceName == 'weight') %}
{%-         set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-         if isHomogeneous %}
    throw BadProperty(
      "Setting of individual weights is not possible! The common weights can "
      "be changed via CopyModel()." );
{%-         else %}
    {{printer.print_origin(parameter)}}{{names.name(parameter)}} = w; // type: {{declarations.print_variable_type(parameter)}}
{%-         endif %}
{%-     endif %}
{%- endfor %}
  }
*/
#}

/*  inline double get_weight() {
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set namespaceName = parameter.get_namespace_decorator('nest') %}
{%-     if (namespaceName == 'weight') %}
{%-         set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-         if isHomogeneous %}
    return cp.{{printer.print_origin(parameter)}}{{names.name(parameter)}}; // type: {{declarations.print_variable_type(parameter)}}   // XXX: replace with get_status or throw()
{%-         else %}
    return {{printer.print_origin(parameter)}}{{names.name(parameter)}}; // type: {{declarations.print_variable_type(parameter)}}
{%-         endif %}
{%-     endif %}
{%- endfor %}
  }
*/
  void
  check_connection( Node& s,
    Node& t,
    rport receptor_type,
    const CommonPropertiesType& cp )
  {
    ConnTestDummyNode dummy_target;
    ConnectionBase::check_connection_( dummy_target, s, t, receptor_type );

{%- if paired_neuron is defined %}
    try {
      dynamic_cast<{{paired_neuron}}&>(t);
    }
    catch (std::bad_cast &exp) {
      std::cout << "wrong type of neuron connected! Synapse '{{synapseName}}' will only work with neuron '{{paired_neuron}}'.\n";
      exit(1);
    }
{%- endif %}
{%- if vt_ports is defined and vt_ports|length > 0  %}

    if ( cp.vt_ == 0 )
    {
      throw BadProperty( "No volume transmitter has been assigned to the dopamine synapse." );
    }
{%- endif %}

    t.register_stdp_connection( t_lastspike_ - get_delay(), get_delay() );
  }

  void
  send( Event& e, const thread tid, const {{synapseName}}CommonSynapseProperties& cp )
  {
    const double __resolution = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the resolution() function

    auto get_thread = [tid]()
    {
        return tid;
    };

    // synapse STDP depressing/facilitation dynamics
    const double __t_spike = e.get_stamp().get_ms();
#ifdef DEBUG
    std::cout << "{{synapseName}}::send(): handling pre spike at t = " << __t_spike << std::endl;
#endif

{%- if vt_ports is defined and vt_ports|length > 0  %}
  // get history of volume transmitter spikes
  const std::vector< spikecounter >& vt_spikes = cp.vt_->deliver_spikes();

{%- endif %}
    // use accessor functions (inherited from Connection< >) to obtain delay and target
{%- if paired_neuron is not none and paired_neuron|length > 0 %}
    {{paired_neuron}}* __target = static_cast<{{paired_neuron}}*>(get_target(tid));
    assert(__target != NULL);
{%- else %}
    Node* __target = get_target( tid );
{%- endif %}
    const double __dendritic_delay = get_delay();
    const bool pre_before_post_update = {{pre_before_post_update}};
    bool pre_before_post_flag = false;

    if (t_lastspike_ < 0.)
    {
        // this is the first presynaptic spike to be processed
        t_lastspike_ = 0.;
    }

{%- if paired_neuron is not none and paired_neuron|length > 0 %}
    double timestep = 0;

    {
      // get spike history in relevant range (t1, t2] from post-synaptic neuron
      std::deque< histentry__{{paired_neuron}} >::iterator start;
      std::deque< histentry__{{paired_neuron}} >::iterator finish;
{%- if vt_ports is defined and vt_ports|length > 0  %}
      double t0 = t_last_update_;
{%- endif %}
      // For a new synapse, t_lastspike_ contains the point in time of the last
      // spike. So we initially read the
      // history(t_last_spike - dendritic_delay, ..., T_spike-dendritic_delay]
      // which increases the access counter for these entries.
      // At registration, all entries' access counters of
      // history[0, ..., t_last_spike - dendritic_delay] have been
      // incremented by Archiving_Node::register_stdp_connection(). See bug #218 for
      // details.
      __target->get_history__( t_lastspike_ - __dendritic_delay,
        __t_spike - __dendritic_delay,
        &start,
        &finish );
      // facilitation due to post-synaptic spikes since last pre-synaptic spike
      while ( start != finish )
      {
        {%- if vt_ports is defined and vt_ports|length > 0  %}
        {%- set vt_port = vt_ports[0] %}
        process_{{vt_port}}_spikes_( vt_spikes, t0, start->t_ + __dendritic_delay, cp );
        t0 = start->t_ + __dendritic_delay;
        {%- endif %}
        const double minus_dt = t_lastspike_ - ( start->t_ + __dendritic_delay );
        // get_history() should make sure that
        // start->t_ > t_lastspike_ - dendritic_delay, i.e. minus_dt < 0
        assert( minus_dt < -kernel().connection_manager.get_stdp_eps() );

        if (pre_before_post_update && start->t_ == __t_spike - __dendritic_delay)
        {
          pre_before_post_flag = true;
          break;  // this would in any case have been the last post spike to be processed
        }

#ifdef DEBUG
        std::cout << "\tprocessing post spike at t = " << start->t_ << std::endl;
#endif

        /**
         * update synapse internal state from `t_lastspike_` to `start->t_`
        **/

        const double old___h = V_.__h;
        V_.__h = (start->t_ + __dendritic_delay) - t_lastspike_;
        timestep += V_.__h;
        init_internals_block_symbols();
{%- filter indent(8, True) %}
{%- with analytic_state_variables_ = analytic_state_variables %}
{%-     include "directives/AnalyticIntegrationStep_begin.jinja2" %}
{%- endwith %}
{%- if uses_numeric_solver %}
{%-     include "directives/GSLIntegrationStep.jinja2" %}
{%- endif %}
{%- with analytic_state_variables_ = analytic_state_variables %}
{%-     include "directives/AnalyticIntegrationStep_end.jinja2" %}
{%- endwith %}
{%- endfilter %}
        V_.__h = old___h;
        init_internals_block_symbols();  // XXX: can be skipped?

        const double _tr_t = start->t_;

// #ifdef DEBUG
//         std::cout << "\tFacilitating, old w = " << S_.w << "\n";
// #endif
#ifdef DEBUG
        std::cout << "\tFacilitating from c = " << S_.c << " (using trace = " << S_.pre_tr << ")";
#endif

{%- filter indent(6, True) %}
{%- if post_ports is defined %}
{%-     for post_port in spiking_post_ports %}
/**
 *  NESTML generated onReceive code block for postsynaptic port "{{post_port}}" begins here!
**/

{%-         set dynamics = synapse.get_on_receive_block(post_port) %}
{%-         with ast = dynamics.get_block() %}
{%-             include "directives/Block.jinja2" %}
{%-         endwith %}
{%-     endfor %}
{%- endif %}
{%- endfilter %}

// #ifdef DEBUG
//       std::cout << "\t--> new w = " << S_.w << std::endl;
// #endif
#ifdef DEBUG
      std::cout << " to " << S_.c << std::endl;
#endif

        /**
         * internal state has now been fully updated to `start->t_ + __dendritic_delay`
        **/

        t_lastspike_ = start->t_ + __dendritic_delay;
        ++start;
      }
    }
{%- endif %}

    /**
     * update synapse internal state from `t_lastspike_` to `__t_spike`
    **/
{%- if vt_ports is defined and vt_ports|length > 0  %}
{%- set vt_port = vt_ports[0] %}
    process_{{vt_port}}_spikes_( vt_spikes, t_lastspike_, __t_spike, cp );
{%- endif %}

    const double old___h = V_.__h;
    V_.__h = __t_spike - t_lastspike_;
    if (V_.__h > 1E-12) {
      init_internals_block_symbols();
{%- filter indent(6, True) %}
{%- with analytic_state_variables_ = analytic_state_variables %}
{%-     include "directives/AnalyticIntegrationStep_begin.jinja2" %}
{%- endwith %}
{%- if uses_numeric_solver %}
{%-     include "directives/GSLIntegrationStep.jinja2" %}
{%- endif %}
{%- with analytic_state_variables_ = analytic_state_variables %}
{%-     include "directives/AnalyticIntegrationStep_end.jinja2" %}
{%- endwith %}
{%- endfilter %}
    }
    V_.__h = old___h;
    init_internals_block_symbols();  // XXX: can be skipped?


    const double _tr_t = __t_spike - __dendritic_delay;

#ifdef DEBUG
    std::cout << "\tDepressing, old w = " << S_.w << "\n";
#endif
    //std::cout << "r2 = " << get_tr_r2() << std::endl;

{%- filter indent(4, True) %}
{%- for pre_port in pre_ports %}
/**
 *  NESTML generated onReceive code block for presynaptic port "{{pre_port}}" begins here!
**/

{%-     set dynamics = synapse.get_on_receive_block(pre_port) %}
{%-     with ast = dynamics.get_block() %}
{%-         include "directives/Block.jinja2" %}
{%-     endwith %}
{%- endfor %}
{%- endfilter %}

#ifdef DEBUG
    std::cout <<"\t-> new w = " << S_.w << std::endl;
#endif

    /**
     *  update all convolutions with pre spikes
    **/

{# {%- for inputLine in synapse.get_spike_buffers() %} #}
{%- for spike_updates_for_port in spike_updates.values() %}
{%-     for spike_update in spike_updates_for_port -%}
    // XXX: TODO: increment with initial value instead of 1
    S_.{{names.name(synapse.get_state_blocks().get_scope().resolve_to_symbol(spike_update.get_variable().get_complete_name(), SymbolKind.VARIABLE))}} += 1.;
{%-     endfor %}
{%- endfor %}

    /**
     *  in case pre and post spike time coincide and pre update takes priority
    **/

    if (pre_before_post_flag)
    {
{%- filter indent(6, True) %}
{%- if post_ports is defined %}
{%-     for post_port in spiking_post_ports %}
/**
 *  NESTML generated onReceive code block for postsynaptic port "{{post_port}}" begins here!
**/
#ifdef DEBUG
std::cout << "\tFacilitating from c = " << S_.c << " (using trace = " << S_.pre_tr << ")";
#endif
{%-         set dynamics = synapse.get_on_receive_block(post_port) %}
{%-         with ast = dynamics.get_block() %}
{%-             include "directives/Block.jinja2" %}
{%-         endwith %}
{%-     endfor %}
{%- endif %}
{%- endfilter %}
#ifdef DEBUG
      std::cout << " to " << S_.c << std::endl;
#endif
    }

    /**
     *  synapse internal state has now been fully updated to `__t_spike`
    **/

    t_lastspike_ = __t_spike;
  }

  void get_status( DictionaryDatum& d ) const;

  void set_status( const DictionaryDatum& d, ConnectorModel& cm );

{%- if norm_rng %}

#if NEST2_COMPAT
  librandom::NormalRandomDev normal_dev_; //!< random deviate generator
#else
  nest::normal_distribution normal_dev_; //!< random deviate generator
#endif
{%- endif %}
};


{%- if vt_ports is defined and vt_ports|length > 0  %}
{%- set vt_port = vt_ports[0] %}
template < typename targetidentifierT >
void
{{synapseName}}< targetidentifierT >::process_{{vt_port}}_spikes_( const std::vector< spikecounter >& vt_spikes,
    double t0,
    double t1,
    const {{synapseName}}CommonSynapseProperties& cp )
{
#ifdef DEBUG
  std::cout << "\tIn process_{{vt_port}}_spikes_(): t0 = " << t0 << ", t1 = " << t1 << "\n";
#endif
  // process dopa spikes in (t0, t1]
  // propagate weight from t0 to t1
  if ( ( vt_spikes.size() > vt_spikes_idx_ + 1 )
    && ( t1 - vt_spikes[ vt_spikes_idx_ + 1 ].spike_time_ > -1.0 * kernel().connection_manager.get_stdp_eps() ) )
  {
    // there is at least 1 dopa spike in (t0, t1]
    // propagate up to first dopa spike
#ifdef DEBUG
  std::cout << "\t\tHandling (1) spike at t = " << vt_spikes[ vt_spikes_idx_ +1].spike_time_ << "\n";
#endif
    update_internal_state_(t0, vt_spikes[ vt_spikes_idx_ + 1 ].spike_time_ - t0, cp );
    ++vt_spikes_idx_;
#ifdef DEBUG
std::cout<<"\t\tIncrementing n_ from " << S_.n << " to " ;
#endif
    /**
     *  NESTML generated onReceive code block for volume transmitter synaptic port "{{vt_port}}" begins here!
    **/

{%- filter indent(4, True) %}
{%-     set dynamics = synapse.get_on_receive_block(vt_port) %}
{%-     with ast = dynamics.get_block() %}
{%-         include "directives/Block.jinja2" %}
{%-     endwith %}
{%- endfilter %}
#ifdef DEBUG
std::cout << S_.n << "\n";
#endif
    // process remaining dopa spikes in (t0, t1]
    double cd;
    while ( ( vt_spikes.size() > vt_spikes_idx_ + 1 )
      && ( t1 - vt_spikes[ vt_spikes_idx_ + 1 ].spike_time_ > -1.0 * kernel().connection_manager.get_stdp_eps() ) )
    {
#ifdef DEBUG
  std::cout << "\t\tHandling (2) spike at t = " << vt_spikes[ vt_spikes_idx_ ].spike_time_ << "\n";
#endif
      // propagate up to next dopa spike
      update_internal_state_(vt_spikes[ vt_spikes_idx_ ].spike_time_,
                             vt_spikes[ vt_spikes_idx_ + 1 ].spike_time_ - vt_spikes[ vt_spikes_idx_ ].spike_time_,
                             cp );
      ++vt_spikes_idx_;

      /**
       *  NESTML generated onReceive code block for volume transmitter synaptic port "{{vt_port}}" begins here!
      **/
#ifdef DEBUG
std::cout<<"\t\tIncrementing n_ from " << S_.n << " to " ;
#endif
{%- filter indent(6, True) %}
{%-     set dynamics = synapse.get_on_receive_block(vt_port) %}
{%-     with ast = dynamics.get_block() %}
{%-         include "directives/Block.jinja2" %}
{%-     endwith %}
{%- endfilter %}
#ifdef DEBUG
std::cout << S_.n << "\n";
#endif
    }
#ifdef DEBUG
  std::cout << "\t\t3\n";
#endif

    // propagate up to t1
    update_internal_state_(vt_spikes[ vt_spikes_idx_ ].spike_time_,
                           t1 - vt_spikes[ vt_spikes_idx_ ].spike_time_,
                           cp );
  }
  else
  {
#ifdef DEBUG
  std::cout << "\t\t4: updating internal state from t0 = " << t0 << " to t1 = " << t1 << "\n";
#endif

    // no dopamine spikes in (t0, t1]
    update_internal_state_( t0, t1 - t0, cp );
  }
}
{%- endif %}


template < typename targetidentifierT >
void
{{synapseName}}< targetidentifierT >::get_status( DictionaryDatum& __d ) const
{
  ConnectionBase::get_status( __d );
  def< long >( __d, names::size_of, sizeof( *this ) );

  // parameters
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-     if (not isHomogeneous) %}
{%-         set namespaceName = parameter.get_namespace_decorator('nest') %}
{%-         if namespaceName == '' %}
{%-             with variable = parameter %}
{%-                 filter indent(2,True) %}
{%-                     include "directives/WriteInDictionary.jinja2" %}
{%-                 endfilter %}
{%-             endwith %}
{%-         else %}
  def< {{declarations.print_variable_type(parameter)}} >( __d, names::{{namespaceName}}, {{printer.print_origin(parameter)}}{{names.name(parameter)}} );
{%-         endif %}
{%-     endif %}
{%- endfor %}

  // initial values for state variables in ODE or kernel
{%- filter indent(2,True) %}
{%- for init in synapse.get_state_symbols() %}
{%-     with variable = init %}
{%-     if not is_delta_kernel(synapse.get_kernel_by_name(init.name)) %}
{%-             include "directives/WriteInDictionary.jinja2" %}
{%-             if variable.get_namespace_decorator("nest")|length > 0 %}
// special treatment for variable marked with @nest::name decorator
{%-                 set nest_namespace_name = variable.get_namespace_decorator("nest") %}
{%-                 if not variable.is_internals() %}
def<{{declarations.print_variable_type(variable)}}>(__d, names::{{nest_namespace_name}}, {{names.getter(variable)}}());
{%-                 endif %}
{%-             endif %}
{%-     endif %}
{%-     endwith %}
{%- endfor %}
{%- endfilter %}
}

template < typename targetidentifierT >
void
{{synapseName}}< targetidentifierT >::set_status( const DictionaryDatum& __d,
  ConnectorModel& cm )
{
  // parameters
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set namespaceName = parameter.get_namespace_decorator('nest') %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-     if (not isHomogeneous) %}
{%-         with variable = parameter %}
{%-             filter indent(2,True) %}
{%-             include "directives/ReadFromDictionaryToTmp.jinja2" %}
{%-             endfilter %}
{%-         endwith %}
{%-     endif %}
{%- endfor %}

  // initial values for state variables in ODE or kernel
{%- filter indent(2,True) %}
{%- for init in synapse.get_state_symbols() %}
{%-     with variable = init %}
{%-         if not is_delta_kernel(synapse.get_kernel_by_name(init.name)) %}
{%-             include "directives/ReadFromDictionaryToTmp.jinja2" %}

{%-             if variable.get_namespace_decorator("nest")|length > 0 %}
// special treatment for variables marked with @nest::name decorator
{%-                 set nest_namespace_name = variable.get_namespace_decorator("nest") %}
{#- -------- XXX: TODO: this is almost the content of directives/ReadFromDictionaryToTmp.jinja2 verbatim, refactor this ----------  #}
{%- if not variable.is_inline_expression and not variable.is_state() %}
tmp_{{names.name(variable)}} = {{names.getter(variable)}}();
updateValue<{{declarations.print_variable_type(variable)}}>(__d, "{{nest_namespace_name}}", tmp_{{names.name(variable)}});
{%- elif not variable.is_inline_expression and variable.is_state() %}
tmp_{{names.convert_to_cpp_name(variable.get_symbol_name())}} = {{names.getter(variable)}}();
updateValue<{{declarations.print_variable_type(variable)}}>(__d, "{{nest_namespace_name}}", tmp_{{names.convert_to_cpp_name(variable.get_symbol_name())}});
{%- else %}
  // ignores '{{names.name(variable)}}' {{declarations.print_variable_type(variable)}}' since it is an function and setter isn't defined
{%- endif %}
{#- -------------------------------------------------------------------------------------------------------------------------------- #}
{%-             endif %}
{%-         endif %}
{%-     endwith %}
{%- endfor %}
{%- endfilter %}


  // We now know that (ptmp, stmp) are consistent. We do not
  // write them back to (P_, S_) before we are also sure that
  // the properties to be set in the parent class are internally
  // consistent.
  ConnectionBase::set_status( __d, cm );

  // if we get here, temporaries contain consistent set of properties
  // set parameters
{%- for parameter in synapse.get_parameter_symbols() %}
{%-      set namespaceName = parameter.get_namespace_decorator('nest') %}
{%-      set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-      if (not isHomogeneous) %}
{%-          with variable = parameter %}
{%-              filter indent(2,True) %}
{%-              include "directives/AssignTmpDictionaryValue.jinja2" %}
{%-              endfilter %}
{%-         endwith %}
{%-      endif %}
{%- endfor %}

  // set state
{%- for init in synapse.get_state_symbols() %}
{%-     with variable = init %}
{%-         if not is_delta_kernel(synapse.get_kernel_by_name(init.name)) %}
{%-             filter indent(2,True) %}
{%-             include "directives/AssignTmpDictionaryValue.jinja2" %}
{%-             endfilter %}
{%-         endif %}
{%-     endwith %}
{%- endfor %}

  // check invariants
{% for invariant in synapse.get_parameter_invariants() %}
  if ( !({{printer.print_expression(invariant)}}) ) {
    throw nest::BadProperty("The constraint '{{idemPrinter.print_expression(invariant)}}' is violated!");
  }
{%- endfor %}
{% if uses_numeric_solver %}

  updateValue< double >(__d, nest::names::gsl_error_tol, P_.__gsl_error_tol);
  if ( P_.__gsl_error_tol <= 0. ){
    throw nest::BadProperty( "The gsl_error_tol must be strictly positive." );
  }
{% endif %}

  // special treatment of NEST delay
  set_delay({%- for parameter in synapse.get_parameter_symbols() %}
{%-     set namespaceName = parameter.get_namespace_decorator("nest") %}
{%-     if namespaceName == "delay" %}
{{ names.getter(parameter) }}()
{%-     endif %}
{%- endfor %});
}

/**
 * NESTML internals block symbols initialisation
**/
template < typename targetidentifierT >
void {{synapseName}}< targetidentifierT >::init_internals_block_symbols()
{
  const double __resolution = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the resolution() function

{%- for variable in synapse.get_internal_symbols() %}
{%-     if not variable.get_symbol_name() == "__h" %}
{%-         include "directives/Calibrate.jinja2" %}
{%-     endif %}
{%- endfor %}
}

/**
 * constructor
**/
template < typename targetidentifierT >
{{synapseName}}< targetidentifierT >::{{synapseName}}() : ConnectionBase()
{
  const double __resolution = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the resolution() function

{%- for parameter in synapse.get_parameter_symbols() %}
{%-     with variable = parameter %}
{%-         set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in variable.get_decorators() %}
{%-         if (not isHomogeneous) %}
{%-             include "directives/MemberInitialization.jinja2" %}
{%-         endif %}
{%-     endwith %}
{%- endfor %}

  V_.__h = nest::Time::get_resolution().get_ms();
  init_internals_block_symbols();

  // initial values for state variables in ODE or kernel
{%- for init in synapse.get_state_symbols() %}
{%-     with variable = init %}
{%-         include "directives/MemberInitialization.jinja2" %}
{%-     endwith %}
{%- endfor %}

  t_lastspike_ = 0.;
{%- if vt_ports is defined and vt_ports|length > 0  %}
  t_last_update_ = 0.;
{%- endif %}
}

/**
 * copy constructor
**/
template < typename targetidentifierT >
{{synapseName}}< targetidentifierT >::{{synapseName}}( const {{synapseName}}< targetidentifierT >& rhs )
: ConnectionBase( rhs )
{
{%- for parameter in synapse.get_parameter_symbols() %}
{%-     set isHomogeneous = PyNestMLLexer["DECORATOR_HOMOGENEOUS"] in parameter.get_decorators() %}
{%-     if (not isHomogeneous) %}
    {{printer.print_origin(parameter)}}{{names.name(parameter)}} = rhs.{{printer.print_origin(parameter)}}{{names.name(parameter)}};
{%-     endif %}
{%- endfor %}

  // state variables in ODE or kernel
{%- for init in synapse.get_state_symbols() %}
{%-     with variable = init %}
    {{printer.print_origin(variable)}}{{names.name(variable)}} = rhs.{{printer.print_origin(variable)}}{{names.name(variable)}};
{%-     endwith %}
{%- endfor %}

    //weight_ = get_named_parameter<double>(names::weight);
    //set_weight( *rhs.weight_ );
{%- if vt_ports is defined and vt_ports|length > 0  %}
    t_last_update_ = rhs.t_last_update_;
{%- endif %}
    t_lastspike_  = rhs.t_lastspike_;

    // special treatment of NEST delay
    set_delay(rhs.get_delay());
}

{%- if vt_ports is defined and vt_ports|length > 0  %}
template < typename targetidentifierT >
inline void
{{synapseName}}< targetidentifierT >::update_internal_state_(double t_start, double timestep, const {{synapseName}}CommonSynapseProperties& cp)
{
  if (timestep < 1E-12)
  {
  #ifdef DEBUG
  std::cout << "\tupdate_internal_state_() called with dt = 0\n" ;
  #endif
    return;
  }

  const double __resolution = timestep;  // do not remove, this is necessary for the resolution() function

#ifdef DEBUG
std::cout<<"\tUpdating internal state: t_start = " << t_start << ", dt = " << timestep << "\n";
std::cout << "\tUpdating state from pre_tr = " << S_.pre_tr << " to " ;
#endif
  const double old___h = V_.__h;
  V_.__h = timestep;
  init_internals_block_symbols();
{%- filter indent(2, True) %}
{%- with analytic_state_variables_ = analytic_state_variables %}
{%-     include "directives/AnalyticIntegrationStep_begin.jinja2" %}
{%- endwith %}
{%- if uses_numeric_solver %}
{%-     include "directives/GSLIntegrationStep.jinja2" %}
{%- endif %}
{%- with analytic_state_variables_ = analytic_state_variables %}
{%-     include "directives/AnalyticIntegrationStep_end.jinja2" %}
{%- endwith %}
{%- endfilter %}
    V_.__h = old___h;
    init_internals_block_symbols();  // XXX: can be skipped?
#ifdef DEBUG
 std::cout << S_.pre_tr << "\n";
 std::cout << "\tUpdating state from w = " << S_.w << " (with c = " << S_.c << ", n = " << S_.n << ", dt = " << __resolution << ") to ";
#endif
{%- if synapse.get_update_blocks() %}
{%- filter indent(2) %}
{%- set dynamics = synapse.get_update_blocks() %}
{%- with ast = dynamics.get_block() %}
{%-   include "directives/Block.jinja2" %}
{%- endwith %}
{%- endfilter %}
{%- endif %}

{%- if vt_ports is defined and vt_ports|length > 0  %}
  t_last_update_ = t_start + timestep;
{%- endif %}
}

/**
 * Update to end of timestep ``t_trig``, while processing vt spikes and post spikes
**/
template < typename targetidentifierT >
inline void
{{synapseName}}< targetidentifierT >::trigger_update_weight( thread t,
  const std::vector< spikecounter >& vt_spikes,
  const double t_trig,
  const CommonPropertiesType& cp )
{
  // propagate all state variables in the synapse to time t_trig
#ifdef DEBUG
    std::cout << "\n{{synapseName}}::trigger_update_weight(): t = " << t_trig << std::endl;
#endif
  // purely dendritic delay
  double dendritic_delay = get_delay();

  // get spike history in relevant range (t_last_update, t_trig] from postsyn. neuron
  std::deque< histentry__{{paired_neuron}} >::iterator start;
  std::deque< histentry__{{paired_neuron}} >::iterator finish;
  static_cast<{{paired_neuron}}*>(get_target(t))->get_history__( t_last_update_ - dendritic_delay, t_trig - dendritic_delay, &start, &finish );

  // facilitation due to postsyn. spikes since last update
  double t0 = t_last_update_;
  // double minus_dt;
  double timestep = 0;

  while ( start != finish )
  {
{%- for vt_port in vt_ports %}
{%- set vt_port = vt_ports[0] %}
    process_{{vt_port}}_spikes_( vt_spikes, t0, start->t_ + dendritic_delay, cp );
{%- endfor %}

#ifdef DEBUG
    std::cout << "\tprocessing post spike from " << t_last_update_ << " to " << start->t_ + dendritic_delay << std::endl;
#endif

    /**
     * update synapse internal state from `t_last_update_` to `start->t_`
    **/

    update_internal_state_(t_last_update_,
                           (start->t_ + dendritic_delay) - t_last_update_,
                           cp);

    const double _tr_t = start->t_;
#ifdef DEBUG
        std::cout << "\tFacilitating from c = " << S_.c << " (using trace = " << S_.pre_tr << ")";
#endif
{%- filter indent(6, True) %}
{%- if post_ports is defined %}
{%-     for post_port in spiking_post_ports %}
    /**
     *  NESTML generated onReceive code block for postsynaptic port "{{post_port}}" begins here!
    **/

{%-         set dynamics = synapse.get_on_receive_block(post_port) %}
{%-         with ast = dynamics.get_block() %}
{%-             include "directives/Block.jinja2" %}
{%-         endwith %}
{%-     endfor %}
{%- endif %}
{%- endfilter %}

// #ifdef DEBUG
//   std::cout << "\t--> new w = " << S_.w << std::endl;
// #endif
#ifdef DEBUG
      std::cout << " to " << S_.c << std::endl;
#endif
    /**
     * internal state has now been fully updated to `start->t_ + dendritic_delay`
    **/

    t0 = start->t_ + dendritic_delay;
    // minus_dt = t_last_update_ - t0;
    t_lastspike_ = start->t_ + dendritic_delay;
    ++start;
  }

  /**
    * update synapse internal state from `t_lastspike_` to `t_trig`
  **/

{%- for vt_port in vt_ports %}
{%- set vt_port = vt_ports[0] %}
  process_{{vt_port}}_spikes_( vt_spikes, t_lastspike_, t_trig, cp );
{%- endfor %}

#ifdef DEBUG
    //std::cout << "{{synapseName}}::trigger_update_weight(): \tupdating from " << t_lastspike_ << " to " << t_trig + dendritic_delay << std::endl;
#endif

 /* update_internal_state_(t_lastspike_,
                         t_trig - t_lastspike_,
                         cp);*/

  vt_spikes_idx_ = 0;
  t_lastspike_ = t_trig;
}


{%- endif %}

} // namespace

#endif /* #ifndef {{synapseName.upper()}}_H */
