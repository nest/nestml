{#-
NeuronClassAnalytic.jinja2

This file is part of NEST.

Copyright (C) 2004 The NEST Initiative

NEST is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 2 of the License, or
(at your option) any later version.

NEST is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with NEST.  If not, see <http://www.gnu.org/licenses/>.
#}
/*
 *  {{ neuronName }}.cu
 *
 *  This file is part of NEST GPU.
 *
 *  Copyright (C) 2021 The NEST Initiative
 *
 *  NEST GPU is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 2 of the License, or
 *  (at your option) any later version.
 *
 *  NEST GPU is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with NEST GPU.  If not, see <http://www.gnu.org/licenses/>.
 *
 */

#include <config.h>
#include <cmath>
#include <iostream>
#include "{{ neuronName }}.h"
#include "spike_buffer.h"

{%- import 'directives/SetScalParamAndVar.jinja2' as set_scal_param_var with context %}

using namespace {{ neuronName }}_ns;

__global__ void {{ neuronName }}_Calibrate(int n_node, float *param_arr,
				      int n_param, float h)
{
  int i_neuron = threadIdx.x + blockIdx.x * blockDim.x;
  if (i_neuron < n_node) {
    float *param = param_arr + n_param*i_neuron;
    param[i___h] = h; // as ms
{%- filter indent(4,True) %}
{%- for internals_block in neuron.get_internals_blocks() %}
{%-     for decl in internals_block.get_declarations() %}
{%-         for variable in decl.get_variables() %}
{%-           if variable.get_name() != "__h" %}
{%-             include "directives/MemberInitialization.jinja2" %}
{%-           endif %}
{%-         endfor %}
{%-     endfor %}
{%- endfor %}
{%- endfilter %}
  }
}


__global__ void {{ neuronName }}_Update(int n_node, int i_node_0, float *var_arr,
				   float *param_arr, int n_var, int n_param)
{
  int i_neuron = threadIdx.x + blockIdx.x * blockDim.x;
  if (i_neuron < n_node) {
    float *var = var_arr + n_var*i_neuron;
    float *param = param_arr + n_param*i_neuron;
    /**
     * subthreshold updates of the convolution variables
     *
     * step 1: regardless of whether and how integrate_odes() will be called, update variables due to convolutions
    **/

{%-     for variable_name in analytic_state_variables %}
{%-         if "__X__" in variable_name %}
{%-             set update_expr = update_expressions[variable_name] %}
{%-             set var_ast = utils.get_variable_by_name(astnode, variable_name)%}
{%-             set var_symbol = var_ast.get_scope().resolve_to_symbol(variable_name, SymbolKind.VARIABLE)%}
const {{ type_symbol_printer.print(var_symbol.type_symbol) }} {{variable_name}}__tmp_ = {{ printer.print(update_expr) }};
{%-         endif %}
{%-     endfor %}

    /**
     * Begin NESTML generated code for the update block(s)
    **/
{%- if neuron.get_update_blocks() %}
{%-     filter indent(2) %}
{%-         for block in neuron.get_update_blocks() %}
{%-             set ast = block.get_block() %}
{%-             if ast.print_comment('*')|length > 1 %}
/*
 {{ast.print_comment('*')}}
 */
{%-             endif %}
{%-             include "directives/Block.jinja2" %}
{%-         endfor %}
{%-     endfilter %}
{%- endif %}

    /**
     * Begin NESTML generated code for the onReceive block(s)
    **/
{%  for blk in neuron.get_on_receive_blocks() %}
{%-     set inport = blk.get_port_name() %}
    if (var[N_SCAL_VAR + i_{{ inport }}])
    {
{%-     set ast = blk.get_block() %}
{%-     filter indent(6, True) -%}
{%-         include "directives/Block.jinja2" %}
{%-     endfilter %}      
      var[N_SCAL_VAR + i_{{ inport }}] = 0; // reset the value
    }
{%- endfor %}

    /**
     * subthreshold updates of the convolution variables
     *
     * step 2: regardless of whether and how integrate_odes() was called, update variables due to convolutions. Set to the updated values at the end of the timestep.
    **/
{%-     for variable_name in analytic_state_variables %}
{%-         if "__X__" in variable_name %}
{%-             set update_expr = update_expressions[variable_name] %}
{%-             set var_ast = utils.get_variable_by_name(astnode, variable_name)%}
{%-             set var_symbol = var_ast.get_scope().resolve_to_symbol(variable_name, SymbolKind.VARIABLE)%}
    {{ printer.print(var_ast) }} = {{variable_name}}__tmp_;
{%-         endif %}
{%-     endfor %}

    /**
     * Begin NESTML generated code for the onCondition block(s)
    **/
{% if neuron.get_on_condition_blocks() %}
{%-     for block in neuron.get_on_condition_blocks() %}
    if ({{ printer.print(block.get_cond_expr()) }})
    {
{%-         set ast = block.get_block() %}
{%-         if ast.print_comment('*') | length > 1 %}
/*
 {{ast.print_comment('*')}}
 */
{%-         endif %}
{%-         filter indent(6) %}
{%-             include "directives/Block.jinja2" %}
{%-         endfilter %}
    }
{%-     endfor %}
{%- endif %}
  }
}


{{ neuronName }}::~{{ neuronName }}()
{
  FreeVarArr();
  FreeParamArr();
}

int {{ neuronName }}::Init(int i_node_0, int n_node, int /*n_port*/,
			 int i_group, unsigned long long *seed)
{
  BaseNeuron::Init(i_node_0, n_node, {{neuron.get_spike_input_ports() | length}} /*n_port*/, i_group, seed);
  node_type_ = i_{{ neuronName }}_model;

  // State variables
  n_scal_var_ = N_SCAL_VAR;
  n_port_var_ = N_PORT_VAR;
  n_var_ = n_scal_var_ + n_port_var_;

  // Parameters
  n_scal_param_ = N_SCAL_PARAM;
  n_param_ = n_scal_param_;

  AllocParamArr();
  AllocVarArr();

  scal_var_name_ = {{ neuronName }}_scal_var_name;
  scal_param_name_ = {{ neuronName }}_scal_param_name;
  port_var_name_ = {{ neuronName }}_port_var_name;

  // Parameters
{%- for variable_symbol in neuron.get_parameter_symbols() %}
{%-     set variable = utils.get_parameter_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
    SetScalParam(0, n_node, "{{ printer_no_origin.print(variable) }}", {{set_scal_param_var.SetScalParamAndVar(variable_symbol.get_declaring_expression())}});  // as {{variable_symbol.get_type_symbol().print_symbol()}}
{%- endfor %}

    // Internal variables
{%- for variable_symbol in neuron.get_internal_symbols() %}
{%-     set variable = utils.get_internal_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
    SetScalParam(0, n_node, "{{ printer_no_origin.print(variable) }}", 0.0);
{%- endfor %}

    // Continuous input port: set to 0
{%- for variable_symbol in neuron.get_continuous_input_ports() %}
{%-     set variable = utils.get_input_port_by_name(astnode.get_input_blocks(), variable_symbol.get_symbol_name()) %}
    SetScalParam(0, n_node, "{{ variable.get_name() }}", 0.0);
{%- endfor %}

    // State variables
{%- for variable_symbol in neuron.get_state_symbols_sorted_by_suffix() %}
{%-     set variable = utils.get_state_variable_by_name(astnode, variable_symbol.get_symbol_name()) %}
    SetScalVar(0, n_node, "{{ printer_no_origin.print(variable) }}", {{set_scal_param_var.SetScalParamAndVar(variable_symbol.get_declaring_expression())}});
{%- endfor %}

  // multiplication factor of input signal is always 1 for all nodes
  float input_weight = 1.0;
  gpuErrchk(cudaMalloc(&port_weight_arr_, sizeof(float)));
  gpuErrchk(cudaMemcpy(port_weight_arr_, &input_weight,
			 sizeof(float), cudaMemcpyHostToDevice));
  port_weight_arr_step_ = 0;
  port_weight_port_step_ = 0;

  // process the input spikes
  port_input_arr_ = GetVarArr() + n_scal_var_ + GetPortVarIdx("{{ utils.get_first_excitatory_port(neuron) }}");
  port_input_arr_step_ = n_var_;
  port_input_port_step_ = 1;

{# TODO #}
{#  den_delay_arr_ =  GetParamArr() + GetScalParamIdx("den_delay"); #}

  return 0;
}

int {{ neuronName }}::Free()
{
  FreeVarArr();
  FreeParamArr();

  return 0;
}

int {{ neuronName }}::Calibrate(double time_min, float time_resolution)
{
   {{ neuronName }}_Calibrate<<<(n_node_+1023)/1024, 1024>>>
    (n_node_, param_arr_, n_param_, time_resolution);
  return 0;
}

int {{ neuronName }}::Update(long long it, double t1)
{
  {{ neuronName }}_Update<<<(n_node_+1023)/1024, 1024>>>
    (n_node_, i_node_0_, var_arr_, param_arr_, n_var_, n_param_);
  // gpuErrchk( cudaDeviceSynchronize() );
  return 0;
}