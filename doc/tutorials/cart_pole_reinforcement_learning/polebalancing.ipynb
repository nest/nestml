{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f763ff4e",
   "metadata": {},
   "source": [
    "# Polebalancing using NESTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c21179",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to build an agent that can successfully solve the classic pole balancing problem using reinforcement learning. We will start with a standard temporal difference learning approach and after that, use NESTML to set up a spiking neural network to perform this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885d90c",
   "metadata": {},
   "source": [
    "# Cart Pole Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c0bfe",
   "metadata": {},
   "source": [
    "For the cart pole environment, we mostly need three things:  \n",
    "    - A renderer to display the simulation  \n",
    "    - The physics system and  \n",
    "    - An input to be able to nudge the pole in both directions  \n",
    "\n",
    "For that, we will need the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ded29bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.0 (SDL 2.28.0, Python 3.11.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "import pygame as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283c79f",
   "metadata": {},
   "source": [
    "Let's start with the renderer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1af3680-b849-48bb-a653-642b580a01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renders the scene. IMPORTANT: Because ipycanvas uses the html canvas coordinates, the y-axis is inverted.\n",
    "class Renderer():\n",
    "    def __init__(self, width: int, height: int, origin_x: int = 0, origin_y: int = 0, SCALE: int = 1) -> None:\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.origin = (origin_x, origin_y)\n",
    "        self.SCALE = SCALE #1m = SCALE pixels\n",
    "\n",
    "        pg.display.init()\n",
    "        pg.display.set_caption(\"Pole Balancing Simulator\")\n",
    "        pg.font.init()\n",
    "        self.screen = pg.display.set_mode((width, height))\n",
    "    \n",
    "    #Translates global coordinates into screen coordinates\n",
    "    def translate(self, x: int, y: int) -> Tuple[int, int]:\n",
    "        return (x+self.origin[0], -y+self.origin[1])\n",
    "    \n",
    "    #Draws ground. offset is there to shift the ground below the car\n",
    "    def draw_ground(self, offset: int, color) -> None:\n",
    "        ground = pg.Rect(self.translate(-self.width//2, -offset * self.SCALE), (self.width, self.height-self.origin[1]-offset * self.SCALE))\n",
    "        pg.draw.rect(self.screen, color, ground)\n",
    "\n",
    "    #Draws car. pos_y is omitted because the car's center should be at y = 0\n",
    "    def draw_car(self, pos_x: float, car_color = \"blue\", wheel_color = \"black\") -> None:\n",
    "        pos_x *= self.SCALE\n",
    "        #values, hard-coded for now, in meters\n",
    "        width = 0.5 * self.SCALE\n",
    "        height = 0.25 * self.SCALE\n",
    "        wheel_radius = 0.1 * self.SCALE\n",
    "\n",
    "        car_body = pg.Rect(self.translate(pos_x - width/2, height/2), (width, height))\n",
    "        pg.draw.rect(self.screen, car_color, car_body)\n",
    "        pg.draw.circle(self.screen, wheel_color, \n",
    "                           self.translate(pos_x - width/2 + wheel_radius, -height/2), wheel_radius)\n",
    "        pg.draw.circle(self.screen, wheel_color, \n",
    "                           self.translate(pos_x + width/2 - wheel_radius, -height/2), wheel_radius)\n",
    "\n",
    "    #Draws the pole\n",
    "    def draw_pole(self, pos_x: float, theta: float, length: float, width: float = 0.1, color = \"red\") -> None:\n",
    "        pos_x *= self.SCALE\n",
    "        width = int(width * self.SCALE)\n",
    "        pole_end_x = length * np.sin(theta) * self.SCALE + pos_x\n",
    "        pole_end_y = length * np.cos(theta) * self.SCALE\n",
    "        pg.draw.line(self.screen, color, self.translate(pos_x, 0), self.translate(pole_end_x, pole_end_y), width)\n",
    "\n",
    "    #Clears the entire canvas\n",
    "    def draw_clear(self) -> None:\n",
    "        self.screen.fill(\"white\")\n",
    "\n",
    "    #Draws physical values\n",
    "    def draw_stats(self, theta: float, w: float, v: float, x: float, \n",
    "                    episode: int, \n",
    "                    spikes_left : int, spikes_right : int, \n",
    "                    dopamine_left : float, dopamine_right : float, \n",
    "                    action: int) -> None:\n",
    "        font = pg.font.Font(None, 24)\n",
    "        #Physics stats, drawn left\n",
    "        text = \"angle: \" + str(theta)[:4] + \\\n",
    "            \"\\nangular velocity: \" + str(w)[:4] + \\\n",
    "            \"\\nposition: \" + str(x)[:4] + \\\n",
    "            \"\\nvelocity\" + str(v)[:4] + \\\n",
    "            \" \\nepisode: \" + str(episode)\n",
    "        lines = text.split('\\n')\n",
    "        y_pos = 10\n",
    "        for line in lines:\n",
    "            text_surface = font.render(line, True, (0,0,0))\n",
    "            self.screen.blit(text_surface, (10, y_pos))\n",
    "            y_pos += 30\n",
    "\n",
    "        #Network stats, drawn right\n",
    "        text = \"Spikes left: \" + str(spikes_left) + \\\n",
    "            \"\\nDopamine left: \" + str(dopamine_left)[:4] + \\\n",
    "            \"\\nSpikes right: \" + str(spikes_right)[:4] + \\\n",
    "            \"\\nDopamine right: \" + str(dopamine_right) + \\\n",
    "            \"\\nTaken action: \" + (\"Left\" if action==0 else \"Right\" if action==1 else \"Failure\")\n",
    "        lines = text.split('\\n')\n",
    "        y_pos = 10\n",
    "        for line in lines:\n",
    "            text_surface = font.render(line, True, (0,0,0))\n",
    "            self.screen.blit(text_surface, (self.width - 200, y_pos))\n",
    "            y_pos += 30\n",
    "\n",
    "    def get_relative_mouse_x(self, mouse_x:float) -> float:\n",
    "        return (mouse_x-self.origin[0])/self.SCALE\n",
    "    \n",
    "    def display(self) -> None:\n",
    "        pg.display.flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6362d90",
   "metadata": {},
   "source": [
    "## Physics Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74907eaf",
   "metadata": {},
   "source": [
    "For the physics, we use the corrected version of of the original problem derived from V. Florian (CITATION NEEDED), but omit the friction forces.\n",
    "The situation is sketched here:  \n",
    "\n",
    "![alt text](cartpole_illustration.png \"Cartpole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c94e0",
   "metadata": {},
   "source": [
    "We apply Newton's second law of motion to the cart:  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbf{F} + \\mathbf{G}_c - \\mathbf{N} = m_c \\cdot \\mathbf{a}_c\n",
    "\\end{aligned}\n",
    "$$\n",
    "Where:  \n",
    "\n",
    "$\\mathbf{F} = F \\cdot \\mathbf{u_x}$ is the control force acting on the cart,  \n",
    "$\\mathbf{G}_c = m_c \\cdot g \\cdot \\mathbf{u}_y$ is the gravitational component acting on the cart,  \n",
    "$\\mathbf{N} = N_x \\cdot \\mathbf{u}_x - N_y \\cdot \\mathbf{u}_y$ is the negative reaction force that the pole is applying on the cart,  \n",
    "$\\mathbf{a}_c = \\ddot{x} \\cdot \\mathbf{u}_x$ is the accelaration of the cart,  \n",
    "$m_c$ is the cart's mass and  \n",
    "$\\mathbf{u}_x$, $\\mathbf{u}_y$, $\\mathbf{u}_z$ are the unit vectors of the frame of reference given in the illustration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2e429",
   "metadata": {},
   "source": [
    "We can decompose this equation now into the $x$ and $y$ component:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    F - N_x = m_c \\cdot \\ddot{x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    m_c \\cdot g + N_y = 0\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62acf48",
   "metadata": {},
   "source": [
    "Newton's second law of motion applied to the pole gives us:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbf{N} + \\mathbf{G}_p = m_p \\cdot \\mathbf{a}_p\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where $\\mathbf{G}_p = m_p \\cdot g \\cdot \\mathbf{u}_y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38770100",
   "metadata": {},
   "source": [
    "The accelaration $\\mathbf{a}_p$ of the pole's center of mass consists of three components, where $\\mathbf{r}_p = l \\cdot (\\sin{\\theta}\\cdot \\mathbf{u}_x-\\cos{\\theta}\\cdot \\mathbf{u}_y)$ denotes the vector pointing to the pole's center of mass relative to it's rotation center:  \n",
    "1. The accelaration of the cart it is attached to $\\mathbf{a}_c$,\n",
    "2. The pole's angular accelaration $\\mathbf{\\epsilon} = \\ddot{\\theta} \\cdot \\mathbf{u}_z$, which is translated into accelaration by $\\mathbf{\\epsilon} \\times \\mathbf{r}_p$.\n",
    "3. The pole's angular velocity $\\mathbf{\\omega} = \\dot{\\theta} \\cdot \\mathbf{u}_z$, for which the accelaration can be derived by  $\\mathbf{\\omega} \\times (\\mathbf{\\omega} \\times \\mathbf{r}_p)$.\n",
    "\n",
    "Thus we obtain:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbf{a}_p  = \\mathbf{a}_c + \\mathbf{\\epsilon} \\times \\mathbf{r}_p + \\mathbf{\\omega} \\times (\\mathbf{\\omega} \\times \\mathbf{r}_p)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Substituting $\\mathbf{r}_p = l \\cdot (\\sin{\\theta}\\cdot \\mathbf{u}_x-\\cos{\\theta}\\cdot \\mathbf{u}_y)$ and $\\mathbf{a}_p = \\ddot{x} \\cdot \\mathbf{u}_x$ as well as $\\mathbf{u}_z \\times \\mathbf{u}_x = \\mathbf{u}_y$ and $\\mathbf{u}_z \\times \\mathbf{u}_y = -\\mathbf{u}_x$:\n",
    "\\begin{aligned}\n",
    "    \\mathbf{a}_p  = \\ddot{x} \\cdot \\mathbf{u}_x + l \\cdot \\ddot{\\theta} \\cdot (\\sin{\\theta}\\cdot \\mathbf{u}_y + \\cos{\\theta}\\cdot \\mathbf{u}_x) - l \\cdot \\dot{\\theta}^2 \\cdot (\\sin{\\theta}\\cdot \\mathbf{u}_x - \\cos{\\theta}\\cdot \\mathbf{u}_y)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895254eb",
   "metadata": {},
   "source": [
    "Inserting this quation into our equation for the forces of the pole and decomposing on the $x$ and $y$ axis we obtain:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    N_x = m_p \\cdot (\\ddot{x} + l \\cdot \\ddot{\\theta} \\cdot \\cos{\\theta} - l \\cdot \\dot{\\theta}^2 \\cdot \\sin{\\theta})\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    m_p \\cdot g - N_y = m_p \\cdot (l \\cdot \\ddot{\\theta} \\cdot \\sin{\\theta} + l \\cdot \\dot{\\theta}^2 \\cdot \\cos{\\theta})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c6dd1",
   "metadata": {},
   "source": [
    "# TODO: FINISH EQUATION DERIVATION (SOLVE EQUATION REFERENCING?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5f4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Physics:\n",
    "    \n",
    "    def __init__(self, x, theta, v = 0, a = 0, w = 0, dw = 0, g = 9.81, m_c = 1, m_p = 0.1, l = 0.5, dt = 0.02) -> None:\n",
    "        self.__dict__.update(vars())\n",
    "\n",
    "    def dw_step(self, cart_force, nudge_force) -> float:\n",
    "        numerator = self.g * np.sin(self.theta) + np.cos(self.theta) * (-cart_force - self.m_p * self.l * self.w**2 * np.sin(self.theta))/(self.m_c+self.m_p) + nudge_force * np.cos(self.theta)/(self.m_p*self.l)\n",
    "        denominator = self.l * (4/3 - (self.m_p*np.cos(self.theta)**2)/(self.m_c+self.m_p))\n",
    "\n",
    "        self.dw = numerator/denominator\n",
    "        self.w += self.dt * self.dw\n",
    "        self.theta += self.dt * self.w\n",
    "\n",
    "        return self.theta\n",
    "    \n",
    "    def a_step(self, force) -> float:\n",
    "        numerator = force + self.m_p * self.l * (self.w**2 * np.sin(self.theta) - self.dw * np.cos(self.theta))\n",
    "        denominator = self.m_c + self.m_p\n",
    "\n",
    "        self.a = numerator/denominator\n",
    "        self.v += self.dt * self.a\n",
    "        self.x += self.dt * self.v\n",
    "\n",
    "        return self.x\n",
    "\n",
    "    def update(self, force, mouse_x) -> Tuple[float, float]:\n",
    "        nudge_force = 0\n",
    "        if mouse_x is not None:\n",
    "            nudge_force = -1 if mouse_x > self.x else 1\n",
    "        return (self.dw_step(force, nudge_force), self.a_step(force))\n",
    "    \n",
    "    #get state of the system that agent can see\n",
    "    def get_state(self) -> Tuple[float,float,float,float]:\n",
    "        return (self.x, self.theta, self.v, self.w)\n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        self.x = 0\n",
    "        self.theta = (np.random.rand() - 1) / 10\n",
    "        self.v = 0\n",
    "        self.a = 0\n",
    "        self.w = 0\n",
    "        self.dw = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76793d12",
   "metadata": {},
   "source": [
    "# The Agent (BOXES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5707ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    State is represented as:\n",
    "\n",
    "    [ x ]\n",
    "    [ θ ]\n",
    "    [ v ]\n",
    "    [ ω ]   # = dθ/dt\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, initial_state: Tuple[float,float,float,float]) -> None:\n",
    "\n",
    "        #thresholds for discretizing the state space\n",
    "        \n",
    "        # ORIGINAL BOXES THAT WE USED SUCCESSFULLY ON THE NON SPIKING AGENT\n",
    "#         self.x_thresholds = np.array([-2.4, -0.8, 0.8, 2.4])\n",
    "#         self.theta_thresholds = np.array([-12, -6, -1, 0, 1, 6, 12])\n",
    "#         self.theta_thresholds = self.theta_thresholds /180 * np.pi\n",
    "#         self.v_thresholds = np.array([float(\"-inf\"), -0.5, 0.5, float(\"+inf\")]) #open intervals ignored here\n",
    "#         self.w_thresholds = np.array([float(\"-inf\"), -50, 50, float(\"+inf\")]) #open intervals ignored here\n",
    "#         self.w_thresholds = self.w_thresholds / 180 * np.pi\n",
    "\n",
    "        # BOXES FROM LIU&PAN CODE\n",
    "        self.x_thresholds = np.array([-2.4, 2.4])\n",
    "        self.v_thresholds = np.array([float(\"-inf\"), float(\"+inf\")])\n",
    "        \n",
    "        self.theta_thresholds = np.array([-12, -5.738738738738739, -2.8758758758758756, 0., 2.8758758758758756, 5.738738738738739, 12])\n",
    "        self.theta_thresholds = self.theta_thresholds / 180 * np.pi\n",
    "        \n",
    "        self.w_thresholds = np.array([float(\"-inf\"), -103., -91.7, -80.2, -68.8, -57.3, -45.9, -34.3, -22.9, -11.5, 0.,\n",
    "                                                      11.5, 22.9, 34.3, 45.9, 57.3, 68.8, 80.2, 91.7, 103., float(\"+inf\")]) #open intervals ignored here\n",
    "        self.w_thresholds = self.w_thresholds / 180 * np.pi\n",
    "        \n",
    "        self.dimensions = (len(self.x_thresholds) - 1, len(self.theta_thresholds) - 1, len(self.v_thresholds) - 1, len(self.w_thresholds) - 1)\n",
    "\n",
    "        print(\"Dimension of input space: \" + str(self.dimensions))\n",
    "        \n",
    "        self.boxes = np.random.rand(self.dimensions[0], \n",
    "                                    self.dimensions[1], \n",
    "                                    self.dimensions[2], \n",
    "                                    self.dimensions[3], \n",
    "                                    2) #one q-value for left and right respectively\n",
    "        box = self.get_box(initial_state)\n",
    "        self.current_box = self.boxes[box[0], box[1], box[2], box[3], :]\n",
    "\n",
    "        self.episode = 1\n",
    "    \n",
    "    def discretize(self, value, thresholds):\n",
    "        for i, limit in enumerate(thresholds):\n",
    "            if value < limit:\n",
    "                return i - 1\n",
    "        return -1\n",
    "\n",
    "    def get_box(self, state: Tuple[float,float,float,float]) -> Tuple[int,int,int,int]:\n",
    "        return (self.discretize(state[0], self.x_thresholds),\n",
    "                 self.discretize(state[1], self.theta_thresholds),\n",
    "                 self.discretize(state[2], self.v_thresholds), \n",
    "                 self.discretize(state[3], self.w_thresholds))\n",
    "    \n",
    "    def get_episode(self) -> int:\n",
    "        return self.episode\n",
    "    \n",
    "    \n",
    "    def failure_reset(self, state: Tuple[float,float,float,float]):\n",
    "        box = self.get_box(state)\n",
    "        self.current_box = self.boxes[box[0], box[1], box[2], box[3], :]\n",
    "        self.episode += 1\n",
    "\n",
    "\n",
    "class NonSpikingAgent(Agent):\n",
    "    def __init__(self, initial_state: Tuple[float,float,float,float], learning_rate, learning_decay, epsilon, epsilon_decay, discount_factor) -> None:\n",
    "        super().__init__(initial_state)\n",
    "\n",
    "        #learning paramters\n",
    "        self.learning_rate = learning_rate\n",
    "        self. learning_decay = learning_decay\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "    #returns 0 if the action is \"left\", else \"1\"\n",
    "    def choose_action(self) -> int:\n",
    "        self.action = np.random.choice([np.argmax(self.current_box), np.argmin(self.current_box)], p=[1-self.epsilon, self.epsilon])\n",
    "        return self.action\n",
    "    \n",
    "    #returns 0 if no failure occured, else 1\n",
    "    #reward is -1 on failure and 0 else\n",
    "    def update(self, next_state: Tuple[float,float,float,float]) -> int:\n",
    "        box = self.get_box(next_state)\n",
    "        if -1 in box:\n",
    "            self.current_box[self.action] += self.learning_rate * -1\n",
    "            return 1\n",
    "        \n",
    "        next_box = self.boxes[box[0], box[1], box[2], box[3], :]\n",
    "        next_q = np.max(next_box)\n",
    "        self.current_box[self.action] += self.learning_rate * (self.discount_factor * (next_q - self.current_box[self.action]))\n",
    "\n",
    "        self.current_box = next_box\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.learning_rate *= self.learning_decay\n",
    "\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e6cd3",
   "metadata": {},
   "source": [
    "# Plot Renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9b07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "class Non_Spiking_PlotRenderer():\n",
    "    def __init__(self, init_x = [0], init_y = [0]) -> None:\n",
    "        plt.ion()\n",
    "\n",
    "        #Construct lifetime plot\n",
    "        self.lifetime_fig, self.lifetime_ax = plt.subplots()\n",
    "        self.x = init_x\n",
    "        self.y = init_y\n",
    "        self.max_lifetime = 0\n",
    "        self.lifetime_line, = self.lifetime_ax.plot(self.x, self.y)\n",
    "        self.lifetime_ax.set_xlabel(\"Episode\")\n",
    "        self.lifetime_ax.set_ylabel(\"Simulation Steps\")\n",
    "        self.lifetime_ax.set_title(\"Lifetime Plot\")\n",
    "\n",
    "        #Construct Heatmap for two parameters\n",
    "        self.q_value_fig, self.q_value_ax = plt.subplots()\n",
    "        self.q_value_ax.set_title(\"Q-Values for a state of (param1/param2)\")\n",
    "        self.cmap = plt.cm.coolwarm\n",
    "        \n",
    "    def update(self, x, y, boxes) -> None:\n",
    "        self.x.append(x)\n",
    "        self.y.append(y)\n",
    "        self.max_lifetime = max(self.max_lifetime, y)\n",
    "        self.lifetime_line.set_data(self.x, self.y)\n",
    "        self.lifetime_ax.set_xlim(self.x[0], self.x[-1])\n",
    "        self.lifetime_ax.set_ylim(0, self.max_lifetime)\n",
    "\n",
    "        if(x % 10 == 0):\n",
    "            q_values = boxes[:,:,:,:,0] - boxes[:,:,:,:,1]\n",
    "            self.q_value_ax.imshow(np.mean(q_values, axis = (1,3)), cmap=self.cmap, interpolation='none')\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7786b",
   "metadata": {},
   "source": [
    "# Executing Non-Spiking-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717eda26-e385-494f-bdca-9847eefe01ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport sys\\n\\nr = Renderer(1200, 800, 600, 500, 400)\\nclock = pg.time.Clock()\\nrunning = True\\n\\np = Physics(0, (np.random.rand() - 1) / 10)\\n\\na = NonSpikingAgent(p.get_state(), 0.5, 0.9999999999999, 1, 0.995, 0.99)\\n\\nplot = Non_Spiking_PlotRenderer()\\n\\nsteps_per_episode = 0\\nmax_steps = 0\\n\\nwindow_size = 30\\nwindow = np.zeros(30)\\navg_lifetime = 20000\\n\\ntoggle_sim = False\\n\\nwhile running:\\n    steps_per_episode += 1\\n\\n    force = 0\\n    mouse_x = None\\n\\n    # poll for events\\n    for event in pg.event.get():\\n        if event.type == pg.QUIT:\\n            running = False\\n            pg.quit()\\n            sys.exit()\\n            quit()\\n        elif event.type == pg.MOUSEBUTTONDOWN:\\n            mouse_x = r.get_relative_mouse_x(pg.mouse.get_pos()[0])\\n        elif event.type == pg.KEYDOWN:\\n            toggle_sim ^= pg.key.get_pressed()[pg.K_SPACE]\\n\\n    # agent chooses action, simulation is updated and reward is calculated\\n    force = 10 if a.choose_action() else -10\\n    theta, x = p.update(force, mouse_x)\\n    failure = a.update(p.get_state())\\n\\n    if failure:\\n        p.reset()\\n        a.failure_reset(p.get_state())\\n        plot.update(a.get_episode(), steps_per_episode, a.boxes)\\n        window = np.roll(window, 1)\\n        window[0] = steps_per_episode\\n        steps_per_episode = 0\\n    \\n    \\n    if np.mean(window) >= avg_lifetime or toggle_sim:\\n        r.draw_clear()\\n        r.draw_ground(0.2, \"grey\")\\n        r.draw_car(x)\\n        r.draw_pole(x, theta, 2*p.l, 0.02)\\n        r.draw_stats(theta*180/np.pi, p.w*180/np.pi, x, p.a, a.get_episode())\\n        r.display()\\n\\n        clock.tick(50)  # limits FPS to 50\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "r = Renderer(1200, 800, 600, 500, 400)\n",
    "clock = pg.time.Clock()\n",
    "running = True\n",
    "\n",
    "p = Physics(0, (np.random.rand() - 1) / 10)\n",
    "\n",
    "a = NonSpikingAgent(p.get_state(), 0.5, 0.9999999999999, 1, 0.995, 0.99)\n",
    "\n",
    "plot = Non_Spiking_PlotRenderer()\n",
    "\n",
    "steps_per_episode = 0\n",
    "max_steps = 0\n",
    "\n",
    "window_size = 30\n",
    "window = np.zeros(30)\n",
    "avg_lifetime = 20000\n",
    "\n",
    "toggle_sim = False\n",
    "\n",
    "while running:\n",
    "    steps_per_episode += 1\n",
    "\n",
    "    force = 0\n",
    "    mouse_x = None\n",
    "\n",
    "    # poll for events\n",
    "    for event in pg.event.get():\n",
    "        if event.type == pg.QUIT:\n",
    "            running = False\n",
    "            pg.quit()\n",
    "            sys.exit()\n",
    "            quit()\n",
    "        elif event.type == pg.MOUSEBUTTONDOWN:\n",
    "            mouse_x = r.get_relative_mouse_x(pg.mouse.get_pos()[0])\n",
    "        elif event.type == pg.KEYDOWN:\n",
    "            toggle_sim ^= pg.key.get_pressed()[pg.K_SPACE]\n",
    "\n",
    "    # agent chooses action, simulation is updated and reward is calculated\n",
    "    force = 10 if a.choose_action() else -10\n",
    "    theta, x = p.update(force, mouse_x)\n",
    "    failure = a.update(p.get_state())\n",
    "\n",
    "    if failure:\n",
    "        p.reset()\n",
    "        a.failure_reset(p.get_state())\n",
    "        plot.update(a.get_episode(), steps_per_episode, a.boxes)\n",
    "        window = np.roll(window, 1)\n",
    "        window[0] = steps_per_episode\n",
    "        steps_per_episode = 0\n",
    "    \n",
    "    \n",
    "    if np.mean(window) >= avg_lifetime or toggle_sim:\n",
    "        r.draw_clear()\n",
    "        r.draw_ground(0.2, \"grey\")\n",
    "        r.draw_car(x)\n",
    "        r.draw_pole(x, theta, 2*p.l, 0.02)\n",
    "        r.draw_stats(theta*180/np.pi, p.w*180/np.pi, x, p.a, a.get_episode())\n",
    "        r.display()\n",
    "\n",
    "        clock.tick(50)  # limits FPS to 50\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2876351",
   "metadata": {},
   "source": [
    "# TODO: clean up code, derive equations and explain renderer briefly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e05060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43c70dff",
   "metadata": {},
   "source": [
    "# Spiking version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4705cf6",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6e192",
   "metadata": {},
   "source": [
    "The core principle of our SNN is to simulate the physics and neuron model in sequence, where the state at the end of a physics step is the input for the SNN and the resulting action at the end of a period of SNN simulation is the input to the next physics simulation. Both cycles are set to 40ms to provide the effect that they run simultaneously.\n",
    "The model's structure consists of two layers of neurons. For each discrete state of the system, the input layer contains a single neuron corresponding to it. Neuromodulated synapses connect these to the output layer, which itself consists of two neuron groups interpreted as actions \"move left\" and \"move right\" respectively.\n",
    "\n",
    "One simulation step of the SNN works as follows:\n",
    "1. Get the current state of the cart pole and find the designated neuron that only fires when that state is reached.\n",
    "2. Set a continuous firing rate for the simulation period on that neuron.\n",
    "3. Determine which of the neuron groups in the output layer has fired more spikes at the end of the step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831c9d7",
   "metadata": {},
   "source": [
    "# SNN Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9bdcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spiking_PlotRenderer:\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        plt.ion()\n",
    "        \n",
    "        self.fig, self.ax = plt.subplots(nrows=4, figsize=(12, 4))\n",
    "        self.fig.show()\n",
    "        \n",
    "        # Construct lifetime plot\n",
    "        self.lifetime_fig, self.lifetime_ax = plt.subplots()\n",
    "        self.max_lifetime = 0\n",
    "        self.episode_number = []\n",
    "        self.steps_per_episode = []\n",
    "        self.lifetime_line, = self.lifetime_ax.plot([0,1], [0,1])\n",
    "        self.lifetime_ax.set_xlabel(\"Episode\")\n",
    "        self.lifetime_ax.set_ylabel(\"Simulation Steps\")\n",
    "        self.lifetime_ax.set_title(\"Lifetime Plot\")\n",
    "        self.lifetime_fig.show()\n",
    "        \n",
    "        # Plot the weights\n",
    "        self.weights_fig, self.weights_ax = plt.subplots(ncols=2)\n",
    "        self.weights_ax[0].set_title(\"Weights left\")\n",
    "        self.weights_ax[1].set_title(\"Weights right\")\n",
    "        self.cmap = plt.cm.coolwarm\n",
    "        self.cbar = None\n",
    "        \n",
    "        # plot actions taken\n",
    "        \n",
    "\n",
    "    def update(self, data) -> None:\n",
    "        if data is None: return\n",
    "\n",
    "        self.weights_ax[0].cla()\n",
    "        self.weights_ax[1].cla()\n",
    "#         self.weights_ax[0].imshow(np.mean(data[\"weights_left\"], axis=(0, 2)), cmap=self.cmap, interpolation='none')\n",
    "#         self.weights_ax[1].imshow(np.mean(data[\"weights_right\"], axis=(0, 2)), cmap=self.cmap, interpolation='none')\n",
    "        weights_left = np.array(data[\"weights_left\"]).reshape((120, 10))\n",
    "        weights_right = np.array(data[\"weights_right\"]).reshape((120, 10))\n",
    "\n",
    "        vmin = min(weights_left.min(), weights_right.min())\n",
    "        vmax = max(weights_left.max(), weights_right.max())\n",
    "        norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "        im_left = self.weights_ax[0].imshow(weights_left, cmap=self.cmap, interpolation='none', norm=norm)\n",
    "        im_right = self.weights_ax[1].imshow(weights_right, cmap=self.cmap, interpolation='none', norm=norm)\n",
    "\n",
    "        if not self.cbar:\n",
    "            self.cbar = self.weights_fig.colorbar(im_left, ax=self.weights_ax, orientation='vertical', pad=0.01)\n",
    "        \n",
    "        self.cbar.update_normal(im_left)\n",
    "        \n",
    "        self.ax[0].cla()\n",
    "        self.ax[1].cla()\n",
    "        self.ax[2].cla()\n",
    "        self.ax[3].cla()\n",
    "\n",
    "        self.ax[0].plot(data[\"input_spikes\"][\"times\"], data[\"input_spikes\"][\"senders\"], \".k\", markersize=5)\n",
    "        self.ax[0].set_xlim(np.min(data[\"multimeter_right_events\"][\"times\"]), np.max(data[\"multimeter_right_events\"][\"times\"]))\n",
    "        \n",
    "        self.ax[1].plot(data[\"multimeter_right_events\"][\"times\"], data[\"multimeter_right_events\"][\"V_m\"], 'r')\n",
    "        self.ax[1].plot(data[\"multimeter_left_events\"][\"times\"], data[\"multimeter_left_events\"][\"V_m\"], 'b')\n",
    "        self.ax[1].set_xlim(np.min(data[\"multimeter_right_events\"][\"times\"]), np.max(data[\"multimeter_right_events\"][\"times\"]))\n",
    "        \n",
    "        self.ax[2].plot(data[\"output_spikes_left\"][\"times\"], data[\"output_spikes_left\"][\"senders\"], \".b\", markersize=5)\n",
    "        self.ax[2].plot(data[\"output_spikes_right\"][\"times\"], data[\"output_spikes_right\"][\"senders\"], \".r\", markersize=5)\n",
    "        #self.ax[2].set_xlim(np.min(data[\"multimeter_right_events\"][\"times\"]), np.max(data[\"multimeter_right_events\"][\"times\"]))\n",
    "        self.ax[2].set_ylabel(\"Output Neuron\")\n",
    "        self.ax[2].set_xlim(np.min(data[\"multimeter_right_events\"][\"times\"]), np.max(data[\"multimeter_right_events\"][\"times\"]))\n",
    "        \n",
    "        self.ax[3].plot(data[\"action_taken_times\"], [action.value for action in data[\"action_taken\"]], \"k\")\n",
    "        self.ax[3].set_ylabel(\"Action taken\")\n",
    "        self.ax[3].set_yticks([AgentAction.LEFT.value, AgentAction.RIGHT.value])\n",
    "        self.ax[3].set_yticklabels([\"LEFT\", \"RIGHT\"])\n",
    "        self.ax[3].set_xlim(np.min(data[\"multimeter_right_events\"][\"times\"]), np.max(data[\"multimeter_right_events\"][\"times\"]))\n",
    "        \n",
    "        # Top plot for spikes\n",
    "        self.ax[0].set_xlabel(\"Time [ms]\")\n",
    "        #self.ax[0].set_yticks([])  # No Y-ticks\n",
    "        self.ax[0].set_ylabel(\"Input Neuron\")\n",
    "        self.ax[0].set_ylim(0, data[\"n_input_neurons\"])\n",
    "        #self.ax[0].set_xlim(0, 40)  # Set the x-axis limits\n",
    "        \n",
    "        # Bottom plot for membrane potential\n",
    "        self.ax[1].set_ylabel(\"V_m [mV]\")\n",
    "        \n",
    "        if not data[\"episode_number\"] in self.episode_number:\n",
    "            self.episode_number.append(data[\"episode_number\"])\n",
    "            self.steps_per_episode.append(data[\"steps_per_episode\"])\n",
    "        else:\n",
    "            idx = self.episode_number.index(data[\"episode_number\"])\n",
    "            self.steps_per_episode[idx] = data[\"steps_per_episode\"]\n",
    "\n",
    "        print(\"episode_number = \" + str(self.episode_number))\n",
    "        print(\"steps_per_episode = \" + str(self.steps_per_episode))\n",
    "\n",
    "        self.max_lifetime = np.amax(self.steps_per_episode)\n",
    "        self.lifetime_line.set_data(self.episode_number, self.steps_per_episode)\n",
    "        self.lifetime_ax.set_xlim(self.episode_number[0], self.episode_number[-1])\n",
    "        self.lifetime_ax.set_ylim(0, self.max_lifetime)\n",
    "        \n",
    "        self.ax[-1].set_xlabel(\"Time [ms]\")\n",
    "        \n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.savefig(\"/tmp/cartpole.png\", dpi=300)\n",
    "        self.fig.canvas.flush_events()\n",
    "        \n",
    "        self.lifetime_fig.canvas.draw()\n",
    "        self.lifetime_fig.savefig(\"/tmp/cartpole_lifetime.png\", dpi=300)\n",
    "        self.lifetime_fig.canvas.flush_events()\n",
    "        \n",
    "        self.weights_fig.canvas.draw()\n",
    "        self.weights_fig.savefig(\"/tmp/cartpole_weights.png\", dpi=300)\n",
    "        self.weights_fig.canvas.flush_events()\n",
    "        \n",
    "        plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3519392",
   "metadata": {},
   "source": [
    "## Neuron Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc47382",
   "metadata": {},
   "source": [
    "### Ignore and Fire Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e16ea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              -- N E S T --\n",
      "  Copyright (C) 2004 The NEST Initiative\n",
      "\n",
      " Version: 3.7.0\n",
      " Built: Mar 12 2025 18:15:33\n",
      "\n",
      " This program is provided AS IS and comes with\n",
      " NO WARRANTY. See the file LICENSE for details.\n",
      "\n",
      " Problems or suggestions?\n",
      "   Visit https://www.nest-simulator.org\n",
      "\n",
      " Type 'nest.help()' to find out more about NEST.\n",
      "\n",
      "\n",
      "              -- N E S T --\n",
      "  Copyright (C) 2004 The NEST Initiative\n",
      "\n",
      " Version: 3.7.0\n",
      " Built: Mar 12 2025 18:15:33\n",
      "\n",
      " This program is provided AS IS and comes with\n",
      " NO WARRANTY. See the file LICENSE for details.\n",
      "\n",
      " Problems or suggestions?\n",
      "   Visit https://www.nest-simulator.org\n",
      "\n",
      " Type 'nest.help()' to find out more about NEST.\n",
      "\n",
      "[12,ignore_and_fire_neuron_nestml, WARNING, [35:34;35:58]]: Model contains a call to fixed-timestep functions (``resolution()`` and/or ``steps()``). This restricts the model to being compatible only with fixed-timestep simulators. Consider eliminating ``resolution()`` and ``steps()`` from the model, and using ``timestep()`` instead.\n",
      "[1,GLOBAL, INFO]: List of files that will be processed:\n",
      "[2,GLOBAL, INFO]: /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/iaf_psc_exp_neuron.nestml\n",
      "[3,GLOBAL, INFO]: /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/neuromodulated_stdp_synapse.nestml\n",
      "[4,GLOBAL, INFO]: Target platform code will be generated in directory: '/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target'\n",
      "[5,GLOBAL, INFO]: Target platform code will be installed in directory: '/tmp/nestml_target_h3zr0n32'\n",
      "\n",
      "              -- N E S T --\n",
      "  Copyright (C) 2004 The NEST Initiative\n",
      "\n",
      " Version: 3.7.0\n",
      " Built: Mar 12 2025 18:15:33\n",
      "\n",
      " This program is provided AS IS and comes with\n",
      " NO WARRANTY. See the file LICENSE for details.\n",
      "\n",
      " Problems or suggestions?\n",
      "   Visit https://www.nest-simulator.org\n",
      "\n",
      " Type 'nest.help()' to find out more about NEST.\n",
      "\n",
      "[6,GLOBAL, INFO]: The NEST Simulator version was automatically detected as: v3.7.0\n",
      "[7,GLOBAL, INFO]: Given template root path is not an absolute path. Creating the absolute path with default templates directory '/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/pynestml/codegeneration/resources_nest/point_neuron'\n",
      "[8,GLOBAL, INFO]: The NEST Simulator installation path was automatically detected as: /home/charl/julich/nest-simulator-install\n",
      "[9,GLOBAL, INFO]: Start processing '/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/iaf_psc_exp_neuron.nestml'!\n",
      "[10,iaf_psc_exp_neuron_nestml, INFO, [37:19;37:19]]: Implicit casting from (compatible) type 'integer' to 'real'.\n",
      "[11,iaf_psc_exp_neuron_nestml, INFO, [40:17;40:17]]: Implicit casting from (compatible) type 'integer' to 'real'.\n",
      "[12,iaf_psc_exp_neuron_nestml, INFO, [53:15;53:32]]: Implicit casting from (compatible) type '1 / s buffer' to 'real'.\n",
      "[13,GLOBAL, INFO]: Start processing '/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/neuromodulated_stdp_synapse.nestml'!\n",
      "[14,neuromodulated_stdp_synapse_nestml, INFO, [8:17;8:17]]: Implicit casting from (compatible) type 'integer' to 'real'.\n",
      "[15,neuromodulated_stdp_synapse_nestml, INFO, [9:19;9:19]]: Implicit casting from (compatible) type 'integer' to 'real'.\n",
      "[16,neuromodulated_stdp_synapse_nestml, INFO, [24:23;24:23]]: Implicit casting from (compatible) type 'integer' to 'real'.\n",
      "[17,iaf_psc_exp_neuron_nestml, WARNING, [40:8;40:17]]: Variable 's' has the same name as a physical unit!\n",
      "[18,iaf_psc_exp_neuron_nestml, WARNING, [26:16;26:42]]: Implicit casting from (compatible) type 'mV' to 'real'.\n",
      "[19,iaf_psc_exp_neuron_nestml, WARNING, [26:16;26:48]]: Implicit casting from (compatible) type 'mV' to 'real buffer'.\n",
      "[20,neuromodulated_stdp_synapse_nestml, WARNING, [15:8;15:17]]: Variable 'd' has the same name as a physical unit!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Analysing input:\n",
      "INFO:{\n",
      "    \"dynamics\": [\n",
      "        {\n",
      "            \"expression\": \"g_e' = (-g_e) / tau_g\",\n",
      "            \"initial_values\": {\n",
      "                \"g_e\": \"0.0\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"expression\": \"V_m' = (g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\",\n",
      "            \"initial_values\": {\n",
      "                \"V_m\": \"E_l\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"options\": {\n",
      "        \"output_timestep_symbol\": \"__h\"\n",
      "    },\n",
      "    \"parameters\": {\n",
      "        \"E_e\": \"0\",\n",
      "        \"E_l\": \"(-74)\",\n",
      "        \"I_e\": \"0\",\n",
      "        \"V_reset\": \"(-60)\",\n",
      "        \"V_th\": \"(-54)\",\n",
      "        \"s\": \"1000\",\n",
      "        \"tau_g\": \"5\",\n",
      "        \"tau_m\": \"10\"\n",
      "    }\n",
      "}\n",
      "INFO:Processing global options...\n",
      "INFO:Processing input shapes...\n",
      "INFO:\n",
      "Processing differential-equation form shape g_e with defining expression = \"(-g_e) / tau_g\"\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol g_e, derivative_factors = [-1/tau_g], inhom_term = 0.0, nonlin_term = 0.0\n",
      "INFO:\tReturning shape: Shape \"g_e\" of order 1\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "INFO:\n",
      "Processing differential-equation form shape V_m with defining expression = \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "DEBUG:Splitting expression (E_l + I_e + I_stim - V_m + g_e*(E_e - V_m))/tau_m (symbols [V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_m]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m\n",
      "DEBUG:\tnonlinear term: E_e*g_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m\n",
      "DEBUG:Created Shape with symbol V_m, derivative_factors = [-1/tau_m], inhom_term = E_l/tau_m + I_e/tau_m, nonlin_term = E_e*g_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m\n",
      "INFO:\tReturning shape: Shape \"V_m\" of order 1\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "INFO:All known variables: [g_e, V_m], all parameters used in ODEs: {I_e, I_stim, tau_m, E_l, tau_g, E_e}\n",
      "INFO:No numerical value specified for parameter \"I_stim\"\n",
      "INFO:\n",
      "Processing differential-equation form shape g_e with defining expression = \"(-g_e) / tau_g\"\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e, V_m, g_e])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol g_e, derivative_factors = [-1/tau_g], inhom_term = 0.0, nonlin_term = 0\n",
      "INFO:\tReturning shape: Shape \"g_e\" of order 1\n",
      "INFO:\n",
      "Processing differential-equation form shape V_m with defining expression = \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "DEBUG:Splitting expression (E_l + I_e + I_stim - V_m + g_e*(E_e - V_m))/tau_m (symbols [g_e, V_m, g_e, V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "DEBUG:Created Shape with symbol V_m, derivative_factors = [-1/tau_m], inhom_term = E_l/tau_m + I_e/tau_m + I_stim/tau_m, nonlin_term = E_e*g_e/tau_m - V_m*g_e/tau_m\n",
      "INFO:\tReturning shape: Shape \"V_m\" of order 1\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,GLOBAL, INFO]: State variables that will be moved from synapse to neuron: ['post_trace']\n",
      "[22,GLOBAL, INFO]: Parameters that will be copied from synapse to neuron: ['tau_tr_post']\n",
      "[23,GLOBAL, INFO]: Synaptic state variables moved to neuron that will need buffering: []\n",
      "[24,GLOBAL, INFO]: Moving state var defining equation(s) post_trace\n",
      "[25,GLOBAL, INFO]: Moving state variables for equation(s) post_trace\n",
      "[26,GLOBAL, INFO]: Moving definition of post_trace from synapse to neuron\n",
      "[27,GLOBAL, INFO]: \tMoving statement post_trace += -1.05e-07 # XXX FIXME!!!! should be ``+= post_trace_increment``\n",
      "[28,GLOBAL, INFO]: In synapse: replacing ``continuous`` type input ports that are connected to postsynaptic neuron with external variable references\n",
      "[29,GLOBAL, INFO]: Copying parameters from synapse to neuron...\n",
      "[30,GLOBAL, INFO]: Copying definition of tau_tr_post from synapse to neuron\n",
      "[31,GLOBAL, INFO]: Adding suffix to variables in spike updates\n",
      "[32,GLOBAL, INFO]: In synapse: replacing variables with suffixed external variable references\n",
      "[33,GLOBAL, INFO]: \t• Replacing variable post_trace\n",
      "[34,GLOBAL, INFO]: Successfully constructed neuron-synapse pair iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml, neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml\n",
      "[35,GLOBAL, INFO]: Analysing/transforming model 'iaf_psc_exp_neuron_nestml'\n",
      "[36,iaf_psc_exp_neuron_nestml, INFO, [18:0;58:0]]: Starts processing of the model 'iaf_psc_exp_neuron_nestml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Splitting expression -g_e/tau_g (symbols Matrix([[g_e], [V_m]]))\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "DEBUG:Splitting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m (symbols Matrix([[g_e], [V_m]]))\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[g_e], [V_m]]), A = Matrix([[-1/tau_g, 0], [E_e/tau_m, -1/tau_m]]), b = Matrix([[0], [E_l/tau_m + I_e/tau_m + I_stim/tau_m]]), c = Matrix([[0], [-V_m*g_e/tau_m]])\n",
      "INFO:Finding analytically solvable equations...\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph.dot']\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e, V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "DEBUG:Splitting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m (symbols [g_e, V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable_before_propagated.dot']\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable.dot']\n",
      "INFO:Generating propagators for the following symbols: g_e\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[g_e]]), A = Matrix([[-1/tau_g]]), b = Matrix([[0]]), c = Matrix([[0]])\n",
      "DEBUG:System of equations:\n",
      "DEBUG:x = Matrix([[g_e]])\n",
      "DEBUG:A = Matrix([[-1/tau_g]])\n",
      "DEBUG:b = Matrix([[0]])\n",
      "DEBUG:c = Matrix([[0]])\n",
      "INFO:update_expr[g_e] = __P__g_e__g_e*g_e\n",
      "INFO:Generating numerical solver for the following symbols: V_m\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[V_m]]), A = Matrix([[-1/tau_m]]), b = Matrix([[E_l/tau_m + I_e/tau_m + I_stim/tau_m]]), c = Matrix([[E_e*g_e/tau_m - V_m*g_e/tau_m]])\n",
      "WARNING:Not preserving expression for variable \"g_e\" as it is solved by propagator solver\n",
      "INFO:Preserving expression for variable \"V_m\"\n",
      "INFO:In ode-toolbox: returning outdict = \n",
      "INFO:[\n",
      "    {\n",
      "        \"initial_values\": {\n",
      "            \"g_e\": \"0.0\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"tau_g\": \"5.00000000000000\"\n",
      "        },\n",
      "        \"propagators\": {\n",
      "            \"__P__g_e__g_e\": \"exp(-__h/tau_g)\"\n",
      "        },\n",
      "        \"solver\": \"analytical\",\n",
      "        \"state_variables\": [\n",
      "            \"g_e\"\n",
      "        ],\n",
      "        \"update_expressions\": {\n",
      "            \"g_e\": \"__P__g_e__g_e*g_e\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"initial_values\": {\n",
      "            \"V_m\": \"E_l\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"E_e\": \"0\",\n",
      "            \"E_l\": \"-74.0000000000000\",\n",
      "            \"I_e\": \"0\",\n",
      "            \"tau_m\": \"10.0000000000000\"\n",
      "        },\n",
      "        \"solver\": \"numeric\",\n",
      "        \"state_variables\": [\n",
      "            \"V_m\"\n",
      "        ],\n",
      "        \"update_expressions\": {\n",
      "            \"V_m\": \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "        }\n",
      "    }\n",
      "]\n",
      "INFO:Analysing input:\n",
      "INFO:{\n",
      "    \"dynamics\": [\n",
      "        {\n",
      "            \"expression\": \"g_e' = (-g_e) / tau_g\",\n",
      "            \"initial_values\": {\n",
      "                \"g_e\": \"0.0\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"expression\": \"V_m' = (g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\",\n",
      "            \"initial_values\": {\n",
      "                \"V_m\": \"E_l\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"options\": {\n",
      "        \"output_timestep_symbol\": \"__h\"\n",
      "    },\n",
      "    \"parameters\": {\n",
      "        \"E_e\": \"0\",\n",
      "        \"E_l\": \"(-74)\",\n",
      "        \"I_e\": \"0\",\n",
      "        \"V_reset\": \"(-60)\",\n",
      "        \"V_th\": \"(-54)\",\n",
      "        \"s\": \"1000\",\n",
      "        \"tau_g\": \"5\",\n",
      "        \"tau_m\": \"10\"\n",
      "    }\n",
      "}\n",
      "INFO:Processing global options...\n",
      "INFO:Processing input shapes...\n",
      "INFO:\n",
      "Processing differential-equation form shape g_e with defining expression = \"(-g_e) / tau_g\"\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol g_e, derivative_factors = [-1/tau_g], inhom_term = 0.0, nonlin_term = 0.0\n",
      "INFO:\tReturning shape: Shape \"g_e\" of order 1\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "INFO:\n",
      "Processing differential-equation form shape V_m with defining expression = \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "DEBUG:Splitting expression (E_l + I_e + I_stim - V_m + g_e*(E_e - V_m))/tau_m (symbols [V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_m]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m\n",
      "DEBUG:\tnonlinear term: E_e*g_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m\n",
      "DEBUG:Created Shape with symbol V_m, derivative_factors = [-1/tau_m], inhom_term = E_l/tau_m + I_e/tau_m, nonlin_term = E_e*g_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m\n",
      "INFO:\tReturning shape: Shape \"V_m\" of order 1\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "INFO:All known variables: [g_e, V_m], all parameters used in ODEs: {I_e, I_stim, tau_m, E_l, tau_g, E_e}\n",
      "INFO:No numerical value specified for parameter \"I_stim\"\n",
      "INFO:\n",
      "Processing differential-equation form shape g_e with defining expression = \"(-g_e) / tau_g\"\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e, V_m, g_e])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol g_e, derivative_factors = [-1/tau_g], inhom_term = 0.0, nonlin_term = 0\n",
      "INFO:\tReturning shape: Shape \"g_e\" of order 1\n",
      "INFO:\n",
      "Processing differential-equation form shape V_m with defining expression = \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "DEBUG:Splitting expression (E_l + I_e + I_stim - V_m + g_e*(E_e - V_m))/tau_m (symbols [g_e, V_m, g_e, V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "DEBUG:Created Shape with symbol V_m, derivative_factors = [-1/tau_m], inhom_term = E_l/tau_m + I_e/tau_m + I_stim/tau_m, nonlin_term = E_e*g_e/tau_m - V_m*g_e/tau_m\n",
      "INFO:\tReturning shape: Shape \"V_m\" of order 1\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols Matrix([[g_e], [V_m]]))\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "DEBUG:Splitting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m (symbols Matrix([[g_e], [V_m]]))\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[g_e], [V_m]]), A = Matrix([[-1/tau_g, 0], [E_e/tau_m, -1/tau_m]]), b = Matrix([[0], [E_l/tau_m + I_e/tau_m + I_stim/tau_m]]), c = Matrix([[0], [-V_m*g_e/tau_m]])\n",
      "INFO:Finding analytically solvable equations...\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph.dot'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph.dot']\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e, V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "DEBUG:Splitting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m (symbols [g_e, V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable_before_propagated.dot']\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable.dot']\n",
      "INFO:Generating numerical solver for the following symbols: V_m, g_e\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[g_e], [V_m]]), A = Matrix([[-1/tau_g, 0], [E_e/tau_m, -1/tau_m]]), b = Matrix([[0], [E_l/tau_m + I_e/tau_m + I_stim/tau_m]]), c = Matrix([[0], [-V_m*g_e/tau_m]])\n",
      "INFO:Preserving expression for variable \"g_e\"\n",
      "INFO:Preserving expression for variable \"V_m\"\n",
      "INFO:In ode-toolbox: returning outdict = \n",
      "INFO:[\n",
      "    {\n",
      "        \"initial_values\": {\n",
      "            \"V_m\": \"E_l\",\n",
      "            \"g_e\": \"0.0\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"E_e\": \"0\",\n",
      "            \"E_l\": \"-74.0000000000000\",\n",
      "            \"I_e\": \"0\",\n",
      "            \"tau_g\": \"5.00000000000000\",\n",
      "            \"tau_m\": \"10.0000000000000\"\n",
      "        },\n",
      "        \"solver\": \"numeric\",\n",
      "        \"state_variables\": [\n",
      "            \"g_e\",\n",
      "            \"V_m\"\n",
      "        ],\n",
      "        \"update_expressions\": {\n",
      "            \"V_m\": \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\",\n",
      "            \"g_e\": \"(-g_e) / tau_g\"\n",
      "        }\n",
      "    }\n",
      "]\n",
      "INFO:Analysing input:\n",
      "INFO:{\n",
      "    \"dynamics\": [\n",
      "        {\n",
      "            \"expression\": \"g_e' = (-g_e) / tau_g\",\n",
      "            \"initial_values\": {\n",
      "                \"g_e\": \"0.0\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"expression\": \"V_m' = (g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\",\n",
      "            \"initial_values\": {\n",
      "                \"V_m\": \"E_l\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"expression\": \"post_trace__for_neuromodulated_stdp_synapse_nestml' = (-post_trace__for_neuromodulated_stdp_synapse_nestml) / tau_tr_post__for_neuromodulated_stdp_synapse_nestml\",\n",
      "            \"initial_values\": {\n",
      "                \"post_trace__for_neuromodulated_stdp_synapse_nestml\": \"0.0\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"options\": {\n",
      "        \"output_timestep_symbol\": \"__h\"\n",
      "    },\n",
      "    \"parameters\": {\n",
      "        \"E_e\": \"0\",\n",
      "        \"E_l\": \"(-74)\",\n",
      "        \"I_e\": \"0\",\n",
      "        \"V_reset\": \"(-60)\",\n",
      "        \"V_th\": \"(-54)\",\n",
      "        \"s\": \"1000\",\n",
      "        \"tau_g\": \"5\",\n",
      "        \"tau_m\": \"10\",\n",
      "        \"tau_tr_post__for_neuromodulated_stdp_synapse_nestml\": \"20\"\n",
      "    }\n",
      "}\n",
      "INFO:Processing global options...\n",
      "INFO:Processing input shapes...\n",
      "INFO:\n",
      "Processing differential-equation form shape g_e with defining expression = \"(-g_e) / tau_g\"\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol g_e, derivative_factors = [-1/tau_g], inhom_term = 0.0, nonlin_term = 0.0\n",
      "INFO:\tReturning shape: Shape \"g_e\" of order 1\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "INFO:\n",
      "Processing differential-equation form shape V_m with defining expression = \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "DEBUG:Splitting expression (E_l + I_e + I_stim - V_m + g_e*(E_e - V_m))/tau_m (symbols [V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_m]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m\n",
      "DEBUG:\tnonlinear term: E_e*g_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m\n",
      "DEBUG:Created Shape with symbol V_m, derivative_factors = [-1/tau_m], inhom_term = E_l/tau_m + I_e/tau_m, nonlin_term = E_e*g_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m\n",
      "INFO:\tReturning shape: Shape \"V_m\" of order 1\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "INFO:\n",
      "Processing differential-equation form shape post_trace__for_neuromodulated_stdp_synapse_nestml with defining expression = \"(-post_trace__for_neuromodulated_stdp_synapse_nestml) / tau_tr_post__for_neuromodulated_stdp_synapse_nestml\"\n",
      "DEBUG:Splitting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml (symbols [post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol post_trace__for_neuromodulated_stdp_synapse_nestml, derivative_factors = [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml], inhom_term = 0.0, nonlin_term = 0.0\n",
      "INFO:\tReturning shape: Shape \"post_trace__for_neuromodulated_stdp_synapse_nestml\" of order 1\n",
      "INFO:Shape post_trace__for_neuromodulated_stdp_synapse_nestml: reconstituting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml\n",
      "INFO:All known variables: [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml], all parameters used in ODEs: {I_e, I_stim, tau_m, tau_tr_post__for_neuromodulated_stdp_synapse_nestml, E_l, tau_g, E_e}\n",
      "INFO:No numerical value specified for parameter \"I_stim\"\n",
      "INFO:\n",
      "Processing differential-equation form shape g_e with defining expression = \"(-g_e) / tau_g\"\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml, g_e])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol g_e, derivative_factors = [-1/tau_g], inhom_term = 0.0, nonlin_term = 0\n",
      "INFO:\tReturning shape: Shape \"g_e\" of order 1\n",
      "INFO:\n",
      "Processing differential-equation form shape V_m with defining expression = \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "DEBUG:Splitting expression (E_l + I_e + I_stim - V_m + g_e*(E_e - V_m))/tau_m (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml, g_e, V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m], [0], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "DEBUG:Created Shape with symbol V_m, derivative_factors = [-1/tau_m], inhom_term = E_l/tau_m + I_e/tau_m + I_stim/tau_m, nonlin_term = E_e*g_e/tau_m - V_m*g_e/tau_m\n",
      "INFO:\tReturning shape: Shape \"V_m\" of order 1\n",
      "INFO:\n",
      "Processing differential-equation form shape post_trace__for_neuromodulated_stdp_synapse_nestml with defining expression = \"(-post_trace__for_neuromodulated_stdp_synapse_nestml) / tau_tr_post__for_neuromodulated_stdp_synapse_nestml\"\n",
      "DEBUG:Splitting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml, g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[0], [0], [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml], [0], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol post_trace__for_neuromodulated_stdp_synapse_nestml, derivative_factors = [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml], inhom_term = 0.0, nonlin_term = 0\n",
      "INFO:\tReturning shape: Shape \"post_trace__for_neuromodulated_stdp_synapse_nestml\" of order 1\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "DEBUG:Splitting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m (symbols Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]))\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m], [0]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "INFO:Shape post_trace__for_neuromodulated_stdp_synapse_nestml: reconstituting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml\n",
      "DEBUG:Splitting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml (symbols Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]))\n",
      "DEBUG:\tlinear factors: Matrix([[0], [0], [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]), A = Matrix([[-1/tau_g, 0, 0], [E_e/tau_m, -1/tau_m, 0], [0, 0, -1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]]), b = Matrix([[0], [E_l/tau_m + I_e/tau_m + I_stim/tau_m], [0]]), c = Matrix([[0], [-V_m*g_e/tau_m], [0]])\n",
      "INFO:Finding analytically solvable equations...\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph.dot']\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "DEBUG:Splitting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m], [0]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "INFO:Shape post_trace__for_neuromodulated_stdp_synapse_nestml: reconstituting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml\n",
      "DEBUG:Splitting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[0], [0], [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable_before_propagated.dot']\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable.dot']\n",
      "INFO:Generating propagators for the following symbols: g_e, post_trace__for_neuromodulated_stdp_synapse_nestml\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[g_e], [post_trace__for_neuromodulated_stdp_synapse_nestml]]), A = Matrix([[-1/tau_g, 0], [0, -1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]]), b = Matrix([[0], [0]]), c = Matrix([[0], [0]])\n",
      "DEBUG:System of equations:\n",
      "DEBUG:x = Matrix([[g_e], [post_trace__for_neuromodulated_stdp_synapse_nestml]])\n",
      "DEBUG:A = Matrix([\n",
      "[-1/tau_g,                                                      0],\n",
      "[       0, -1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]])\n",
      "DEBUG:b = Matrix([[0], [0]])\n",
      "DEBUG:c = Matrix([[0], [0]])\n",
      "INFO:update_expr[g_e] = __P__g_e__g_e*g_e\n",
      "INFO:update_expr[post_trace__for_neuromodulated_stdp_synapse_nestml] = __P__post_trace__for_neuromodulated_stdp_synapse_nestml__post_trace__for_neuromodulated_stdp_synapse_nestml*post_trace__for_neuromodulated_stdp_synapse_nestml\n",
      "INFO:Generating numerical solver for the following symbols: V_m\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[V_m]]), A = Matrix([[-1/tau_m]]), b = Matrix([[E_l/tau_m + I_e/tau_m + I_stim/tau_m]]), c = Matrix([[E_e*g_e/tau_m - V_m*g_e/tau_m]])\n",
      "WARNING:Not preserving expression for variable \"g_e\" as it is solved by propagator solver\n",
      "WARNING:Not preserving expression for variable \"post_trace__for_neuromodulated_stdp_synapse_nestml\" as it is solved by propagator solver\n",
      "INFO:Preserving expression for variable \"V_m\"\n",
      "INFO:In ode-toolbox: returning outdict = \n",
      "INFO:[\n",
      "    {\n",
      "        \"initial_values\": {\n",
      "            \"g_e\": \"0.0\",\n",
      "            \"post_trace__for_neuromodulated_stdp_synapse_nestml\": \"0.0\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"tau_g\": \"5.00000000000000\",\n",
      "            \"tau_tr_post__for_neuromodulated_stdp_synapse_nestml\": \"20.0000000000000\"\n",
      "        },\n",
      "        \"propagators\": {\n",
      "            \"__P__g_e__g_e\": \"exp(-__h/tau_g)\",\n",
      "            \"__P__post_trace__for_neuromodulated_stdp_synapse_nestml__post_trace__for_neuromodulated_stdp_synapse_nestml\": \"exp(-__h/tau_tr_post__for_neuromodulated_stdp_synapse_nestml)\"\n",
      "        },\n",
      "        \"solver\": \"analytical\",\n",
      "        \"state_variables\": [\n",
      "            \"g_e\",\n",
      "            \"post_trace__for_neuromodulated_stdp_synapse_nestml\"\n",
      "        ],\n",
      "        \"update_expressions\": {\n",
      "            \"g_e\": \"__P__g_e__g_e*g_e\",\n",
      "            \"post_trace__for_neuromodulated_stdp_synapse_nestml\": \"__P__post_trace__for_neuromodulated_stdp_synapse_nestml__post_trace__for_neuromodulated_stdp_synapse_nestml*post_trace__for_neuromodulated_stdp_synapse_nestml\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"initial_values\": {\n",
      "            \"V_m\": \"E_l\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"E_e\": \"0\",\n",
      "            \"E_l\": \"-74.0000000000000\",\n",
      "            \"I_e\": \"0\",\n",
      "            \"tau_m\": \"10.0000000000000\"\n",
      "        },\n",
      "        \"solver\": \"numeric\",\n",
      "        \"state_variables\": [\n",
      "            \"V_m\"\n",
      "        ],\n",
      "        \"update_expressions\": {\n",
      "            \"V_m\": \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "        }\n",
      "    }\n",
      "]\n",
      "INFO:Analysing input:\n",
      "INFO:{\n",
      "    \"dynamics\": [\n",
      "        {\n",
      "            \"expression\": \"g_e' = (-g_e) / tau_g\",\n",
      "            \"initial_values\": {\n",
      "                \"g_e\": \"0.0\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"expression\": \"V_m' = (g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\",\n",
      "            \"initial_values\": {\n",
      "                \"V_m\": \"E_l\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"expression\": \"post_trace__for_neuromodulated_stdp_synapse_nestml' = (-post_trace__for_neuromodulated_stdp_synapse_nestml) / tau_tr_post__for_neuromodulated_stdp_synapse_nestml\",\n",
      "            \"initial_values\": {\n",
      "                \"post_trace__for_neuromodulated_stdp_synapse_nestml\": \"0.0\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"options\": {\n",
      "        \"output_timestep_symbol\": \"__h\"\n",
      "    },\n",
      "    \"parameters\": {\n",
      "        \"E_e\": \"0\",\n",
      "        \"E_l\": \"(-74)\",\n",
      "        \"I_e\": \"0\",\n",
      "        \"V_reset\": \"(-60)\",\n",
      "        \"V_th\": \"(-54)\",\n",
      "        \"s\": \"1000\",\n",
      "        \"tau_g\": \"5\",\n",
      "        \"tau_m\": \"10\",\n",
      "        \"tau_tr_post__for_neuromodulated_stdp_synapse_nestml\": \"20\"\n",
      "    }\n",
      "}\n",
      "INFO:Processing global options...\n",
      "INFO:Processing input shapes...\n",
      "INFO:\n",
      "Processing differential-equation form shape g_e with defining expression = \"(-g_e) / tau_g\"\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol g_e, derivative_factors = [-1/tau_g], inhom_term = 0.0, nonlin_term = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:\tReturning shape: Shape \"g_e\" of order 1\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "INFO:\n",
      "Processing differential-equation form shape V_m with defining expression = \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "DEBUG:Splitting expression (E_l + I_e + I_stim - V_m + g_e*(E_e - V_m))/tau_m (symbols [V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_m]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m\n",
      "DEBUG:\tnonlinear term: E_e*g_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m\n",
      "DEBUG:Created Shape with symbol V_m, derivative_factors = [-1/tau_m], inhom_term = E_l/tau_m + I_e/tau_m, nonlin_term = E_e*g_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m\n",
      "INFO:\tReturning shape: Shape \"V_m\" of order 1\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "INFO:\n",
      "Processing differential-equation form shape post_trace__for_neuromodulated_stdp_synapse_nestml with defining expression = \"(-post_trace__for_neuromodulated_stdp_synapse_nestml) / tau_tr_post__for_neuromodulated_stdp_synapse_nestml\"\n",
      "DEBUG:Splitting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml (symbols [post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol post_trace__for_neuromodulated_stdp_synapse_nestml, derivative_factors = [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml], inhom_term = 0.0, nonlin_term = 0.0\n",
      "INFO:\tReturning shape: Shape \"post_trace__for_neuromodulated_stdp_synapse_nestml\" of order 1\n",
      "INFO:Shape post_trace__for_neuromodulated_stdp_synapse_nestml: reconstituting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml\n",
      "INFO:All known variables: [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml], all parameters used in ODEs: {I_e, I_stim, tau_m, tau_tr_post__for_neuromodulated_stdp_synapse_nestml, E_l, tau_g, E_e}\n",
      "INFO:No numerical value specified for parameter \"I_stim\"\n",
      "INFO:\n",
      "Processing differential-equation form shape g_e with defining expression = \"(-g_e) / tau_g\"\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml, g_e])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol g_e, derivative_factors = [-1/tau_g], inhom_term = 0.0, nonlin_term = 0\n",
      "INFO:\tReturning shape: Shape \"g_e\" of order 1\n",
      "INFO:\n",
      "Processing differential-equation form shape V_m with defining expression = \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\"\n",
      "DEBUG:Splitting expression (E_l + I_e + I_stim - V_m + g_e*(E_e - V_m))/tau_m (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml, g_e, V_m])\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m], [0], [0], [0]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37,GLOBAL, INFO]: Analysing/transforming model 'iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml'\n",
      "[38,iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml, INFO, [18:0;58:0]]: Starts processing of the model 'iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "DEBUG:Created Shape with symbol V_m, derivative_factors = [-1/tau_m], inhom_term = E_l/tau_m + I_e/tau_m + I_stim/tau_m, nonlin_term = E_e*g_e/tau_m - V_m*g_e/tau_m\n",
      "INFO:\tReturning shape: Shape \"V_m\" of order 1\n",
      "INFO:\n",
      "Processing differential-equation form shape post_trace__for_neuromodulated_stdp_synapse_nestml with defining expression = \"(-post_trace__for_neuromodulated_stdp_synapse_nestml) / tau_tr_post__for_neuromodulated_stdp_synapse_nestml\"\n",
      "DEBUG:Splitting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml, g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[0], [0], [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml], [0], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol post_trace__for_neuromodulated_stdp_synapse_nestml, derivative_factors = [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml], inhom_term = 0.0, nonlin_term = 0\n",
      "INFO:\tReturning shape: Shape \"post_trace__for_neuromodulated_stdp_synapse_nestml\" of order 1\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]))\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "DEBUG:Splitting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m (symbols Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]))\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m], [0]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "INFO:Shape post_trace__for_neuromodulated_stdp_synapse_nestml: reconstituting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml\n",
      "DEBUG:Splitting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml (symbols Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]))\n",
      "DEBUG:\tlinear factors: Matrix([[0], [0], [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]), A = Matrix([[-1/tau_g, 0, 0], [E_e/tau_m, -1/tau_m, 0], [0, 0, -1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]]), b = Matrix([[0], [E_l/tau_m + I_e/tau_m + I_stim/tau_m], [0]]), c = Matrix([[0], [-V_m*g_e/tau_m], [0]])\n",
      "INFO:Finding analytically solvable equations...\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph.dot']\n",
      "INFO:Shape g_e: reconstituting expression -g_e/tau_g\n",
      "DEBUG:Splitting expression -g_e/tau_g (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_g], [0], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Shape V_m: reconstituting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m\n",
      "DEBUG:Splitting expression E_e*g_e/tau_m + E_l/tau_m + I_e/tau_m + I_stim/tau_m - V_m*g_e/tau_m - V_m/tau_m (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[E_e/tau_m], [-1/tau_m], [0]])\n",
      "DEBUG:\tinhomogeneous term: E_l/tau_m + I_e/tau_m + I_stim/tau_m\n",
      "DEBUG:\tnonlinear term: -V_m*g_e/tau_m\n",
      "INFO:Shape post_trace__for_neuromodulated_stdp_synapse_nestml: reconstituting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml\n",
      "DEBUG:Splitting expression -post_trace__for_neuromodulated_stdp_synapse_nestml/tau_tr_post__for_neuromodulated_stdp_synapse_nestml (symbols [g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml])\n",
      "DEBUG:\tlinear factors: Matrix([[0], [0], [-1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable_before_propagated.dot']\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable.dot']\n",
      "INFO:Generating numerical solver for the following symbols: g_e, V_m, post_trace__for_neuromodulated_stdp_synapse_nestml\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[g_e], [V_m], [post_trace__for_neuromodulated_stdp_synapse_nestml]]), A = Matrix([[-1/tau_g, 0, 0], [E_e/tau_m, -1/tau_m, 0], [0, 0, -1/tau_tr_post__for_neuromodulated_stdp_synapse_nestml]]), b = Matrix([[0], [E_l/tau_m + I_e/tau_m + I_stim/tau_m], [0]]), c = Matrix([[0], [-V_m*g_e/tau_m], [0]])\n",
      "INFO:Preserving expression for variable \"g_e\"\n",
      "INFO:Preserving expression for variable \"V_m\"\n",
      "INFO:Preserving expression for variable \"post_trace__for_neuromodulated_stdp_synapse_nestml\"\n",
      "INFO:In ode-toolbox: returning outdict = \n",
      "INFO:[\n",
      "    {\n",
      "        \"initial_values\": {\n",
      "            \"V_m\": \"E_l\",\n",
      "            \"g_e\": \"0.0\",\n",
      "            \"post_trace__for_neuromodulated_stdp_synapse_nestml\": \"0.0\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"E_e\": \"0\",\n",
      "            \"E_l\": \"-74.0000000000000\",\n",
      "            \"I_e\": \"0\",\n",
      "            \"tau_g\": \"5.00000000000000\",\n",
      "            \"tau_m\": \"10.0000000000000\",\n",
      "            \"tau_tr_post__for_neuromodulated_stdp_synapse_nestml\": \"20.0000000000000\"\n",
      "        },\n",
      "        \"solver\": \"numeric\",\n",
      "        \"state_variables\": [\n",
      "            \"g_e\",\n",
      "            \"V_m\",\n",
      "            \"post_trace__for_neuromodulated_stdp_synapse_nestml\"\n",
      "        ],\n",
      "        \"update_expressions\": {\n",
      "            \"V_m\": \"(g_e * (E_e - V_m) + E_l - V_m + I_e + I_stim) / tau_m\",\n",
      "            \"g_e\": \"(-g_e) / tau_g\",\n",
      "            \"post_trace__for_neuromodulated_stdp_synapse_nestml\": \"(-post_trace__for_neuromodulated_stdp_synapse_nestml) / tau_tr_post__for_neuromodulated_stdp_synapse_nestml\"\n",
      "        }\n",
      "    }\n",
      "]\n",
      "INFO:Analysing input:\n",
      "INFO:{\n",
      "    \"dynamics\": [\n",
      "        {\n",
      "            \"expression\": \"pre_trace' = (-pre_trace) / tau_tr_pre\",\n",
      "            \"initial_values\": {\n",
      "                \"pre_trace\": \"0.0\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"options\": {\n",
      "        \"output_timestep_symbol\": \"__h\"\n",
      "    },\n",
      "    \"parameters\": {\n",
      "        \"Wmax\": \"100.0\",\n",
      "        \"Wmin\": \"0.0\",\n",
      "        \"beta\": \"0.01\",\n",
      "        \"d\": \"1\",\n",
      "        \"n\": \"0.0\",\n",
      "        \"post_trace_increment\": \"1.0\",\n",
      "        \"pre_trace_increment\": \"1.0\",\n",
      "        \"tau_tr_post\": \"20\",\n",
      "        \"tau_tr_pre\": \"20\",\n",
      "        \"wtr_max\": \"0.1\",\n",
      "        \"wtr_min\": \"0\"\n",
      "    }\n",
      "}\n",
      "INFO:Processing global options...\n",
      "INFO:Processing input shapes...\n",
      "INFO:\n",
      "Processing differential-equation form shape pre_trace with defining expression = \"(-pre_trace) / tau_tr_pre\"\n",
      "DEBUG:Splitting expression -pre_trace/tau_tr_pre (symbols [pre_trace])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_tr_pre]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol pre_trace, derivative_factors = [-1/tau_tr_pre], inhom_term = 0.0, nonlin_term = 0.0\n",
      "INFO:\tReturning shape: Shape \"pre_trace\" of order 1\n",
      "INFO:Shape pre_trace: reconstituting expression -pre_trace/tau_tr_pre\n",
      "INFO:All known variables: [pre_trace], all parameters used in ODEs: {tau_tr_pre}\n",
      "INFO:\n",
      "Processing differential-equation form shape pre_trace with defining expression = \"(-pre_trace) / tau_tr_pre\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Splitting expression -pre_trace/tau_tr_pre (symbols [pre_trace, pre_trace])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_tr_pre], [0]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Created Shape with symbol pre_trace, derivative_factors = [-1/tau_tr_pre], inhom_term = 0.0, nonlin_term = 0\n",
      "INFO:\tReturning shape: Shape \"pre_trace\" of order 1\n",
      "INFO:Shape pre_trace: reconstituting expression -pre_trace/tau_tr_pre\n",
      "DEBUG:Splitting expression -pre_trace/tau_tr_pre (symbols Matrix([[pre_trace]]))\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_tr_pre]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[pre_trace]]), A = Matrix([[-1/tau_tr_pre]]), b = Matrix([[0]]), c = Matrix([[0]])\n",
      "INFO:Finding analytically solvable equations...\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph.dot']\n",
      "INFO:Shape pre_trace: reconstituting expression -pre_trace/tau_tr_pre\n",
      "DEBUG:Splitting expression -pre_trace/tau_tr_pre (symbols [pre_trace])\n",
      "DEBUG:\tlinear factors: Matrix([[-1/tau_tr_pre]])\n",
      "DEBUG:\tinhomogeneous term: 0.0\n",
      "DEBUG:\tnonlinear term: 0.0\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable_before_propagated.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable_before_propagated.dot']\n",
      "INFO:Saving dependency graph plot to /tmp/ode_dependency_graph_analytically_solvable.dot\n",
      "DEBUG:os.makedirs('/tmp')\n",
      "DEBUG:write lines to '/tmp/ode_dependency_graph_analytically_solvable.dot'\n",
      "DEBUG:run [PosixPath('dot'), '-Kdot', '-Tpdf', '-O', 'ode_dependency_graph_analytically_solvable.dot']\n",
      "INFO:Generating propagators for the following symbols: pre_trace\n",
      "DEBUG:Initializing system of shapes with x = Matrix([[pre_trace]]), A = Matrix([[-1/tau_tr_pre]]), b = Matrix([[0]]), c = Matrix([[0]])\n",
      "DEBUG:System of equations:\n",
      "DEBUG:x = Matrix([[pre_trace]])\n",
      "DEBUG:A = Matrix([[-1/tau_tr_pre]])\n",
      "DEBUG:b = Matrix([[0]])\n",
      "DEBUG:c = Matrix([[0]])\n",
      "INFO:update_expr[pre_trace] = __P__pre_trace__pre_trace*pre_trace\n",
      "WARNING:Not preserving expression for variable \"pre_trace\" as it is solved by propagator solver\n",
      "INFO:In ode-toolbox: returning outdict = \n",
      "INFO:[\n",
      "    {\n",
      "        \"initial_values\": {\n",
      "            \"pre_trace\": \"0.0\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"tau_tr_pre\": \"20.0000000000000\"\n",
      "        },\n",
      "        \"propagators\": {\n",
      "            \"__P__pre_trace__pre_trace\": \"exp(-__h/tau_tr_pre)\"\n",
      "        },\n",
      "        \"solver\": \"analytical\",\n",
      "        \"state_variables\": [\n",
      "            \"pre_trace\"\n",
      "        ],\n",
      "        \"update_expressions\": {\n",
      "            \"pre_trace\": \"__P__pre_trace__pre_trace*pre_trace\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39,GLOBAL, INFO]: Analysing/transforming synapse neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.\n",
      "[40,neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml, INFO, [6:0;55:0]]: Starts processing of the model 'neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml'\n",
      "[41,GLOBAL, INFO]: Rendering template /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp\n",
      "[42,GLOBAL, INFO]: Rendering template /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.h\n",
      "[43,iaf_psc_exp_neuron_nestml, INFO, [18:0;58:0]]: Successfully generated code for the model: 'iaf_psc_exp_neuron_nestml' in: '/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target' !\n",
      "[44,GLOBAL, INFO]: Rendering template /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp\n",
      "[45,GLOBAL, INFO]: Rendering template /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.h\n",
      "[46,iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml, INFO, [18:0;58:0]]: Successfully generated code for the model: 'iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml' in: '/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target' !\n",
      "[47,GLOBAL, INFO]: Rendering template /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h\n",
      "[48,neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml, INFO, [6:0;55:0]]: Successfully generated code for the model: 'neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml' in: '/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target' !\n",
      "[49,GLOBAL, INFO]: Rendering template /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/nestml_c69cecaf9bf140df8896610867ef0932_module.cpp\n",
      "[50,GLOBAL, INFO]: Rendering template /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/nestml_c69cecaf9bf140df8896610867ef0932_module.h\n",
      "[51,GLOBAL, INFO]: Rendering template /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/CMakeLists.txt\n",
      "[52,GLOBAL, INFO]: Successfully generated NEST module code in '/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target' !\n",
      "CMake Warning (dev) at CMakeLists.txt:95 (project):\n",
      "  cmake_minimum_required() should be called prior to this top-level project()\n",
      "  call.  Please see the cmake-commands(7) manual for usage documentation of\n",
      "  both commands.\n",
      "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\n",
      "-- The CXX compiler identification is GNU 12.3.0\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "\n",
      "-------------------------------------------------------\n",
      "nestml_c69cecaf9bf140df8896610867ef0932_module Configuration Summary\n",
      "-------------------------------------------------------\n",
      "\n",
      "C++ compiler         : /usr/bin/c++\n",
      "Build static libs    : OFF\n",
      "C++ compiler flags   : \n",
      "NEST compiler flags  :  -std=c++17 -Wall -fopenmp -O2 -fdiagnostics-color=auto\n",
      "NEST include dirs    :  -I/home/charl/julich/nest-simulator-install/include/nest -I/usr/include -I/usr/local/include -I/usr/include\n",
      "NEST libraries flags : -L/home/charl/julich/nest-simulator-install/lib/nest -lnest -lsli /usr/lib/x86_64-linux-gnu/libltdl.so  /usr/local/lib/libgsl.so /usr/local/lib/libgslcblas.so    /usr/lib/gcc/x86_64-linux-gnu/12/libgomp.so /usr/lib/x86_64-linux-gnu/libpthread.a\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "You can now build and install 'nestml_c69cecaf9bf140df8896610867ef0932_module' using\n",
      "  make\n",
      "  make install\n",
      "\n",
      "The library file libnestml_c69cecaf9bf140df8896610867ef0932_module.so will be installed to\n",
      "  /tmp/nestml_target_h3zr0n32\n",
      "The module can be loaded into NEST using\n",
      "  (nestml_c69cecaf9bf140df8896610867ef0932_module) Install       (in SLI)\n",
      "  nest.Install(nestml_c69cecaf9bf140df8896610867ef0932_module)   (in PyNEST)\n",
      "\n",
      "CMake Warning (dev) in CMakeLists.txt:\n",
      "  No cmake_minimum_required command is present.  A line of code such as\n",
      "\n",
      "    cmake_minimum_required(VERSION 3.26)\n",
      "\n",
      "  should be added at the top of the file.  The version specified may be lower\n",
      "  if you wish to support older CMake versions for this project.  For more\n",
      "  information run \"cmake --help-policy CMP0000\".\n",
      "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\n",
      "-- Configuring done (0.1s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target\n",
      "[ 25%] Building CXX object CMakeFiles/nestml_c69cecaf9bf140df8896610867ef0932_module_module.dir/nestml_c69cecaf9bf140df8896610867ef0932_module.o\n",
      "[ 50%] Building CXX object CMakeFiles/nestml_c69cecaf9bf140df8896610867ef0932_module_module.dir/iaf_psc_exp_neuron_nestml.o\n",
      "[ 75%] Building CXX object CMakeFiles/nestml_c69cecaf9bf140df8896610867ef0932_module_module.dir/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.o\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp: In member function ‘void iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml::init_state_internal_()’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp:201:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  201 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp: In member function ‘void iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml::recompute_internal_variables(bool)’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp:290:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  290 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp: In function ‘int iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml_dynamics_post_trace__for_neuromodulated_stdp_synapse_nestml(double, const double*, double*, void*)’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp:347:77: warning: unused variable ‘node’ [-Wunused-variable]\n",
      "  347 |   const iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml& node = *( reinterpret_cast< iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml* >( pnode ) );\n",
      "      |                                                                             ^~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp: In member function ‘virtual void iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml::update(const nest::Time&, long int, long int)’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp:375:24: warning: comparison of integer expressions of different signedness: ‘long int’ and ‘const size_t’ {aka ‘const long unsigned int’} [-Wsign-compare]\n",
      "  375 |     for (long i = 0; i < NUM_SPIKE_RECEPTORS; ++i)\n",
      "      |                      ~~^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp:366:10: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  366 |     auto get_t = [origin, lag](){ return nest::Time( nest::Time::step( origin.get_steps() + lag + 1) ).get_ms(); };\n",
      "      |          ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp:360:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  360 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp: In member function ‘void iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml::on_receive_block_spikes_in_port()’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml__with_neuromodulated_stdp_synapse_nestml.cpp:537:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  537 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp: In member function ‘void iaf_psc_exp_neuron_nestml::init_state_internal_()’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp:191:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  191 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp: In member function ‘void iaf_psc_exp_neuron_nestml::recompute_internal_variables(bool)’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp:271:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  271 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp: In member function ‘virtual void iaf_psc_exp_neuron_nestml::update(const nest::Time&, long int, long int)’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp:337:24: warning: comparison of integer expressions of different signedness: ‘long int’ and ‘const size_t’ {aka ‘const long unsigned int’} [-Wsign-compare]\n",
      "  337 |     for (long i = 0; i < NUM_SPIKE_RECEPTORS; ++i)\n",
      "      |                      ~~^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp:328:10: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  328 |     auto get_t = [origin, lag](){ return nest::Time( nest::Time::step( origin.get_steps() + lag + 1) ).get_ms(); };\n",
      "      |          ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp:322:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  322 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp: In member function ‘void iaf_psc_exp_neuron_nestml::on_receive_block_spikes_in_port()’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/iaf_psc_exp_neuron_nestml.cpp:496:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  496 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file included from /home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/nestml_c69cecaf9bf140df8896610867ef0932_module.cpp:36:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h: In instantiation of ‘nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml() [with targetidentifierT = nest::TargetIdentifierPtrRport]’:\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_model.h:164:25:   required from ‘nest::GenericConnectorModel<ConnectionT>::GenericConnectorModel(std::string) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierPtrRport>; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/model_manager_impl.h:62:5:   required from ‘void nest::ModelManager::register_connection_model(const std::string&) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/nest_impl.h:37:70:   required from ‘void nest::register_connection_model(const std::string&) [with ConnectorModelT = neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:622:104:   required from here\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:758:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  758 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h: In instantiation of ‘void nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::recompute_internal_variables() [with targetidentifierT = nest::TargetIdentifierPtrRport]’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:773:3:   required from ‘nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml() [with targetidentifierT = nest::TargetIdentifierPtrRport]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_model.h:164:25:   required from ‘nest::GenericConnectorModel<ConnectionT>::GenericConnectorModel(std::string) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierPtrRport>; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/model_manager_impl.h:62:5:   required from ‘void nest::ModelManager::register_connection_model(const std::string&) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/nest_impl.h:37:70:   required from ‘void nest::register_connection_model(const std::string&) [with ConnectorModelT = neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:622:104:   required from here\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:746:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  746 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h: In instantiation of ‘nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml() [with targetidentifierT = nest::TargetIdentifierIndex]’:\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_model.h:164:25:   required from ‘nest::GenericConnectorModel<ConnectionT>::GenericConnectorModel(std::string) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierIndex>; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/model_manager_impl.h:103:34:   required from ‘void nest::ModelManager::register_specific_connection_model_(const std::string&) [with CompleteConnecionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierIndex>; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/model_manager_impl.h:67:80:   required from ‘void nest::ModelManager::register_connection_model(const std::string&) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/nest_impl.h:37:70:   required from ‘void nest::register_connection_model(const std::string&) [with ConnectorModelT = neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:622:104:   required from here\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:758:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  758 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h: In instantiation of ‘void nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::recompute_internal_variables() [with targetidentifierT = nest::TargetIdentifierIndex]’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:773:3:   required from ‘nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml() [with targetidentifierT = nest::TargetIdentifierIndex]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_model.h:164:25:   required from ‘nest::GenericConnectorModel<ConnectionT>::GenericConnectorModel(std::string) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierIndex>; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/model_manager_impl.h:103:34:   required from ‘void nest::ModelManager::register_specific_connection_model_(const std::string&) [with CompleteConnecionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierIndex>; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/model_manager_impl.h:67:80:   required from ‘void nest::ModelManager::register_connection_model(const std::string&) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/nest_impl.h:37:70:   required from ‘void nest::register_connection_model(const std::string&) [with ConnectorModelT = neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml; std::string = std::__cxx11::basic_string<char>]’\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:622:104:   required from here\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:746:16: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  746 |   const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h: In instantiation of ‘bool nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::send(nest::Event&, size_t, const nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestmlCommonSynapseProperties&) [with targetidentifierT = nest::TargetIdentifierPtrRport; size_t = long unsigned int]’:\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_base.h:391:22:   required from ‘void nest::Connector<ConnectionT>::send_to_all(size_t, const std::vector<nest::ConnectorModel*>&, nest::Event&) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierPtrRport>; size_t = long unsigned int]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_base.h:383:3:   required from here\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:526:14: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  526 |         auto get_t = [t_hist_entry_ms](){ return t_hist_entry_ms; };   // do not remove, this is in case the predefined time variable ``t`` is used in the NESTML model\n",
      "      |              ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:555:12: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  555 |       auto get_t = [__t_spike](){ return __t_spike; };    // do not remove, this is in case the predefined time variable ``t`` is used in the NESTML model\n",
      "      |            ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:596:12: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  596 |       auto get_t = [__t_spike](){ return __t_spike; };    // do not remove, this is in case the predefined time variable ``t`` is used in the NESTML model\n",
      "      |            ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:451:18: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  451 |     const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                  ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:453:10: warning: variable ‘get_thread’ set but not used [-Wunused-but-set-variable]\n",
      "  453 |     auto get_thread = [tid]()\n",
      "      |          ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h: In instantiation of ‘bool nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::send(nest::Event&, size_t, const nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestmlCommonSynapseProperties&) [with targetidentifierT = nest::TargetIdentifierIndex; size_t = long unsigned int]’:\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_base.h:391:22:   required from ‘void nest::Connector<ConnectionT>::send_to_all(size_t, const std::vector<nest::ConnectorModel*>&, nest::Event&) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierIndex>; size_t = long unsigned int]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_base.h:383:3:   required from here\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:526:14: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  526 |         auto get_t = [t_hist_entry_ms](){ return t_hist_entry_ms; };   // do not remove, this is in case the predefined time variable ``t`` is used in the NESTML model\n",
      "      |              ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:555:12: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  555 |       auto get_t = [__t_spike](){ return __t_spike; };    // do not remove, this is in case the predefined time variable ``t`` is used in the NESTML model\n",
      "      |            ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:596:12: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  596 |       auto get_t = [__t_spike](){ return __t_spike; };    // do not remove, this is in case the predefined time variable ``t`` is used in the NESTML model\n",
      "      |            ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:451:18: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  451 |     const double __timestep = nest::Time::get_resolution().get_ms();  // do not remove, this is necessary for the timestep() function\n",
      "      |                  ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:453:10: warning: variable ‘get_thread’ set but not used [-Wunused-but-set-variable]\n",
      "  453 |     auto get_thread = [tid]()\n",
      "      |          ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h: In instantiation of ‘void nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::update_internal_state_(double, double, const nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestmlCommonSynapseProperties&) [with targetidentifierT = nest::TargetIdentifierPtrRport]’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:521:9:   required from ‘bool nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::send(nest::Event&, size_t, const nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestmlCommonSynapseProperties&) [with targetidentifierT = nest::TargetIdentifierPtrRport; size_t = long unsigned int]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_base.h:391:22:   required from ‘void nest::Connector<ConnectionT>::send_to_all(size_t, const std::vector<nest::ConnectorModel*>&, nest::Event&) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierPtrRport>; size_t = long unsigned int]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_base.h:383:3:   required from here\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:826:18: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  826 |     const double __timestep = timestep;  // do not remove, this is necessary for the timestep() function\n",
      "      |                  ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:827:10: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  827 |     auto get_t = [t_start](){ return t_start; };   // do not remove, this is in case the predefined time variable ``t`` is used in the NESTML model\n",
      "      |          ^~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h: In instantiation of ‘void nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::update_internal_state_(double, double, const nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestmlCommonSynapseProperties&) [with targetidentifierT = nest::TargetIdentifierIndex]’:\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:521:9:   required from ‘bool nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<targetidentifierT>::send(nest::Event&, size_t, const nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestmlCommonSynapseProperties&) [with targetidentifierT = nest::TargetIdentifierIndex; size_t = long unsigned int]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_base.h:391:22:   required from ‘void nest::Connector<ConnectionT>::send_to_all(size_t, const std::vector<nest::ConnectorModel*>&, nest::Event&) [with ConnectionT = nest::neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml<nest::TargetIdentifierIndex>; size_t = long unsigned int]’\n",
      "/home/charl/julich/nest-simulator-install/include/nest/connector_base.h:383:3:   required from here\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:826:18: warning: unused variable ‘__timestep’ [-Wunused-variable]\n",
      "  826 |     const double __timestep = timestep;  // do not remove, this is necessary for the timestep() function\n",
      "      |                  ^~~~~~~~~~\n",
      "/home/charl/julich/nestml-fork-AlexisWis-cart_pole_tutorial-stash-restore/nestml/doc/tutorials/cart_pole_reinforcement_learning/target/neuromodulated_stdp_synapse_nestml__with_iaf_psc_exp_neuron_nestml.h:827:10: warning: variable ‘get_t’ set but not used [-Wunused-but-set-variable]\n",
      "  827 |     auto get_t = [t_start](){ return t_start; };   // do not remove, this is in case the predefined time variable ``t`` is used in the NESTML model\n",
      "      |          ^~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] Linking CXX shared module nestml_c69cecaf9bf140df8896610867ef0932_module.so\n",
      "[100%] Built target nestml_c69cecaf9bf140df8896610867ef0932_module_module\n",
      "[100%] Built target nestml_c69cecaf9bf140df8896610867ef0932_module_module\n",
      "Install the project...\n",
      "-- Install configuration: \"\"\n",
      "-- Installing: /tmp/nestml_target_h3zr0n32/nestml_c69cecaf9bf140df8896610867ef0932_module.so\n"
     ]
    }
   ],
   "source": [
    "# ... generate NESTML model code...\n",
    "\n",
    "from pynestml.codegeneration.nest_code_generator_utils import NESTCodeGeneratorUtils\n",
    "\n",
    "# generate and build code\n",
    "input_layer_module_name, input_layer_neuron_model_name = \\\n",
    "   NESTCodeGeneratorUtils.generate_code_for(\"../../../models/neurons/ignore_and_fire_neuron.nestml\")\n",
    "\n",
    "# ignore_and_fire\n",
    "output_layer_module_name, output_layer_neuron_model_name, output_layer_synapse_model_name = \\\n",
    "    NESTCodeGeneratorUtils.generate_code_for(\"iaf_psc_exp_neuron.nestml\",\n",
    "                                             \"neuromodulated_stdp_synapse.nestml\",\n",
    "                                             post_ports=[\"post_spikes\"],\n",
    "                                             logging_level=\"DEBUG\",\n",
    "                                             codegen_opts={\"delay_variable\": {\"neuromodulated_stdp_synapse\": \"d\"},\n",
    "                                                           \"weight_variable\": {\"neuromodulated_stdp_synapse\": \"w\"}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99614c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest\n",
    "import json\n",
    "import os\n",
    "import enum\n",
    "\n",
    "nest.set_verbosity(\"M_ERROR\")\n",
    "\n",
    "class AgentAction(enum.Enum):\n",
    "    FAILURE = -1\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "\n",
    "class SpikingAgent(Agent):\n",
    "    cycle_period = 10.   # alternate between physics and SNN simulation with this cycle length [ms]\n",
    "   \n",
    "    def __init__(self, initial_state: Tuple[float,float,float,float], gamma) -> None:\n",
    "        super().__init__(initial_state)\n",
    "        self.gamma = gamma\n",
    "        self.construct_neural_network()\n",
    "        self.Q_left = 0.\n",
    "        self.Q_right = 0.\n",
    "        self.Q_left_prev = 0.\n",
    "        self.Q_right_prev = 0.\n",
    "        self.scale_n_output_spikes_to_Q_value = 0.1\n",
    "        self.dopamine_left = 0.\n",
    "        self.dopamine_right = 0.\n",
    "        self.last_action_chosen = AgentAction.LEFT   # ?! choose first action randomly\n",
    "        self.R = 1.  # reward -- always 1!\n",
    "\n",
    "    def get_state_neuron(self, state) -> int:\n",
    "        idx = 0\n",
    "        thresholds = [self.x_thresholds, self.theta_thresholds, self.v_thresholds, self.w_thresholds]\n",
    "        for dim, val, thresh in zip(self.dimensions, state, thresholds):\n",
    "            i = self.discretize(val,thresh)\n",
    "            if i == -1:\n",
    "                return -1\n",
    "            idx = idx * dim + i\n",
    "\n",
    "        return idx\n",
    "    \n",
    "    def get_state_from_id(self, idx) -> None:\n",
    "        assert idx >= 0 and idx < len(self.input_population)\n",
    "        state = [-1,-1,-1,-1]\n",
    "        for i in reversed(range(len(state))):\n",
    "            state[i] = idx % self.dimensions[i]\n",
    "            idx = idx // self.dimensions[i]\n",
    "        return tuple(state)\n",
    "    \n",
    "    def construct_neural_network(self):\n",
    "        nest.ResetKernel()\n",
    "        nest.resolution = .01\n",
    "        nest.Install(input_layer_module_name)   # makes the generated NESTML model available\n",
    "        nest.Install(output_layer_module_name)   # makes the generated NESTML model available\n",
    "\n",
    "        self.input_size = self.dimensions[0] * self.dimensions[1] * self.dimensions[2] * self.dimensions[3]\n",
    "        self.input_population = nest.Create(input_layer_neuron_model_name, self.input_size)\n",
    "        print(\"Input dimensions: \" + str((self.dimensions[0], self.dimensions[1], self.dimensions[2], self.dimensions[3])))\n",
    "        print(\"Size of the input population: \" + str(self.input_size))\n",
    "        \n",
    "        self.output_population_left = nest.Create(output_layer_neuron_model_name, 10)\n",
    "        self.output_population_right = nest.Create(output_layer_neuron_model_name, 10)\n",
    "        \n",
    "        self.spike_recorder_input = nest.Create(\"spike_recorder\")\n",
    "        nest.Connect(self.input_population, self.spike_recorder_input)\n",
    "\n",
    "        self.multimeter_left = nest.Create('multimeter', 1, {'record_from': ['V_m']})\n",
    "        nest.Connect(self.multimeter_left, self.output_population_left)\n",
    "        self.multimeter_right = nest.Create('multimeter', 1, {'record_from': ['V_m']})\n",
    "        nest.Connect(self.multimeter_right, self.output_population_right)\n",
    "\n",
    "        syn_opts = {\"synapse_model\": output_layer_synapse_model_name,\n",
    "                    \"weight\": 0.1 + nest.random.uniform(min=0.0, max=1.0) * 0.02,\n",
    "                    \"beta\": 0.01,\n",
    "                    \"tau_tr_pre\": 20., # [ms]\n",
    "                    \"tau_tr_post\": 20.,  # [ms]\n",
    "                    \"Wmax\": 0.3,\n",
    "                    \"Wmin\": 0.005,\n",
    "                    \"wtr_max\": 0.1,\n",
    "                    \"wtr_min\": 0.,\n",
    "                    \"pre_trace_increment\": 0.0001,\n",
    "                    \"post_trace_increment\": -1.05E-7}\n",
    "        \n",
    "        nest.Connect(self.input_population, self.output_population_left, syn_spec=syn_opts)\n",
    "        nest.Connect(self.input_population, self.output_population_right, syn_spec=syn_opts)\n",
    "\n",
    "        syn = nest.GetConnections(source=self.input_population, target=self.output_population_right)\n",
    "        print(\"after network init:\")\n",
    "        print(\"\\tbeta = \" + str(syn.beta))\n",
    "        print(\"\\tbefore w = \" + str(syn.w))\n",
    "        print(\"\\tbefore wtr = \" + str(syn.wtr))\n",
    "\n",
    "        \n",
    "        self.output_population_spike_recorder_left = nest.Create(\"spike_recorder\")\n",
    "        nest.Connect(self.output_population_left, self.output_population_spike_recorder_left)\n",
    "\n",
    "        self.output_population_spike_recorder_right = nest.Create(\"spike_recorder\")\n",
    "        nest.Connect(self.output_population_right, self.output_population_spike_recorder_right)\n",
    "        \n",
    "        # set default values for prev_syn_wtr_right and left\n",
    "        syn_right = nest.GetConnections(source=self.input_population, target=self.output_population_right)\n",
    "        self.prev_syn_wtr_right = syn_right.wtr\n",
    "        syn_left = nest.GetConnections(source=self.input_population, target=self.output_population_left)\n",
    "        self.prev_syn_wtr_left = syn_left.wtr\n",
    "        \n",
    "        \n",
    "    #stores important connections in a JSON, can be used to plot features of network\n",
    "    def save_network(self):\n",
    "        connection_dictionary = {}\n",
    "        for input_neuron_id in range(len(self.input_population)):\n",
    "            neuron = self.input_population[input_neuron_id]\n",
    "            conn_left = nest.GetConnections(source=neuron, target=self.output_population_left)\n",
    "            conn_right = nest.GetConnections(source=neuron, target=self.output_population_right)\n",
    "            state = self.get_state_from_id(input_neuron_id) #state is a tuple of the corresponding bins for each variable indexed at 0\n",
    "            connection_dictionary[str(state)] = {\"neuron\": neuron.get(),\n",
    "                                            \"connection_left\": conn_left.get(),\n",
    "                                            \"connection_right\": conn_right.get(),\n",
    "                                            }\n",
    "        #os.makedirs(\"/saved_networks\", exist_ok=True)\n",
    "        with open(\"saved_networks/network.json\", \"w\") as f:\n",
    "            json.dump(connection_dictionary, f, indent=4)\n",
    "\n",
    "    def choose_action(self, Q_left, Q_right) -> AgentAction:\n",
    "        if Q_left > Q_right:\n",
    "            return AgentAction.LEFT\n",
    "        \n",
    "        return AgentAction.RIGHT\n",
    "\n",
    "    def compute_Q_values(self) -> None:\n",
    "        r\"\"\"The output of the SNN is interpreted as the (scaled) Q values.\"\"\"\n",
    "        self.Q_left_prev = self.Q_left\n",
    "        self.Q_right_prev = self.Q_right\n",
    "\n",
    "        n_events_in_last_interval_left = self.output_population_spike_recorder_left.n_events\n",
    "        n_events_in_last_interval_right = self.output_population_spike_recorder_right.n_events\n",
    "        print(\"n_events_in_last_interval_left = \" + str(n_events_in_last_interval_left))\n",
    "        print(\"n_events_in_last_interval_right = \" + str(n_events_in_last_interval_right))\n",
    "        self.Q_left = self.scale_n_output_spikes_to_Q_value * n_events_in_last_interval_left\n",
    "        self.Q_right = self.scale_n_output_spikes_to_Q_value * n_events_in_last_interval_right\n",
    "\n",
    "    # update Q_value using TD-Error with previous Q_value and reward = 0\n",
    "    # cooldown_time in case the SNN doesn't need 40ms to update\n",
    "    def failure_reset(self) -> None:\n",
    "        # if for some reason the simulation terminates super fast\n",
    "        if self.Q_left_prev == None and self.Q_right_prev == None:\n",
    "            return\n",
    "        # what would we mean by that? negative dopamine is biologically inaccurate\n",
    "        # inhibitory neuromodulators?\n",
    "#         if self.choose_action(self.Q_left_prev, self.Q_right_prev) == AgentAction.RIGHT:\n",
    "#             syn = nest.GetConnections(source=self.input_population, target=self.output_population_right)\n",
    "#             syn.n = -self.Q_right\n",
    "#         else:\n",
    "#             syn = nest.GetConnections(source=self.input_population, target=self.output_population_left)\n",
    "#             syn.n = -self.Q_left\n",
    "\n",
    "        TD = -self.Q_new\n",
    "         \n",
    "        if self.last_action_chosen == AgentAction.RIGHT:\n",
    "            print(\"Chosen action = RIGHT\")\n",
    "            syn = nest.GetConnections(source=self.input_population, target=self.output_population_right)\n",
    "            print(\"\\tbeta = \" + str(syn.beta))\n",
    "            print(\"\\tbefore w = \" + str(syn.w))\n",
    "            print(\"\\tbefore wtr = \" + str(syn.wtr))\n",
    "            print(\"\\tbefore prev_syn_wtr_right = \" + str(self.prev_syn_wtr_right))\n",
    "            print(\"\\tbefore TD = \" + str(TD))\n",
    "            syn.w += np.array(syn.beta) * TD * np.array(self.prev_syn_wtr_right)\n",
    "            print(\"\\tafter w = \" + str(syn.w))\n",
    "        else:\n",
    "            assert self.last_action_chosen == AgentAction.LEFT\n",
    "            print(\"Chosen action = LEFT\")\n",
    "            syn = nest.GetConnections(source=self.input_population, target=self.output_population_left)\n",
    "            print(\"\\tbeta = \" + str(syn.beta))\n",
    "            print(\"\\tbefore w = \" + str(syn.w))\n",
    "            print(\"\\tbefore wtr = \" + str(syn.wtr))\n",
    "            print(\"\\tbefore prev_syn_wtr_right = \" + str(self.prev_syn_wtr_right))\n",
    "            print(\"\\tbefore TD = \" + str(TD))\n",
    "            syn.w += np.array(syn.beta) * TD * np.array(self.prev_syn_wtr_left)\n",
    "            print(\"\\tafter w = \" + str(syn.w))\n",
    "            \n",
    "        self.episode += 1\n",
    "\n",
    "    def update(self, next_state: Tuple[float,float,float,float]) -> Tuple[int, dict]:\n",
    "\n",
    "        #Reset all spike recorders and multimeters\n",
    "        #self.multimeter_left.n_events = 0\n",
    "        #self.multimeter_right.n_events = 0\n",
    "        #self.spike_recorder_input.n_events = 0\n",
    "        self.output_population_spike_recorder_left.n_events = 0\n",
    "        self.output_population_spike_recorder_right.n_events = 0\n",
    "\n",
    "        # make the correct input neuron fire\n",
    "        self.input_population.firing_rate = 0.\n",
    "        neuron_id = self.get_state_neuron(next_state)\n",
    "        \n",
    "        # if state was a failure\n",
    "        if neuron_id == -1:\n",
    "#             self.failure_reset(SpikingAgent.cycle_period)\n",
    "            return AgentAction.FAILURE, None\n",
    "        \n",
    "        self.input_population[neuron_id].firing_rate = 5000.    # [s⁻¹]\n",
    "\n",
    "        # simulate for one cycle\n",
    "        nest.Simulate(SpikingAgent.cycle_period)\n",
    "        \n",
    "        syn_left = nest.GetConnections(source=self.input_population, target=self.output_population_left)\n",
    "        syn_right = nest.GetConnections(source=self.input_population, target=self.output_population_right)\n",
    "        \n",
    "        # plot data, passed onto Spiking_Plot_Renderer()\n",
    "        plot_data = {\n",
    "            \"weights_left\": syn_left.get(\"weight\"),\n",
    "            \"weights_right\": syn_right.get(\"weight\"),\n",
    "            \"input_spikes\": nest.GetStatus(self.spike_recorder_input, keys=\"events\")[0],\n",
    "            \"output_spikes_left\": nest.GetStatus(self.output_population_spike_recorder_left, keys=\"events\")[0],\n",
    "            \"output_spikes_right\": nest.GetStatus(self.output_population_spike_recorder_right, keys=\"events\")[0],\n",
    "            \"multimeter_right_events\": self.multimeter_right.get(\"events\"),\n",
    "            \"multimeter_left_events\": self.multimeter_left.get(\"events\"),\n",
    "            \"n_input_neurons\": self.input_size\n",
    "        }\n",
    "\n",
    "        self.compute_Q_values()\n",
    "\n",
    "        # set new dopamine concentration on the synapses\n",
    "        # PROBLEM: HOW DO WE HANDLE FAILURE? The physics simulation immediately resets after it.\n",
    "        # Perhaps run the simulation without spiking to let the weights update? (BVogler)\n",
    "\n",
    "        self.Q_new = max(self.Q_left, self.Q_right)\n",
    "        \n",
    "        if self.last_action_chosen == AgentAction.LEFT:\n",
    "            Q_old = self.Q_left_prev\n",
    "        elif self.last_action_chosen == AgentAction.RIGHT:\n",
    "            Q_old = self.Q_right_prev\n",
    "        else:\n",
    "            assert self.last_action_chosen == AgentAction.FAILURE\n",
    "        \n",
    "        TD = self.gamma * self.Q_new + self.R - Q_old\n",
    "         \n",
    "        if self.last_action_chosen == AgentAction.RIGHT:\n",
    "            print(\"ast chosen = right\")\n",
    "            syn = nest.GetConnections(source=self.input_population, target=self.output_population_right)\n",
    "            syn.w += np.array(syn.beta) * TD * np.array(self.prev_syn_wtr_right)\n",
    "        else:\n",
    "            print(\"ast chosen = left\")\n",
    "            assert self.last_action_chosen == AgentAction.LEFT\n",
    "            syn = nest.GetConnections(source=self.input_population, target=self.output_population_left)\n",
    "            syn.w += np.array(syn.beta) * TD * np.array(self.prev_syn_wtr_left)\n",
    "            \n",
    "#             fig,ax=plt.subplots()\n",
    "#             ax.plot(np.arange(1200), self.prev_syn_wtr_left)\n",
    "#             import uuid\n",
    "#             fig.savefig(\"/tmp/weights_nest\" + str(uuid.uuid4()) + \".png\")\n",
    "            \n",
    "        self.last_action_chosen = self.choose_action(self.Q_left, self.Q_right)\n",
    "            \n",
    "        return self.last_action_chosen, plot_data            \n",
    "            \n",
    "            \n",
    "    def save_prev_syn_wtr(self):\n",
    "        syn_right = nest.GetConnections(source=self.input_population, target=self.output_population_right)\n",
    "        self.prev_syn_wtr_right = syn_right.wtr\n",
    "        syn_left = nest.GetConnections(source=self.input_population, target=self.output_population_left)\n",
    "        self.prev_syn_wtr_left = syn_left.wtr\n",
    "        \n",
    "#         # update Q_value using TD-Error with previous Q_value and reward = 1\n",
    "#         if self.Q_left_prev != None and self.Q_right_prev != None:\n",
    "#             if self.choose_action(self.Q_left_prev, self.Q_right_prev) == ...:\n",
    "#                 last_action_chosen = AgentAction....\n",
    "#                 syn = nest.GetConnections(source=self.input_population, target=self.output_population_right)\n",
    "#                 syn.n = self.gamma * self.Q_right + R - self.Q_right_prev\n",
    "#                 self.dopamine_right = syn.n[0] #for displaying stats\n",
    "#             else:\n",
    "#                 syn = nest.GetConnections(source=self.input_population, target=self.output_population_left)\n",
    "#                 syn.n = self.gamma * self.Q_left + R - self.Q_left_prev\n",
    "#                 self.dopamine_left = syn.n[0] #for displaying stats\n",
    "        \n",
    "#         # 0 if action is \"left\", else 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fa9c9",
   "metadata": {},
   "source": [
    "# Executing spiking version\n",
    "\n",
    "The main loop looks like this: for every iteration of the loop (for every \"cycle\" or \"step\"):\n",
    "\n",
    "- set the rate of the input neurons to the current state of the system\n",
    "- run the SNN with this input state s_n for a period of time (cycle time, in BVogler's thesis: 40 ms)\n",
    "- obtain the Q(sn, a) values, by counting nr of spikes in output population over this cycle period\n",
    "- choose action $a_n$ on the basis of Q-values\n",
    "- run the environment for the same cycle time (40 ms) to obtain next state $s_{n+1}$\n",
    "- compute reward on the basis of the last taken action (????)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4bda6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "Dimension of input space: (1, 6, 1, 20)\n",
      "Input dimensions: (1, 6, 1, 20)\n",
      "Size of the input population: 120\n",
      "after network init:\n",
      "\tbeta = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
      "\tbefore w = [0.1030840799084283, 0.10818471277665606, 0.1093530261059271, 0.1060874095101689, 0.10332633655904294, 0.10278589356998041, 0.10142232444763528, 0.10104127912408956, 0.1092420554655466, 0.11305000765887342, 0.10454100487766312, 0.10423058754349193, 0.11237860266626329, 0.11809210481897496, 0.111299885109804, 0.11556934623403736, 0.11373929648366678, 0.10443276132096864, 0.10228226381788692, 0.10643791840545887, 0.10607032734243028, 0.1171072778281299, 0.11352850841730883, 0.10929543013298147, 0.10012008810399081, 0.10660196275930245, 0.11525656498761196, 0.11796560027143921, 0.10907636622617126, 0.11251503981482584, 0.11122104935740704, 0.11565690753667951, 0.10569819855530281, 0.10656081364593552, 0.11008280828067248, 0.11910623791364959, 0.10411275698129245, 0.11138902425744165, 0.11439230423915753, 0.11024074048170512, 0.10355024079658384, 0.11866524275638299, 0.10735544546336448, 0.11490391382885391, 0.10354466777888567, 0.10081894902081029, 0.1177593828439417, 0.10798459393015902, 0.10333466452642284, 0.10978364160886102, 0.10051926674272196, 0.10525148207240279, 0.11822874075512706, 0.11829165569410699, 0.11993771307910552, 0.11639039128569906, 0.11973679147887842, 0.10395934095777443, 0.10555407404403744, 0.11404185838958465, 0.11533640401264644, 0.10281821152714611, 0.10108226007862679, 0.11230380412534621, 0.10631990626521784, 0.10824830659610077, 0.1158588586488091, 0.10126408068058526, 0.11933971307154775, 0.11540783001284227, 0.10726627463616925, 0.11580286895696996, 0.11262678965198167, 0.1052290000406438, 0.10373753074849196, 0.11223307477183915, 0.11501790674434478, 0.11100505603270285, 0.11921262016899543, 0.11643289531998278, 0.10995753524899354, 0.11775007354984263, 0.10931153248254996, 0.11617756295507616, 0.10575996137149149, 0.10452035135460468, 0.10937961564703554, 0.1176487770263081, 0.10432005463915452, 0.10543715356129137, 0.11176658993776903, 0.10405833175309542, 0.10912834234765176, 0.10959115046913917, 0.10345153127116942, 0.11889265402702484, 0.10584071710404791, 0.10121077922890101, 0.1152224267233326, 0.11527901744428548, 0.10087649646363404, 0.11397730898927205, 0.11335387832220103, 0.1114611299108936, 0.10587606506164213, 0.10095279331469376, 0.11030138202312319, 0.10378489433249483, 0.11057838666079876, 0.11930944987974995, 0.11579415043293823, 0.10178323243913397, 0.10842846409932357, 0.10075269794056634, 0.11362324877640745, 0.10581173268291388, 0.10112723884526845, 0.1164572297991168, 0.10475323142222033, 0.10904164006593359, 0.1073140567947003, 0.10130443312251186, 0.10684730544362267, 0.11173679756348887, 0.11387506395851942, 0.11591439350455478, 0.10651588763759268, 0.10174687649164622, 0.10256399320331697, 0.10293123138062356, 0.1185555783751304, 0.10399545388862132, 0.10202205245692834, 0.11565956038369445, 0.1014387716997804, 0.10741418795512842, 0.11179232090463467, 0.10919344094327005, 0.11808921181397594, 0.11696684054947959, 0.1083093115031249, 0.11675687724190145, 0.11892733038566092, 0.10948348609233413, 0.10187976181775031, 0.11180921306563821, 0.11015919609595143, 0.11067778595411021, 0.10270512250040413, 0.10062213521216293, 0.10321903025472949, 0.10390279016601738, 0.10207777643272249, 0.10405199485168949, 0.10581792670358775, 0.1195287605188489, 0.10597269120554481, 0.11609482847512334, 0.10137252743302744, 0.10941757386295438, 0.10171089463004314, 0.10476895654225299, 0.11236194191397683, 0.11985059961610975, 0.11922471870983964, 0.11416308399171964, 0.11519374344524222, 0.11002971511415967, 0.1050952614643482, 0.10658549448892725, 0.11029849483985793, 0.10411085870430122, 0.11885950609408581, 0.11724102173558114, 0.10152250282217912, 0.11733902608635477, 0.1011150579623611, 0.10368076905162373, 0.109593355703736, 0.10243254984247412, 0.11641708838404866, 0.10100510829730801, 0.10561329629915435, 0.11431517335361407, 0.11887144798846302, 0.10396451474300238, 0.11690943384844937, 0.11581083479730479, 0.1021544144140274, 0.10148322695580214, 0.10577667086984316, 0.10012802507255489, 0.11510348462521246, 0.11283016527367369, 0.11059314463357692, 0.10435274848438914, 0.10064328206624638, 0.11952440221656806, 0.10566426465938827, 0.10633441334315823, 0.10367014718941231, 0.10011700978547232, 0.10580468196632471, 0.11998344189071934, 0.11771030029189657, 0.10991260443452705, 0.10237285485863304, 0.10462926063875969, 0.10192151450403304, 0.10947958010090497, 0.11459485479667625, 0.10507966878920943, 0.10433873765264526, 0.11204826689580082, 0.11412038604846039, 0.10910770532075717, 0.116453742917738, 0.10671030976606909, 0.11803507341734337, 0.10766118484432896, 0.11041236918007112, 0.10208823182315557, 0.10353903976412601, 0.1144954367241024, 0.11651847634787128, 0.1055839039792862, 0.11686220111847809, 0.11071839471311665, 0.1059813971827725, 0.10240743820015022, 0.11802621648534344, 0.11993939164728645, 0.10121664097820673, 0.11595988338529445, 0.10214105080772663, 0.10067367044175782, 0.10554917077892186, 0.1194035856214645, 0.11620626026318669, 0.1173292118421583, 0.10982769101010169, 0.1032878431172849, 0.10196198900578013, 0.11796513257157579, 0.11353213303910821, 0.10770120251285664, 0.11822319231745626, 0.11928158749147096, 0.10817295598403535, 0.10620882663166983, 0.10707808286800076, 0.11513415078729429, 0.11890223727907956, 0.1153237697392649, 0.1119507212850837, 0.10599456423294171, 0.10745538782288075, 0.10732371563071383, 0.11236167450920254, 0.1133819107483808, 0.11590399175444985, 0.10562370529152065, 0.10383259983705534, 0.11627334553034259, 0.11786325054247619, 0.10774016950191179, 0.10709863681568008, 0.10105720251677001, 0.10579175685060838, 0.10173848314412118, 0.10439314525288822, 0.1196948141907494, 0.10311564458089388, 0.10601573898517926, 0.11085833348674531, 0.10150745772369238, 0.10974543907708363, 0.10746956604395307, 0.10979205243628967, 0.10825876615497174, 0.10741367797072629, 0.11621654365187449, 0.10702801653718515, 0.11487866192370992, 0.10950243217409884, 0.10113561293607279, 0.1012781037865597, 0.10216520302910376, 0.11710954061169214, 0.10055195717890106, 0.11250422067481004, 0.11249221719550961, 0.11340636859951123, 0.11100861919971032, 0.10696756871918374, 0.10657996804653827, 0.10970711150118664, 0.11922684785423802, 0.11771585093371746, 0.10967131479382998, 0.10166691987592126, 0.11741816484329726, 0.10011829979434064, 0.1106157487220636, 0.1018073945093846, 0.10340427294825488, 0.11623768595151057, 0.10763500150268801, 0.11892440117456782, 0.10211100921462618, 0.11372322480954193, 0.11373403493721645, 0.10286315808596615, 0.10878205937438559, 0.11826394064022222, 0.11194742932983026, 0.11861446338386325, 0.11364597797291165, 0.11622505602563153, 0.11893516027564091, 0.10295505782607835, 0.1111508808976276, 0.11365732328545355, 0.11630914736707662, 0.11599470836046283, 0.10606977001811294, 0.10622763552665479, 0.11229985408887007, 0.10786723508702648, 0.10364694684812138, 0.11456930106370414, 0.10242311745879372, 0.11919372928967474, 0.1195006557478327, 0.10085037033445934, 0.10338818337658215, 0.10276755592942058, 0.10406946148691193, 0.11538375779706221, 0.11875165454378586, 0.11122369637722526, 0.11219188565934002, 0.11039665234068305, 0.10396678923616788, 0.11830937397231082, 0.10587151876540257, 0.1039755225539056, 0.10726212471773207, 0.11918164359739289, 0.10651065655969223, 0.11665960422419722, 0.10255217659116159, 0.10793540600689666, 0.10241078119410346, 0.11380118899558378, 0.1144948514962506, 0.1123287425799559, 0.11234951542544831, 0.11432510484798879, 0.10143868158728113, 0.10815785799025687, 0.10352819493872244, 0.11350216414046421, 0.11628599993248545, 0.1159527554290313, 0.11003049250369282, 0.11895361734004938, 0.10540308238393518, 0.11691001190461196, 0.1057733297256855, 0.11724482963347183, 0.11044356702692104, 0.10362346078213686, 0.11065376372448911, 0.10412239959542574, 0.10735021761232422, 0.11240391012654999, 0.10736683215406131, 0.11113912088207721, 0.11082280028005193, 0.11807659793372025, 0.10394700404357435, 0.11542394998172714, 0.11372472531489548, 0.11692862731656836, 0.10343549101100366, 0.11240710040530183, 0.11958911754823766, 0.10228558946709815, 0.11688024347354815, 0.11329961269219882, 0.11512354011451498, 0.1051954735460635, 0.10048912611216906, 0.10542494721148463, 0.10439503268800397, 0.1044985738592911, 0.10177363828756911, 0.11138325094722538, 0.11183136781513629, 0.10324869387161197, 0.10422199040867693, 0.10250259842064985, 0.11706522927087724, 0.10693072969163603, 0.10030773761267325, 0.11678331251694013, 0.11995449634298949, 0.10073795614619188, 0.104807319117931, 0.10422193873108519, 0.10509427308275249, 0.10844954084626487, 0.11513624199285068, 0.11660595454666496, 0.11702248532944312, 0.11270892254716583, 0.10478542161314486, 0.11335553894835101, 0.11559904609149876, 0.11093713268474081, 0.10370036328767288, 0.10899012141636516, 0.10902360892687753, 0.11474688647717549, 0.11360208670765068, 0.11614077606390512, 0.10544260844572907, 0.11099915726533321, 0.11399512178894139, 0.11677369636255089, 0.11654386966226202, 0.10962370778942997, 0.11368701731689698, 0.11150866703505433, 0.11533555796495407, 0.11752424741221452, 0.11045533228738899, 0.10251911111331896, 0.11934678474444448, 0.1132903013346455, 0.11388997057090489, 0.11282048358685018, 0.10438196162608006, 0.1178467613397646, 0.11612748891678643, 0.1063364642253294, 0.10351198830560197, 0.1156048437502165, 0.1021677527120547, 0.10394567059741795, 0.11302059138516231, 0.11205659974127466, 0.11931804697156514, 0.10702998296458845, 0.11934295829308005, 0.10723107858478574, 0.11733455288172917, 0.10674466549839429, 0.11686035205854753, 0.11786045294993916, 0.11183703178706007, 0.10232963070346385, 0.10564532855812095, 0.11866088752532794, 0.10762618999116369, 0.10815948722298054, 0.10241502300934549, 0.10239405526497179, 0.11568287739149681, 0.1069087092632652, 0.10710866830147277, 0.10176394721663046, 0.11487431965571784, 0.10982886861017034, 0.10887239708535873, 0.10560208574783733, 0.11140480776875226, 0.1073982884927338, 0.11912125679714095, 0.11673612535685418, 0.10382428435353598, 0.10861872923969519, 0.11437177739930475, 0.10168038908993293, 0.10604563008260814, 0.10204016428110194, 0.11944222700494897, 0.11285996910593177, 0.1177337654071756, 0.11898359376353788, 0.10835010708957236, 0.11311663180104921, 0.106491240865456, 0.1067901138373734, 0.11143942842294295, 0.11822894553464514, 0.11818845784585442, 0.11014294420849796, 0.11012519502140092, 0.10807474298135206, 0.11218075000094277, 0.11756306432091301, 0.10963960910169178, 0.10922881368671221, 0.11236711770769298, 0.10853553327647672, 0.10117137153672018, 0.11698308974758707, 0.10814359544135269, 0.10754398898515752, 0.10907211307952422, 0.11742398937017237, 0.10606589108361011, 0.11171149399507148, 0.10199671486265535, 0.10943425753271582, 0.10689669661735952, 0.11268290225262394, 0.11183250322790464, 0.11522084741515996, 0.11779122713083966, 0.11935649313847072, 0.11310997193373021, 0.1060909901968583, 0.10763028628301322, 0.1133499216786813, 0.11980285297156126, 0.10671698178827711, 0.1037240666036901, 0.10489780876142893, 0.10502511740609724, 0.11338970663877461, 0.11972546391671686, 0.10080068634727063, 0.11567123686628616, 0.10374538052198867, 0.10732514287232767, 0.11019549342036981, 0.11718805593926654, 0.11259646598010113, 0.10780014071954871, 0.11931172201695461, 0.10688026135417891, 0.11619394415385229, 0.1049641732446941, 0.10035165471683168, 0.11810495946849228, 0.10881762281529606, 0.11345017977024874, 0.11081642976222923, 0.11861048921640607, 0.10896980619776317, 0.10487097233993495, 0.11282752233253761, 0.10669569642790958, 0.101042683984266, 0.10343422644430442, 0.11145789388043394, 0.11880109167197016, 0.11718636307460298, 0.10131035098939761, 0.10148126479794482, 0.10855143630788064, 0.11364507708640281, 0.10930155818846096, 0.11679698528464875, 0.10401964645046062, 0.11950522610115857, 0.10544769780238447, 0.11707126745891491, 0.11294935492175269, 0.10833467835910805, 0.11340545656677362, 0.11619743996689476, 0.1126196562568661, 0.11563534925425904, 0.11846700304835198, 0.10191903162434364, 0.10557541826128397, 0.10660365968464175, 0.10579765061139329, 0.1181966291829754, 0.10817722918688283, 0.11020880393059565, 0.10779131097284385, 0.11105396457198412, 0.11042335762155708, 0.11718244687808257, 0.11452736386443527, 0.10044879329862419, 0.10963483422039903, 0.11434567789835173, 0.11807860471691356, 0.11396950375817047, 0.11769099751660923, 0.1142489830219709, 0.10349760208983386, 0.11917654368838064, 0.11186701633630011, 0.10078134457575032, 0.10032778106285878, 0.119144515327313, 0.10736988510114157, 0.10321299394928923, 0.11288383003311511, 0.10240145779999177, 0.11148364516296505, 0.11684423239317751, 0.11893515391748138, 0.10463905945508621, 0.10984195349037197, 0.10808052740949835, 0.10813109207539076, 0.1168497419952163, 0.113504640207054, 0.11973004443262562, 0.11288968835659348, 0.11413253861846263, 0.1124306343273305, 0.10587648653984821, 0.10376065177400098, 0.10536661664250664, 0.10568157984174816, 0.1111931152644422, 0.11898830757265053, 0.11684852245262398, 0.11012465128939242, 0.11230802724393713, 0.1090068475596579, 0.10551051746635205, 0.1072795984984741, 0.10019853021751174, 0.10643285253829746, 0.11371660507521077, 0.10429230690235752, 0.1086872434464659, 0.1164973685417316, 0.11631521404676093, 0.11083881092208299, 0.11539534139171514, 0.11761802473397456, 0.10258200938538943, 0.101024776645813, 0.10662823825397216, 0.10411583106392246, 0.11683118731149766, 0.10047193608249222, 0.10860388600535067, 0.10707963448356811, 0.10489480401253445, 0.11242481300453921, 0.11172004394929014, 0.11197822713768704, 0.11223546011371693, 0.11569814054444813, 0.10442406239825787, 0.11959943205884571, 0.10960845236126342, 0.10774891494333896, 0.10199663279582032, 0.11660303342563752, 0.108130396259036, 0.11120526016287653, 0.10188346630313146, 0.10972707801216064, 0.11164171132001095, 0.11195812090256246, 0.11837581736770121, 0.11323821969158697, 0.11130381975233611, 0.10444801357182584, 0.10571436702687023, 0.11416428355548083, 0.10203343200377685, 0.10565998325805807, 0.10264435607458135, 0.11992350621425378, 0.11975550621397547, 0.11216071956772775, 0.10899083991120742, 0.11714582495492402, 0.11190147697706845, 0.10943989139230452, 0.10127648877621936, 0.10312835331961759, 0.11068092187430767, 0.11639351135927882, 0.1091516042904093, 0.10797882759442588, 0.11360784789192195, 0.1148444663630348, 0.11364414839927249, 0.10505016932236931, 0.11275607155753477, 0.10893677442631328, 0.10138233769287787, 0.10001431181751748, 0.11111155103557571, 0.11037410434827434, 0.10340938517381289, 0.1162116752731429, 0.11588586440008633, 0.11723513490457534, 0.10198830449669653, 0.11188345406792394, 0.10977751739130742, 0.10164784327979559, 0.10318544794784262, 0.11246926653149918, 0.11995687904465968, 0.11046610491708016, 0.1043291024024681, 0.10548829582130739, 0.11192473372754719, 0.11895381748095395, 0.11556990115684268, 0.10116861218908377, 0.11331285387173326, 0.10939730853063853, 0.10204293700840644, 0.1137814768146691, 0.11585142358038342, 0.10729740994822369, 0.11248006413581421, 0.10900267329969181, 0.10811499240576639, 0.10757727021854777, 0.11362150233876693, 0.11688606508346752, 0.11175123387307588, 0.10426030753749586, 0.10790408263440648, 0.10519231378119243, 0.10437786354557893, 0.11562417505729104, 0.10273846283105252, 0.11870304163896814, 0.10047507129252428, 0.10331482988036685, 0.10545853616395603, 0.11523969193450086, 0.11462171403813377, 0.10907580419583914, 0.10604678603464225, 0.10007682764553105, 0.10529515773565387, 0.10787560905185896, 0.10290575249875966, 0.11047418226514791, 0.10409074263564978, 0.10662713318984032, 0.1103962115066227, 0.11514188846670208, 0.11383138814463423, 0.10038927302211391, 0.11139526269105743, 0.10930373169271927, 0.11778909611075564, 0.11316761200610988, 0.10295557976114833, 0.10806386216281447, 0.11952275474760932, 0.1019999952330282, 0.11212645462604297, 0.10128619991177316, 0.11292043983717864, 0.11024929665767827, 0.10769242436974531, 0.10244816555536547, 0.10148677064966664, 0.10133303891587939, 0.11591359710461602, 0.1186539567329601, 0.1164240683162394, 0.10781849606303652, 0.10535601179010198, 0.10655369096348444, 0.11294693643371402, 0.11038550482284494, 0.11721899170512881, 0.10789230669407096, 0.11668998083392947, 0.1169782182574281, 0.10397693915580428, 0.10523667491061162, 0.1086989859536065, 0.11451158230564124, 0.10161123037589433, 0.11663879037472834, 0.11607769337357607, 0.10281462541825911, 0.10717049767312176, 0.11337129998297493, 0.10852775573981538, 0.10189002357616853, 0.11133019126763682, 0.11137867403034878, 0.11999049864236853, 0.10670796198330804, 0.1172170189340285, 0.10130903661281641, 0.11095882595401262, 0.11345678951653647, 0.10854397277732561, 0.11140802408359055, 0.11697344296693944, 0.11945962373432803, 0.1044523287851358, 0.1004579253273864, 0.10317618248631595, 0.11171250135734721, 0.11392624631452368, 0.10446989884488155, 0.11449157295605995, 0.11188228099774788, 0.11406925407975699, 0.11072029639851826, 0.1151359511644685, 0.10608929670829531, 0.10761036916396417, 0.10346570259840868, 0.10627827978940341, 0.10967749278711031, 0.11591625004862716, 0.10554671780008541, 0.10223973898667037, 0.1186226192796917, 0.1139562562358319, 0.1012683700528709, 0.10692953711485266, 0.10969370150628666, 0.1196511269256362, 0.10520432317914402, 0.10040438871662397, 0.11330031411988001, 0.11784184536781316, 0.10168239765785153, 0.10997935046818752, 0.1095808491352845, 0.10983766429761521, 0.1120760049970661, 0.10368589087145302, 0.10544149597830532, 0.10084544384381122, 0.10621363824520721, 0.10969050004888468, 0.11002025487892361, 0.11168489366296624, 0.10242072983479932, 0.10662284728714888, 0.11404246393933308, 0.10073939129347123, 0.11812497259371846, 0.10181906651694386, 0.11327695461229265, 0.11833788246149506, 0.11211906174091014, 0.11126451344771979, 0.10199704764590845, 0.10214908396943607, 0.11459081665421982, 0.11661610263432332, 0.11993426343614616, 0.11205564203177969, 0.10347329512932939, 0.10610833500415699, 0.1044894202598619, 0.10697739253588512, 0.10550297557357695, 0.11748150611967745, 0.10660034429186294, 0.10766476208603747, 0.10166476113686218, 0.10836283779460876, 0.11820614738127538, 0.11363611450571362, 0.10643538808876105, 0.10142519486931888, 0.11270439016849869, 0.1073765760740571, 0.10835497942011263, 0.10836579361706024, 0.11420854286881091, 0.1151844728850951, 0.11428008947629553, 0.11200480570179609, 0.11510012900000724, 0.10957815760078819, 0.10193014202271321, 0.11970377679127084, 0.10632204384823891, 0.10501436420479394, 0.11691091248009222, 0.10341320090914002, 0.10438077052436784, 0.11762678591258069, 0.10890368093667406, 0.10022870582358058, 0.10488316860206245, 0.10000956861884541, 0.10338891613296414, 0.10930354229438602, 0.1154165531089997, 0.10945672127313438, 0.10289733546601394, 0.11498437601146408, 0.1168927144550487, 0.11699000551680312, 0.10330147939709637, 0.11816428714211973, 0.1069612685472825, 0.11400434287684182, 0.11554066229012579, 0.11889101847302394, 0.11356275048499145, 0.11706929026092278, 0.10332311813390124, 0.10430901834598409, 0.10585952548587897, 0.10145615315421509, 0.11575386802452635, 0.10953784890531397, 0.10789467263820766, 0.11819905316763893, 0.11347674393151161, 0.11086811530203164, 0.10392109996447914, 0.10853254941652439, 0.11011054291303793, 0.10208058734719233, 0.10361086573625501, 0.10086499938893106, 0.10271895529425049, 0.11133202051633853, 0.11968645318672624, 0.1148492477594619, 0.11683497971657993, 0.11025175441268859, 0.11634586630081692, 0.10613936759532201, 0.10509184468047679, 0.10606406788462429, 0.10325783575977421, 0.11093358927200515, 0.10801369804668058, 0.10129680856874945, 0.11032565996000795, 0.11576960997538184, 0.11959854468288741, 0.1036422981861775, 0.10436301128972693, 0.1168914767402401, 0.11001768685172414, 0.1119862039462689, 0.1155000292245742, 0.11875370070125887, 0.11966274897326759, 0.10213711636049874, 0.11675049414955507, 0.10320373219223845, 0.11604010730114456, 0.11876455478674326, 0.11952663491808922, 0.1085719464731309, 0.10045577354781433, 0.10594803663523122, 0.11010597931561805, 0.10732755137932028, 0.10257074550026256, 0.11471088714280572, 0.11806808907713397, 0.10159745182754257, 0.1162816438521978, 0.11331395290793761, 0.11525767167738965, 0.11950098619217676, 0.10480982443246514, 0.11203100544655506, 0.1030767451143901, 0.1086020986916955, 0.10003887091262681, 0.1059377465827567, 0.11569147915072575, 0.11188954451709963, 0.10295335143449431, 0.11957098557273865, 0.11219520517956214, 0.10149408079887441, 0.11261345465275623, 0.1098683299172867, 0.10279004965633953, 0.111726977295625, 0.11991827299076022, 0.11589666375555194, 0.10945900355041716, 0.10323321378799001, 0.11845163018127641, 0.11465404164504599, 0.11441351485481568, 0.11052225142015837, 0.10556504814811708, 0.10395961876726136, 0.10892614296314407, 0.10009431585328098, 0.10845387964092672, 0.11339246055831073, 0.1118440627445338, 0.1000352281997266, 0.10281265069408208, 0.10044892957669053, 0.11084428007537428, 0.10086702484401906, 0.1029000365050309, 0.11731078456339686, 0.11543747362812329, 0.10101143001015543, 0.11362271224375536, 0.10812549514355621, 0.11322697649192007, 0.10922020742707753, 0.11755252363438984, 0.10096132432976629, 0.106397728338576, 0.11832399659730904, 0.10763019614862296, 0.10336824018030016, 0.10572894972050711, 0.1149636528617911, 0.10526661996509391, 0.10800949230975183, 0.1091670558442632, 0.10256892238079703, 0.1057881864474426, 0.11405875098568671, 0.10242562516948416, 0.11769367702946451, 0.10446958372788524, 0.10782239843319706, 0.1092146285850946, 0.10980682407870918, 0.10554764908052017, 0.10443876236600884, 0.11504565774454102, 0.10370175756695278, 0.10507984206558763, 0.1132940616893745, 0.10136548479507747, 0.11505086867400625, 0.1144406549729794, 0.10920207214518546, 0.11738144525226894, 0.11954037367425671, 0.1151994305201199, 0.1082084962806188, 0.11394035375910645, 0.11035626958386151, 0.10066622375912225, 0.10398578188567949, 0.1131087440609009, 0.10540597730022828, 0.1001930769468461, 0.11472549749106072, 0.10359313107762384, 0.11106343529966821, 0.11000817103763844, 0.11675059177577159, 0.11128826115233063, 0.11180741010598087, 0.11781748910600866, 0.10197687039525002, 0.10186637953250918, 0.11713228325314681, 0.11346940020650602, 0.10590386632644898, 0.11324846155395758, 0.11079402519015931, 0.1086183499391308, 0.1148676657833813, 0.10593171448867561, 0.11713032544707132, 0.10707706658664702, 0.1190633088355431, 0.1121379535317182, 0.10672958234219668, 0.10341093586389931, 0.10977657716282377, 0.10692904084077169, 0.10427763097086058, 0.11761311473778063, 0.10815889069155277, 0.1107589562418115, 0.10274294980841218, 0.10291560581563286, 0.11195536221397295, 0.10833505832316792, 0.11876901036956425, 0.1054856362929486, 0.11981606068190034, 0.11302446807893597, 0.11385418741139333, 0.1080137289743569, 0.11258045216441766, 0.10076182526835491, 0.11110185311343503, 0.11598736114762796, 0.11385301222346374, 0.11893969289917963, 0.11499449478298591, 0.11152455381802134, 0.11472146768320503, 0.10127458358199637, 0.1149895830484485, 0.11073873891321419, 0.10589780541645816, 0.10976086854293225, 0.11801807342775367, 0.10356255096111912, 0.11104506630172133, 0.11818130111081232, 0.10431485469028663, 0.10664452050187768, 0.11266375693687952, 0.10148860455350292, 0.10528011547512273, 0.1106808165092592, 0.11586717541947032, 0.10427881653950338, 0.11151484837491928, 0.10625431197096835, 0.1011288900175401, 0.10739567599714704, 0.10279209177331498, 0.11649473058710486, 0.10877414930228799, 0.11019199140153849, 0.11405386999083245, 0.11746933521353534, 0.10123888961813506, 0.10986931306172854, 0.10657040854706529, 0.11979335844310239, 0.10408569311358698, 0.11497618619294948, 0.11510162236797408, 0.10562710686999446, 0.11858195340624021, 0.10551885495869404, 0.11185857074608219, 0.10021580945265476, 0.10295824972086838, 0.1156926785157618, 0.11575796485286424, 0.10367413430126797, 0.11047152673874935, 0.10392047605607833, 0.1156517348619351, 0.1096931184435743, 0.1007078404601814, 0.1004251868308812, 0.10957865103947918, 0.10841911801716589, 0.11392731518292316, 0.1180223119658253, 0.10866794771061185, 0.11265950317253581, 0.10677544576706494, 0.10728245936280312, 0.11875194986156969, 0.11596582797194618, 0.10071577934336863, 0.10668644742196785, 0.1058823076013266, 0.10696670994393163, 0.11334723689517404, 0.11559355141152215, 0.10724274413440012, 0.10346334278771269, 0.10999376714410312, 0.1071287228758488, 0.1006858658613513, 0.10633256453367135, 0.11158396670045836, 0.10851338214459864, 0.10346013707938502, 0.10448909023912784, 0.10305208118361009, 0.11252939031263304, 0.11779914685763064, 0.1145854892405109, 0.10835664032264222, 0.11211021312906097, 0.10551412720788661, 0.10386848277831967, 0.10810730320625982, 0.11672747369858028, 0.10886243553283625, 0.10095767074572001, 0.10290267510708416, 0.11020102693086159]\n",
      "\tbefore wtr = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3864ee9910>\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38bd22d910> <matplotlib.colors.Normalize object at 0x7f38bd22d910>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3864ee9910>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 83\n",
      "n_events_in_last_interval_right = 79\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 1\n",
      "episode_number = [1]\n",
      "steps_per_episode = [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38be208c50> <matplotlib.colors.Normalize object at 0x7f38bd22d910>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3864e52510>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 335\n",
      "n_events_in_last_interval_right = 217\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 2\n",
      "episode_number = [1]\n",
      "steps_per_episode = [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f386642dc10> <matplotlib.colors.Normalize object at 0x7f38be208c50>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38641c7ad0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 753\n",
      "n_events_in_last_interval_right = 234\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 3\n",
      "episode_number = [1]\n",
      "steps_per_episode = [3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38bd27af90> <matplotlib.colors.Normalize object at 0x7f386642dc10>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3866442d50>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 975\n",
      "n_events_in_last_interval_right = 233\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 4\n",
      "episode_number = [1]\n",
      "steps_per_episode = [4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f3866413450> <matplotlib.colors.Normalize object at 0x7f38bd27af90>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38663f7610>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 230\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 5\n",
      "episode_number = [1]\n",
      "steps_per_episode = [5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38be324a90> <matplotlib.colors.Normalize object at 0x7f3866413450>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3864e92dd0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 228\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 6\n",
      "episode_number = [1]\n",
      "steps_per_episode = [6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38bdca5c10> <matplotlib.colors.Normalize object at 0x7f38be324a90>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3864e94210>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 229\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 7\n",
      "episode_number = [1]\n",
      "steps_per_episode = [7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38bd6a9090> <matplotlib.colors.Normalize object at 0x7f38bdca5c10>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3864ec3b50>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 226\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 8\n",
      "episode_number = [1]\n",
      "steps_per_episode = [8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f386420ca90> <matplotlib.colors.Normalize object at 0x7f38bd6a9090>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3864ec3810>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 225\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 9\n",
      "episode_number = [1]\n",
      "steps_per_episode = [9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f3864eba010> <matplotlib.colors.Normalize object at 0x7f386420ca90>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38bd7401d0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 225\n",
      "ast chosen = left\n",
      "..... episode_number = 1\n",
      "..... steps_per_episode = 10\n",
      "episode_number = [1]\n",
      "steps_per_episode = [10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841028/1802972612.py:98: UserWarning:Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38bd778f50> <matplotlib.colors.Normalize object at 0x7f3864eba010>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38bd6a2850>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure in main loop!\n",
      "Chosen action = LEFT\n",
      "\tbeta = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
      "\tbefore w = [0.46269629069872964, 0.4506475060228748, 0.45129947143754234, 0.46387993695059115, 0.4650298870227356, 0.4570454850607842, 0.45643754791427726, 0.46357160465039926, 0.44685135470151, 0.45154983440851276, 0.46467238331278493, 0.44707022416402864, 0.448087215921694, 0.45188670405205505, 0.4480086076478661, 0.45754731225594286, 0.46313859646657635, 0.4498536264934275, 0.452146616005063, 0.46320978643871474, 0.45970964174987505, 0.46119480663301393, 0.45056075243152854, 0.45453711468194413, 0.46499020009381525, 0.4536841258043742, 0.46155263630953364, 0.45931510248982904, 0.4528760084785183, 0.462942364911315, 0.4573213707528606, 0.46659848484476474, 0.45195568673097997, 0.4512868710695735, 0.44813846142718256, 0.4488104196484298, 0.4552812329770187, 0.46599878229758457, 0.4486020474950292, 0.4639382289685108, 0.4574354423852188, 0.4482638179270399, 0.4594532214891823, 0.4518598449211948, 0.465892195031744, 0.45312363194834426, 0.46273369241001827, 0.44994024546335853, 0.45995042745371006, 0.46364277444893437, 0.4614927301645329, 0.4622049354104202, 0.4626776430809072, 0.4549583921888013, 0.4484587452826124, 0.45384139001297363, 0.4562776770275718, 0.46500351113129434, 0.46260821354474335, 0.46390305290644385, 0.44759998849841925, 0.45767346106644013, 0.45803038294830056, 0.4553967632853833, 0.45376327481460255, 0.45237970059063076, 0.4466473824578376, 0.4484427591211455, 0.4509896720705775, 0.46540666889505433, 0.4612988735313159, 0.46021049702519934, 0.4576393227744752, 0.45074897874708575, 0.45617589341693005, 0.44740010524380147, 0.455114516802695, 0.45501265909152494, 0.45727726606694147, 0.4604610957596632, 0.4477850199525907, 0.4554552059336807, 0.45746190522836616, 0.44995655710875676, 0.46383314524056696, 0.4645574499114131, 0.4575365600384341, 0.4533255392931551, 0.4631382501763258, 0.4597277855642088, 0.45824552815932246, 0.4542955333170757, 0.4491422432128554, 0.4469019473319996, 0.45962309974715587, 0.45796479203431983, 0.4598991560898464, 0.46662979669646887, 0.4492189557744002, 0.4474666472145994, 0.46405571850333704, 0.45020819708546767, 0.4543079446564574, 0.4512439200370394, 0.4657053195273282, 0.4587486670111015, 0.44985819435695934, 0.45938224781734627, 0.4605890181063031, 0.46188834101147636, 0.4573007226635839, 0.462529469227378, 0.44751764457157633, 0.45220606740074354, 0.46323218845944036, 0.4592271798318377, 0.45628464276863967, 0.45308950481558674, 0.46058685552669903, 0.4609085165831802, 0.4630156756795723, 0.4661038314759356, 0.45318792870514324, 0.4545412483062153, 0.4623605670526896, 0.4546436897704558, 0.45171539744560624, 0.46602739052506087, 0.4531750686596422, 0.4583185316985696, 0.45678007942677845, 0.44685904630280504, 0.45409447226917277, 0.4510549197540171, 0.4497650961065729, 0.45412779547390325, 0.4587755850624936, 0.451050476003151, 0.44811435738890953, 0.45412154950487066, 0.4473570492745245, 0.45872368799292956, 0.46410265880268664, 0.4546751342736845, 0.45898457600726816, 0.45802132868682915, 0.4623597109625082, 0.4519399801123765, 0.450650377834939, 0.45513399920004066, 0.4623652218075537, 0.4563268844792955, 0.44893385299697597, 0.45974744283817365, 0.45496090661475247, 0.4663489172989293, 0.4612137687263017, 0.45647768187497145, 0.4488613995487562, 0.45798647268897463, 0.4648855820772907, 0.4614326702313154, 0.4629341356598342, 0.46577436675468026, 0.4623983563593657, 0.4657781172281307, 0.4570813116586779, 0.4640632743785589, 0.4502552618112188, 0.4604933118218807, 0.45875609176280513, 0.4560497396158487, 0.45453224540343296, 0.4585018691342786, 0.4605190295593425, 0.4553086762007462, 0.452539452475198, 0.4638627999750151, 0.4502755639702459, 0.44817055064145966, 0.4527694622698041, 0.4614500647843858, 0.4566184627049547, 0.4642034201791321, 0.46020727511092885, 0.4647201481163617, 0.45453743598245766, 0.45424574643102034, 0.45552632067545407, 0.45500573019086976, 0.45806928719795614, 0.45130584143036045, 0.4632442560633031, 0.45918868513379624, 0.4476290122329075, 0.45926629291219334, 0.45915777179990086, 0.44899472796162093, 0.46399026355226713, 0.46114187658964934, 0.4608279013811502, 0.4546086743759262, 0.44952343221781693, 0.45060737481635155, 0.4584930842804106, 0.45891965879157665, 0.4627572389900614, 0.45121657001186083, 0.4586506751338677, 0.46394340920156124, 0.45010904415154473, 0.44786662151958456, 0.46296116083207095, 0.4561854729066899, 0.45362817586984366, 0.4595264513917912, 0.4628116524770425, 0.4630560048675769, 0.4584052534075814, 0.4505196025122207, 0.4512054167862285, 0.4557113021798915, 0.4480295288363332, 0.4526089600241263, 0.4472110142351303, 0.4543991292150992, 0.4525368133308538, 0.46632982331748973, 0.4631485086925845, 0.45080226692516634, 0.46004625047325903, 0.45052247592957256, 0.4577454011827145, 0.4515528103457796, 0.4506850590761963, 0.4627320182179615, 0.4522685710355852, 0.4587627462335315, 0.4532473636303821, 0.4628355592417829, 0.44691296883152276, 0.4652878031069699, 0.45829042483318255, 0.44886746247444664, 0.456849572098635, 0.4530218691271619, 0.4656267567744382, 0.46404010261084666, 0.4548884027101854, 0.4481729194675481, 0.4602275812418915, 0.4634705016838493, 0.4604767175393488, 0.45838179106833893, 0.460723519538676, 0.4632650400366043, 0.4659299963579, 0.4488971230232885, 0.46136566162548953, 0.4596853981530078, 0.45536303593724514, 0.4609090745715117, 0.458222170529458, 0.45885656971745103, 0.44921318261659776, 0.45075006000778367, 0.4508985760808716, 0.4628941264396594, 0.4575106062388776, 0.44856480298423484, 0.4551529553398249, 0.4573986852482099, 0.4615666433827509, 0.4562133938828863, 0.46652450821948815, 0.4528544045020156, 0.44981294597882937, 0.4644764825891858, 0.45354337300934444, 0.46440479202519264, 0.45405448062986464, 0.4654386321840776, 0.4654809309904452, 0.464290210044376, 0.4601883364117449, 0.4575001835453415, 0.4510750717715317, 0.45637710129543696, 0.4477552420264935, 0.4652158092974216, 0.44754858691023625, 0.4485771120588089, 0.46402425547110615, 0.4645330901222769, 0.46210678033889596, 0.46495745866697435, 0.4657287347888322, 0.45531797510250493, 0.46537457289809175, 0.4497607080416365, 0.229264399668723, 0.2263140135746991, 0.22616839843394596, 0.23639295952888262, 0.231712711949533, 0.22337876773865004, 0.21860415548966772, 0.22545833905055365, 0.2335315655728281, 0.22617311015779365, 0.4857482545466015, 0.47071105858766704, 0.48558339829946734, 0.4791798154725035, 0.4849986588948527, 0.46859505321173134, 0.48857821232520504, 0.4837580759860419, 0.4739286090299282, 0.4894336693843753, 0.4665164078967853, 0.4612918405700471, 0.45812925233983626, 0.4565508108753378, 0.459460830901049, 0.45519459327246553, 0.45490963195039774, 0.46509982586599, 0.46406100932100286, 0.4615952873995014, 0.45461242105591443, 0.4648332341565571, 0.4665778256758727, 0.45002758275419324, 0.4509441139787757, 0.46613425320795865, 0.45530904425163277, 0.4560140674503911, 0.4620625489222427, 0.4546987051110131, 0.4600068584922756, 0.4529850927958777, 0.4605402033112532, 0.46505017254300196, 0.4576931777853917, 0.4626552736771812, 0.45024902741573697, 0.4658431788331272, 0.45681824191554776, 0.46285227656607547, 0.4551141073793387, 0.44757428982108616, 0.4608391894714624, 0.44822226141185173, 0.4547514353862916, 0.4466791825378119, 0.45292814294722494, 0.4609227868057702, 0.4548698797082791, 0.4503528600995807, 0.44789548809298857, 0.45900722861936266, 0.46207800198729676, 0.4531295748937142, 0.4591159295482592, 0.45774511959888725, 0.44974972775186856, 0.45786310190008833, 0.46364032494645563, 0.45037019936404044, 0.45708612773619445, 0.45144130264181165, 0.44871753402125597, 0.4467086207289189, 0.44863640581625147, 0.4540805662778725, 0.449958298444954, 0.46450598361723516, 0.4645309901292567, 0.45762594201614065, 0.4581246904550109, 0.45556540907033904, 0.44721343906431205, 0.46408553588062884, 0.4535041513713322, 0.4560930027882497, 0.45225814461356995, 0.45389391070302143, 0.46423205314520755, 0.4536029517600408, 0.4663188393873164, 0.4480501619027978, 0.46063339214524907, 0.4626087746160188, 0.4616727107700664, 0.45123291136764815, 0.4601500752654694, 0.44914354926810995, 0.46489681745448325, 0.4520454134030146, 0.4576458751470701, 0.4622313014515689, 0.4512745656156906, 0.4492378039623173, 0.4620638264997847, 0.4594290605324019, 0.4656151237995394, 0.4521933969313407, 0.45569265308297385, 0.45347018114599424, 0.46472296971744953, 0.4614714611601465, 0.4664352317959675, 0.45199985222915856, 0.45203240913326453, 0.46222988836569406, 0.4601168862426306, 0.4565476876830111, 0.45576710901322315, 0.45806600587962537, 0.45680890599721446, 0.4471962400735173, 0.4572000762645312, 0.45696121068565176, 0.46118818190057753, 0.4636018487001874, 0.46106597013743, 0.45708172900894417, 0.4577970009869843, 0.4627475364068889, 0.45928958599556646, 0.45871191524066757, 0.4518939270851397, 0.45172281231375705, 0.4518120927337474, 0.4485726656930814, 0.4509053507505007, 0.4512051863231211, 0.45626019754463754, 0.45917473444116885, 0.4626702971070256, 0.45139937218979176, 0.45191327259332587, 0.4466951178821022, 0.46366283230920285, 0.4559375479788172, 0.46362528224927724, 0.4571460994369383, 0.45414460890368924, 0.46394729410121327, 0.45126417526684864, 0.45864221705387953, 0.4658267854268012, 0.46640273291074186, 0.4489812275251645, 0.45661234710416904, 0.448798949184134, 0.46072572418982954, 0.44863741817904085, 0.4588588192542903, 0.4591630191975455, 0.44986228714865506, 0.46297262621633184, 0.45056040117491386, 0.4606416001367355, 0.466201696882238, 0.4626605534007726, 0.46109788428676884, 0.4635502855182779, 0.4572231621543052, 0.46258695751677814, 0.4576012026474149, 0.4474161130361593, 0.46215635381683207, 0.45293218139363906, 0.4578095429993849, 0.45285411822437494, 0.45154307228793034, 0.46045855834418686, 0.4615225791019416, 0.4508347109992212, 0.4602304263530907, 0.44986132515251664, 0.45261540566792374, 0.46210479032995605, 0.4623816613594639, 0.46372631431362904, 0.4557455608916929, 0.4613522062750711, 0.4626498141765336, 0.4556453770310058, 0.4603312472713845, 0.45680863090463586, 0.4555113488067156, 0.4662110486283784, 0.46405187452415714, 0.4511914302120081, 0.4540632276191901, 0.4479949754441801, 0.4504892851433812, 0.46126275401251315, 0.45066644586079996, 0.45007615192726924, 0.46015613378791625, 0.46560882153186484, 0.45775956298103615, 0.44695928752614644, 0.46104376074906117, 0.46612432654244873, 0.45694337755586023, 0.4492966815211045, 0.4579512104574925, 0.4570246815669463, 0.4599744322685003, 0.44849692401397945, 0.4506030082704057, 0.4493992437516531, 0.464252874716733, 0.44772968304140376, 0.45430126223879563, 0.47002779721659943, 0.481035029393353, 0.47406188743468847, 0.4762168157410416, 0.4746736819772112, 0.4714055975580353, 0.4730677351287851, 0.4856268084947019, 0.4832822266230381, 0.471565777583754, 0.4518819766782296, 0.45663566654305465, 0.4569805998366559, 0.4525213932590768, 0.45214589008324035, 0.4528164627978348, 0.46315306741480766, 0.4575507845083645, 0.45314142178342226, 0.45474134735922034, 0.44844419993139767, 0.4619411214847191, 0.4662838033942091, 0.4665636868877318, 0.4582685155223322, 0.4647448623733631, 0.4485875458702343, 0.46005003569837016, 0.4614619115786513, 0.4515361371424533, 0.4604299465964237, 0.4572637802270118, 0.46224848106442784, 0.45947449592993334, 0.4574802307894017, 0.4637094355964205, 0.46202225095490135, 0.4588648990343271, 0.4567274634272261, 0.4497121580134205, 0.460620438137081, 0.4579784417459293, 0.44811757958079707, 0.4611983288587794, 0.45168397046175157, 0.4610354712656861, 0.46100744262083104, 0.4529629807664186, 0.4502497187410971, 0.4484841066440036, 0.4500786799630614, 0.4624973268384982, 0.4479294172610935, 0.4563020172561755, 0.4580623043920876, 0.44942026491448506, 0.4507750365386889, 0.4484702601821494, 0.4562492067666214, 0.45425798609915913, 0.46143600178506955, 0.4501417070157061, 0.46478638641830455, 0.45788557432323257, 0.4609156243801075, 0.4592390947570862, 0.45721194093414663, 0.45322415727794085, 0.45743558820257274, 0.4581160107252067, 0.46653988243947364, 0.44886220095300655, 0.46211291079524686, 0.44882554007694886, 0.4585688172203006, 0.4575794961313276, 0.4500439353393938, 0.45941087796244917, 0.4572695507243504, 0.4521617834477038, 0.448215445498904, 0.447091378837127, 0.4491498663683038, 0.46365886015952124, 0.460696941277535, 0.4649930059505163, 0.4590413013282594, 0.4603749351311989, 0.4591266031490783, 0.46180544327113054, 0.46047452919149484, 0.4545790752961069, 0.46230904778272847, 0.4641671495293602, 0.455119324524003, 0.45115949133648825, 0.44747482269302646, 0.456943108930312, 0.46565030553435544, 0.46258503376384974, 0.4516820926966132, 0.4571780737865954, 0.4484049920941271, 0.4633628882255814, 0.4492982798495142, 0.46037004172750035, 0.45142500412292547, 0.4643219546945318, 0.45872869785237347, 0.449694458319881, 0.45316150883728146, 0.45229767020398637, 0.44702095693180494, 0.45634258505093356, 0.4595312932690533, 0.4635177526918468, 0.4601001574164342, 0.4651924015304377, 0.4620219180487368, 0.4653954442215631, 0.4587645345744663, 0.45962685018693555, 0.457610874382636, 0.45484173350548546, 0.4569996822070448, 0.44946585457136373, 0.46050041532667724, 0.4647650455011998, 0.4596759616384166, 0.4631337910403868, 0.45208235389849116, 0.44937213006511717, 0.45331510930507496, 0.45877840998421915, 0.4578707457541087, 0.4643886600696441, 0.46431643454092547, 0.4586594817505916, 0.46225332025119176, 0.45742725674222207, 0.46210121488740685, 0.46166229397805153, 0.4496243683682336, 0.45183359747026364, 0.45616420547774034, 0.4614367170659916, 0.4496608197143448, 0.45413678384448214, 0.4581818663788382, 0.44953023377780593, 0.4472552022363288, 0.4488262031375487, 0.45061079772238816, 0.46039716045629, 0.4535786301280441, 0.44902736934682724, 0.46038819096393857, 0.4533534510860586, 0.46035569066408455, 0.4647789297230909, 0.4664309465802181, 0.44730077173012234, 0.4580741626175864, 0.4653390125247592, 0.44721474718075777, 0.4594868765039651, 0.45553969185285864, 0.4475623227660858, 0.46643919716717097, 0.4655234495264243, 0.46353651527470363, 0.4591493390669378, 0.4595191499048501, 0.44767744689034245, 0.45521073893392017, 0.4497553112531021, 0.44719439126608485, 0.46046915613246986, 0.44914532563326415, 0.4528875489957112, 0.46087630984570105, 0.4658919932228399, 0.4531037710910691, 0.46284827527020056, 0.44785470968366353, 0.4516063040065578, 0.4614618434399913, 0.4567271816220165, 0.45198544298920945, 0.45831396201975827, 0.4532003331063269, 0.4507616394628402, 0.44743944252991696, 0.4482166132361406, 0.457007742632083, 0.45695309122104477, 0.46658434355106404, 0.45597458016854553, 0.45314434858352054, 0.44932550112235303, 0.45468381024432636, 0.45133084815681884, 0.45671684148332553, 0.4493127338919716, 0.463467560484078, 0.4584733129432861, 0.45925071604592316, 0.4597155583224095, 0.4497867362169148, 0.45510025905411455, 0.4659610191741379, 0.4527219288435711, 0.4643841599414032, 0.4557027284344407, 0.46641172170823797, 0.4540420853523137, 0.4558323425422996, 0.452879471661764, 0.4521407070454958, 0.45521252929539824, 0.45492331827202537, 0.45047517944630294, 0.45796064742926446, 0.4491231843503952, 0.4611654219951099, 0.4650753134634772, 0.46198188019670416, 0.4504785672783893, 0.4502191440092435, 0.45438370688584473, 0.4604323993766557, 0.45093791218759544, 0.4514599584313148, 0.4534809266337525, 0.46080851285339364, 0.4653211073283914, 0.4610941624945408, 0.44710824810777083, 0.4581139998822057, 0.450951265498385, 0.45118368872033604, 0.4565513178754599, 0.4640789007124286, 0.4643358399135261, 0.45339452975040684, 0.4593682480993343, 0.46052198636003705, 0.44927116098494224, 0.45434258203542643, 0.45041246968973114, 0.4553190322863029, 0.44863996581251436, 0.45701869902532316, 0.46492436003551446, 0.46057502480405377, 0.4541191350568339, 0.46402528895549217, 0.4583755861494557, 0.4463513464234246, 0.45834114288010114, 0.447217983928476, 0.4608720625617404, 0.4472256838781287, 0.4640594602375921, 0.4496030529419933, 0.4582763212004203, 0.4596059609989956, 0.44834021242947975, 0.4538302864867194, 0.45966846150918067, 0.45623002299491855, 0.45535407106238773, 0.4588082808078879, 0.4608357388213179, 0.4565417459579788, 0.45652750881643855, 0.4628665581247815, 0.4481040484694613, 0.4503931312325753, 0.45010018230873006, 0.4587604815721355, 0.4617776780011588, 0.4493891330001067, 0.45946496575844586, 0.45718578931636294, 0.46226116553922814, 0.4615304012312201, 0.45333538087552105, 0.46055925319197427, 0.44826977939757257, 0.4484218033856443, 0.46205027333012966, 0.45513117528689623, 0.4647523623305059, 0.4553379097470934, 0.447095591106928, 0.4649606368867538, 0.4543333424825119, 0.4525666333941837, 0.462104778863761, 0.4525381887547414, 0.4567836486054929, 0.4666276461371849, 0.44671163076780673, 0.45261409514154904, 0.4554577098313398, 0.46536877989174896, 0.45599133787712076, 0.45497673071946787, 0.4493088765951505, 0.46626053536216716, 0.4619575372230973, 0.4611320098373701, 0.45113750689485366, 0.46618746775598113, 0.4478829748539757, 0.4651721406762966, 0.4633141517506982, 0.4603718317525638, 0.4588730548894494, 0.45618817794935074, 0.4653536971956943, 0.46621621958700504, 0.4494159449558142, 0.45648709281672234, 0.4660494751449127, 0.45728826656724164, 0.46155925204108617, 0.452513602886096, 0.4622073560911063, 0.45610260207146264, 0.46007742179130506, 0.452845449053117, 0.4512272123868488, 0.4624770875944213, 0.4496715278049399, 0.46318930292948646, 0.4625981532347831, 0.45170420916798054, 0.4581951583403212, 0.4545610400849638, 0.46022406942731847, 0.44756107473059037, 0.4630836772784893, 0.4588065113562169, 0.44821676337990723, 0.4585511425387016, 0.46083626663404453, 0.4522322035684196, 0.4515555296034427, 0.4476686904544862, 0.46302058295263887, 0.4642922603947941, 0.44818481421433937, 0.4638022813070031, 0.45849132193055264, 0.4529274758513899, 0.45525258040120575, 0.45695346594441344, 0.46029021009670607, 0.45394960338206547, 0.46345005805552486, 0.4540805726164259, 0.45043531661326375, 0.46275911876402437, 0.44974117837330296, 0.45975600717494414, 0.4595499242074436, 0.45977158016759645, 0.4639782719581884, 0.4582925926966651, 0.46073057843117526, 0.4645787911552048, 0.4642277185353183, 0.46392081348927794, 0.4609175300380956, 0.4561210540740449, 0.4477721287210753, 0.4628669564856412, 0.45254400520420646, 0.4571739124175606, 0.4547165590716598, 0.45866902819765143, 0.45413655522583285, 0.4557947217823006, 0.45975333318890177, 0.4568541271669626, 0.45827287023864444, 0.45049636729740855, 0.45775231227408525, 0.45000082385032514, 0.454085876372656, 0.46605619372403917, 0.4631772087435517, 0.4530930131349445, 0.4525843242467962, 0.4638836185278029, 0.46521077699897706, 0.4557049491224904, 0.4621223925879844, 0.461831765618665, 0.45700396590757986, 0.4650275525953038, 0.4508644098027208, 0.4551018493486275, 0.4589905836043675, 0.44784205287004963, 0.4645612223353998, 0.4574939273774547, 0.4637303223910227, 0.45666326323051304, 0.46443110466952997, 0.45655445537509715, 0.4568579943419384, 0.4552728260609435, 0.4628473384197366, 0.4511883693364586, 0.452933353288197, 0.4622706787883289, 0.4519357053923354, 0.45251774289764457, 0.4548197438465583, 0.4570024686644879, 0.4496871744866297, 0.4598488922078673, 0.45791224676126263, 0.45563706601415616, 0.4552410895612252, 0.4496453643061794, 0.45433783999840843, 0.45141559785042695, 0.46461464144670084, 0.4542936175404344, 0.4604709456696434, 0.4597977804449088, 0.460275813591452, 0.46519527457310333, 0.45727692085164495, 0.4632538974239523, 0.4658108215273369, 0.46658979912713394, 0.45423457768676223, 0.4558171327551847, 0.4480664955229378, 0.46205393082268087, 0.46407155167130776, 0.45238108637874375, 0.4574304420955864, 0.45223413001076385, 0.46138512074315674, 0.4534628395832997, 0.4638246154815634, 0.4648000762750095, 0.46134897668838054, 0.4556713549896527, 0.45970647254305297, 0.4657261097036747, 0.45406856113735417, 0.4585737312814489, 0.45439629495721123, 0.46374800671038424, 0.45717700518029186, 0.4617341195588629, 0.461004714787376, 0.45675030455432325, 0.45992294710361353, 0.45923717799501623, 0.46503877132903887, 0.45120099351667525, 0.45801311428355174, 0.45874759386631414, 0.4580911591283541, 0.4546222918080729, 0.45496212102762124, 0.4518124279384296, 0.45364408593000044, 0.46260190835237647, 0.4501577245435201, 0.458802565129626, 0.4481639767701038, 0.45257466642410843, 0.44842422798263937, 0.4620976062238828, 0.462137109662218, 0.45677829732354314, 0.4648521756964423, 0.45391391934119774, 0.4572933754143758, 0.4617245659220263, 0.4508607169084044, 0.44695891093535967, 0.4658688598649688, 0.44893803179892183, 0.45093930605239213, 0.46541653931826593, 0.46653458458179925, 0.44978930139554707, 0.45216158436920967, 0.4507057902203444, 0.45582358503470155, 0.4473531133799215, 0.4504854640591023, 0.4477617252239237, 0.4511802898603464, 0.462146937694692, 0.45053439277618884, 0.45888124100689454, 0.45956079501181396, 0.4568156180558199, 0.45090179434523336, 0.4571559259000021, 0.4555388134140936, 0.4632065209111393, 0.46486910389153735, 0.4652729260250443, 0.45686592474054816, 0.45647983318044605, 0.44881284155237383, 0.45449536434090243, 0.46296346776633746, 0.4539095800527247, 0.44800240793404017, 0.4572381148369854, 0.45955695963367915, 0.45299016804494774, 0.4610021470821781, 0.46185044275551507, 0.46331619859820417, 0.45670899485230115, 0.46265405142827115, 0.45580234760549504, 0.4659603640071355, 0.4531026914843478, 0.45980534314091226, 0.4467259801597091, 0.45523617420840135, 0.45650914755719363, 0.46031635059538334, 0.4610700796829237, 0.4619146680731119, 0.4548651527858899, 0.46399910836502056, 0.4575267083361115, 0.44728614329446603, 0.45801245797425827, 0.4592529763667225, 0.45270602575651214, 0.4657965837618934, 0.46326950980162535, 0.4631125438469007, 0.46528833473451614, 0.4608620847889826, 0.4477884544276314, 0.4494335400563302, 0.4591125960987823, 0.45747093996278754, 0.4491689950124875, 0.46543700311871017, 0.46218827657611555, 0.4626920853011677, 0.46485589648522474, 0.4615425082889423, 0.45163429055966287, 0.46581309976475915, 0.45159211285657175, 0.4606228288161136, 0.45511336504059896, 0.4565390223372228, 0.4499265220497797, 0.45138442598682865, 0.4592684927051638, 0.45982031975718796, 0.45560549864152416, 0.4568082663882415, 0.4523771657859351, 0.4512628261710855, 0.4534428607382919, 0.44784147674530383, 0.4478803579417854, 0.4499182322427264, 0.4601556661790819, 0.4572400456115361, 0.4618222072877578, 0.4646915573185162, 0.46523842626555634, 0.4542436374462224, 0.44784940228469683, 0.45190024716955496, 0.46051240634370627, 0.45074399369448526, 0.45474078395074335, 0.46611716503123424, 0.4500555774414714, 0.45558973875565656, 0.45813035745995695, 0.4654416567501312, 0.4491609784632078, 0.45156448524440684, 0.46102175237069676, 0.462212449761766, 0.4548214349362015, 0.4656883182984567, 0.4645802453561881, 0.4619709317258737, 0.4581656433681669, 0.45418146113478086, 0.45300046450984877, 0.46324873748296186, 0.4599704528483556, 0.4615882682699882, 0.46096051933526094, 0.46514661488105347, 0.46371029116526236, 0.4656608083487741, 0.45595914885788186, 0.44955930822607004, 0.4590060068510867, 0.4643493616091582, 0.4631007034290681, 0.4473572027886353, 0.4619676438434758, 0.4581899563255415, 0.4484899204454328, 0.46421872863274877, 0.4609934346199115, 0.4585192984110007, 0.44820920254156804, 0.45961742620806156, 0.44911520303762537, 0.4542008692118535, 0.4589495282608544, 0.4486691888917702, 0.4596977706248384, 0.4649969541674987, 0.4487127373442785, 0.4597464028925353, 0.4659700808391299, 0.45991460018245206, 0.44882258755489235, 0.4543688163717391, 0.4593998022211922, 0.45970535880232644, 0.4478561247458883, 0.44829435743011237, 0.45201610624639244, 0.4632525670074821, 0.4547487763719896, 0.4660214660945229, 0.45975239949765356, 0.4602290687816726, 0.458709863819306, 0.4609885701615754, 0.46424417070694596, 0.46335589536803407, 0.4555313948834877, 0.4524648528416304, 0.4626605531887124, 0.4484303368469092, 0.4549433074010834, 0.4644106621749319, 0.4626648479837742, 0.4641838966649647, 0.46579040191310395, 0.4646486962954184, 0.4586671840648207, 0.45255370229959146, 0.44762263794113766, 0.4532656682547054, 0.44783576164209377, 0.45877352207276617, 0.46214586735098157, 0.4459530237496043, 0.4619129451217262, 0.4600204860553259, 0.4628516072882097, 0.4577703493230798, 0.4495011455682935, 0.4609597338667972, 0.4529970938164612, 0.4475785637692234]\n",
      "\tbefore wtr = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09997944570832569, 0.09997944843347918, 0.09997945545501653, 0.09997947090743524, 0.09997943286865428, 0.09997944009963229, 0.0999794426699644, 0.09997947727051876, 0.09997944734343887, 0.09997945967887942]\n",
      "\tbefore prev_syn_wtr_right = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048039647187139364, 0.048319065265189864, 0.04676463553364772, 0.04377618422957628, 0.046865652686586136, 0.050681404166493575, 0.046967437106839066, 0.04366166410913197, 0.04612002747371984, 0.04997049961129637]\n",
      "\tbefore TD = -100.0\n",
      "\tafter w = [0.46269629069872964, 0.4506475060228748, 0.45129947143754234, 0.46387993695059115, 0.4650298870227356, 0.4570454850607842, 0.45643754791427726, 0.46357160465039926, 0.44685135470151, 0.45154983440851276, 0.46467238331278493, 0.44707022416402864, 0.448087215921694, 0.45188670405205505, 0.4480086076478661, 0.45754731225594286, 0.46313859646657635, 0.4498536264934275, 0.452146616005063, 0.46320978643871474, 0.45970964174987505, 0.46119480663301393, 0.45056075243152854, 0.45453711468194413, 0.46499020009381525, 0.4536841258043742, 0.46155263630953364, 0.45931510248982904, 0.4528760084785183, 0.462942364911315, 0.4573213707528606, 0.46659848484476474, 0.45195568673097997, 0.4512868710695735, 0.44813846142718256, 0.4488104196484298, 0.4552812329770187, 0.46599878229758457, 0.4486020474950292, 0.4639382289685108, 0.4574354423852188, 0.4482638179270399, 0.4594532214891823, 0.4518598449211948, 0.465892195031744, 0.45312363194834426, 0.46273369241001827, 0.44994024546335853, 0.45995042745371006, 0.46364277444893437, 0.4614927301645329, 0.4622049354104202, 0.4626776430809072, 0.4549583921888013, 0.4484587452826124, 0.45384139001297363, 0.4562776770275718, 0.46500351113129434, 0.46260821354474335, 0.46390305290644385, 0.44759998849841925, 0.45767346106644013, 0.45803038294830056, 0.4553967632853833, 0.45376327481460255, 0.45237970059063076, 0.4466473824578376, 0.4484427591211455, 0.4509896720705775, 0.46540666889505433, 0.4612988735313159, 0.46021049702519934, 0.4576393227744752, 0.45074897874708575, 0.45617589341693005, 0.44740010524380147, 0.455114516802695, 0.45501265909152494, 0.45727726606694147, 0.4604610957596632, 0.4477850199525907, 0.4554552059336807, 0.45746190522836616, 0.44995655710875676, 0.46383314524056696, 0.4645574499114131, 0.4575365600384341, 0.4533255392931551, 0.4631382501763258, 0.4597277855642088, 0.45824552815932246, 0.4542955333170757, 0.4491422432128554, 0.4469019473319996, 0.45962309974715587, 0.45796479203431983, 0.4598991560898464, 0.46662979669646887, 0.4492189557744002, 0.4474666472145994, 0.46405571850333704, 0.45020819708546767, 0.4543079446564574, 0.4512439200370394, 0.4657053195273282, 0.4587486670111015, 0.44985819435695934, 0.45938224781734627, 0.4605890181063031, 0.46188834101147636, 0.4573007226635839, 0.462529469227378, 0.44751764457157633, 0.45220606740074354, 0.46323218845944036, 0.4592271798318377, 0.45628464276863967, 0.45308950481558674, 0.46058685552669903, 0.4609085165831802, 0.4630156756795723, 0.4661038314759356, 0.45318792870514324, 0.4545412483062153, 0.4623605670526896, 0.4546436897704558, 0.45171539744560624, 0.46602739052506087, 0.4531750686596422, 0.4583185316985696, 0.45678007942677845, 0.44685904630280504, 0.45409447226917277, 0.4510549197540171, 0.4497650961065729, 0.45412779547390325, 0.4587755850624936, 0.451050476003151, 0.44811435738890953, 0.45412154950487066, 0.4473570492745245, 0.45872368799292956, 0.46410265880268664, 0.4546751342736845, 0.45898457600726816, 0.45802132868682915, 0.4623597109625082, 0.4519399801123765, 0.450650377834939, 0.45513399920004066, 0.4623652218075537, 0.4563268844792955, 0.44893385299697597, 0.45974744283817365, 0.45496090661475247, 0.4663489172989293, 0.4612137687263017, 0.45647768187497145, 0.4488613995487562, 0.45798647268897463, 0.4648855820772907, 0.4614326702313154, 0.4629341356598342, 0.46577436675468026, 0.4623983563593657, 0.4657781172281307, 0.4570813116586779, 0.4640632743785589, 0.4502552618112188, 0.4604933118218807, 0.45875609176280513, 0.4560497396158487, 0.45453224540343296, 0.4585018691342786, 0.4605190295593425, 0.4553086762007462, 0.452539452475198, 0.4638627999750151, 0.4502755639702459, 0.44817055064145966, 0.4527694622698041, 0.4614500647843858, 0.4566184627049547, 0.4642034201791321, 0.46020727511092885, 0.4647201481163617, 0.45453743598245766, 0.45424574643102034, 0.45552632067545407, 0.45500573019086976, 0.45806928719795614, 0.45130584143036045, 0.4632442560633031, 0.45918868513379624, 0.4476290122329075, 0.45926629291219334, 0.45915777179990086, 0.44899472796162093, 0.46399026355226713, 0.46114187658964934, 0.4608279013811502, 0.4546086743759262, 0.44952343221781693, 0.45060737481635155, 0.4584930842804106, 0.45891965879157665, 0.4627572389900614, 0.45121657001186083, 0.4586506751338677, 0.46394340920156124, 0.45010904415154473, 0.44786662151958456, 0.46296116083207095, 0.4561854729066899, 0.45362817586984366, 0.4595264513917912, 0.4628116524770425, 0.4630560048675769, 0.4584052534075814, 0.4505196025122207, 0.4512054167862285, 0.4557113021798915, 0.4480295288363332, 0.4526089600241263, 0.4472110142351303, 0.4543991292150992, 0.4525368133308538, 0.46632982331748973, 0.4631485086925845, 0.45080226692516634, 0.46004625047325903, 0.45052247592957256, 0.4577454011827145, 0.4515528103457796, 0.4506850590761963, 0.4627320182179615, 0.4522685710355852, 0.4587627462335315, 0.4532473636303821, 0.4628355592417829, 0.44691296883152276, 0.4652878031069699, 0.45829042483318255, 0.44886746247444664, 0.456849572098635, 0.4530218691271619, 0.4656267567744382, 0.46404010261084666, 0.4548884027101854, 0.4481729194675481, 0.4602275812418915, 0.4634705016838493, 0.4604767175393488, 0.45838179106833893, 0.460723519538676, 0.4632650400366043, 0.4659299963579, 0.4488971230232885, 0.46136566162548953, 0.4596853981530078, 0.45536303593724514, 0.4609090745715117, 0.458222170529458, 0.45885656971745103, 0.44921318261659776, 0.45075006000778367, 0.4508985760808716, 0.4628941264396594, 0.4575106062388776, 0.44856480298423484, 0.4551529553398249, 0.4573986852482099, 0.4615666433827509, 0.4562133938828863, 0.46652450821948815, 0.4528544045020156, 0.44981294597882937, 0.4644764825891858, 0.45354337300934444, 0.46440479202519264, 0.45405448062986464, 0.4654386321840776, 0.4654809309904452, 0.464290210044376, 0.4601883364117449, 0.4575001835453415, 0.4510750717715317, 0.45637710129543696, 0.4477552420264935, 0.4652158092974216, 0.44754858691023625, 0.4485771120588089, 0.46402425547110615, 0.4645330901222769, 0.46210678033889596, 0.46495745866697435, 0.4657287347888322, 0.45531797510250493, 0.46537457289809175, 0.4497607080416365, 0.229264399668723, 0.2263140135746991, 0.22616839843394596, 0.23639295952888262, 0.231712711949533, 0.22337876773865004, 0.21860415548966772, 0.22545833905055365, 0.2335315655728281, 0.22617311015779365, 0.4857482545466015, 0.47071105858766704, 0.48558339829946734, 0.4791798154725035, 0.4849986588948527, 0.46859505321173134, 0.48857821232520504, 0.4837580759860419, 0.4739286090299282, 0.4894336693843753, 0.4665164078967853, 0.4612918405700471, 0.45812925233983626, 0.4565508108753378, 0.459460830901049, 0.45519459327246553, 0.45490963195039774, 0.46509982586599, 0.46406100932100286, 0.4615952873995014, 0.45461242105591443, 0.4648332341565571, 0.4665778256758727, 0.45002758275419324, 0.4509441139787757, 0.46613425320795865, 0.45530904425163277, 0.4560140674503911, 0.4620625489222427, 0.4546987051110131, 0.4600068584922756, 0.4529850927958777, 0.4605402033112532, 0.46505017254300196, 0.4576931777853917, 0.4626552736771812, 0.45024902741573697, 0.4658431788331272, 0.45681824191554776, 0.46285227656607547, 0.4551141073793387, 0.44757428982108616, 0.4608391894714624, 0.44822226141185173, 0.4547514353862916, 0.4466791825378119, 0.45292814294722494, 0.4609227868057702, 0.4548698797082791, 0.4503528600995807, 0.44789548809298857, 0.45900722861936266, 0.46207800198729676, 0.4531295748937142, 0.4591159295482592, 0.45774511959888725, 0.44974972775186856, 0.45786310190008833, 0.46364032494645563, 0.45037019936404044, 0.45708612773619445, 0.45144130264181165, 0.44871753402125597, 0.4467086207289189, 0.44863640581625147, 0.4540805662778725, 0.449958298444954, 0.46450598361723516, 0.4645309901292567, 0.45762594201614065, 0.4581246904550109, 0.45556540907033904, 0.44721343906431205, 0.46408553588062884, 0.4535041513713322, 0.4560930027882497, 0.45225814461356995, 0.45389391070302143, 0.46423205314520755, 0.4536029517600408, 0.4663188393873164, 0.4480501619027978, 0.46063339214524907, 0.4626087746160188, 0.4616727107700664, 0.45123291136764815, 0.4601500752654694, 0.44914354926810995, 0.46489681745448325, 0.4520454134030146, 0.4576458751470701, 0.4622313014515689, 0.4512745656156906, 0.4492378039623173, 0.4620638264997847, 0.4594290605324019, 0.4656151237995394, 0.4521933969313407, 0.45569265308297385, 0.45347018114599424, 0.46472296971744953, 0.4614714611601465, 0.4664352317959675, 0.45199985222915856, 0.45203240913326453, 0.46222988836569406, 0.4601168862426306, 0.4565476876830111, 0.45576710901322315, 0.45806600587962537, 0.45680890599721446, 0.4471962400735173, 0.4572000762645312, 0.45696121068565176, 0.46118818190057753, 0.4636018487001874, 0.46106597013743, 0.45708172900894417, 0.4577970009869843, 0.4627475364068889, 0.45928958599556646, 0.45871191524066757, 0.4518939270851397, 0.45172281231375705, 0.4518120927337474, 0.4485726656930814, 0.4509053507505007, 0.4512051863231211, 0.45626019754463754, 0.45917473444116885, 0.4626702971070256, 0.45139937218979176, 0.45191327259332587, 0.4466951178821022, 0.46366283230920285, 0.4559375479788172, 0.46362528224927724, 0.4571460994369383, 0.45414460890368924, 0.46394729410121327, 0.45126417526684864, 0.45864221705387953, 0.4658267854268012, 0.46640273291074186, 0.4489812275251645, 0.45661234710416904, 0.448798949184134, 0.46072572418982954, 0.44863741817904085, 0.4588588192542903, 0.4591630191975455, 0.44986228714865506, 0.46297262621633184, 0.45056040117491386, 0.4606416001367355, 0.466201696882238, 0.4626605534007726, 0.46109788428676884, 0.4635502855182779, 0.4572231621543052, 0.46258695751677814, 0.4576012026474149, 0.4474161130361593, 0.46215635381683207, 0.45293218139363906, 0.4578095429993849, 0.45285411822437494, 0.45154307228793034, 0.46045855834418686, 0.4615225791019416, 0.4508347109992212, 0.4602304263530907, 0.44986132515251664, 0.45261540566792374, 0.46210479032995605, 0.4623816613594639, 0.46372631431362904, 0.4557455608916929, 0.4613522062750711, 0.4626498141765336, 0.4556453770310058, 0.4603312472713845, 0.45680863090463586, 0.4555113488067156, 0.4662110486283784, 0.46405187452415714, 0.4511914302120081, 0.4540632276191901, 0.4479949754441801, 0.4504892851433812, 0.46126275401251315, 0.45066644586079996, 0.45007615192726924, 0.46015613378791625, 0.46560882153186484, 0.45775956298103615, 0.44695928752614644, 0.46104376074906117, 0.46612432654244873, 0.45694337755586023, 0.4492966815211045, 0.4579512104574925, 0.4570246815669463, 0.4599744322685003, 0.44849692401397945, 0.4506030082704057, 0.4493992437516531, 0.464252874716733, 0.44772968304140376, 0.45430126223879563, 0.47002779721659943, 0.481035029393353, 0.47406188743468847, 0.4762168157410416, 0.4746736819772112, 0.4714055975580353, 0.4730677351287851, 0.4856268084947019, 0.4832822266230381, 0.471565777583754, 0.4518819766782296, 0.45663566654305465, 0.4569805998366559, 0.4525213932590768, 0.45214589008324035, 0.4528164627978348, 0.46315306741480766, 0.4575507845083645, 0.45314142178342226, 0.45474134735922034, 0.44844419993139767, 0.4619411214847191, 0.4662838033942091, 0.4665636868877318, 0.4582685155223322, 0.4647448623733631, 0.4485875458702343, 0.46005003569837016, 0.4614619115786513, 0.4515361371424533, 0.4604299465964237, 0.4572637802270118, 0.46224848106442784, 0.45947449592993334, 0.4574802307894017, 0.4637094355964205, 0.46202225095490135, 0.4588648990343271, 0.4567274634272261, 0.4497121580134205, 0.460620438137081, 0.4579784417459293, 0.44811757958079707, 0.4611983288587794, 0.45168397046175157, 0.4610354712656861, 0.46100744262083104, 0.4529629807664186, 0.4502497187410971, 0.4484841066440036, 0.4500786799630614, 0.4624973268384982, 0.4479294172610935, 0.4563020172561755, 0.4580623043920876, 0.44942026491448506, 0.4507750365386889, 0.4484702601821494, 0.4562492067666214, 0.45425798609915913, 0.46143600178506955, 0.4501417070157061, 0.46478638641830455, 0.45788557432323257, 0.4609156243801075, 0.4592390947570862, 0.45721194093414663, 0.45322415727794085, 0.45743558820257274, 0.4581160107252067, 0.46653988243947364, 0.44886220095300655, 0.46211291079524686, 0.44882554007694886, 0.4585688172203006, 0.4575794961313276, 0.4500439353393938, 0.45941087796244917, 0.4572695507243504, 0.4521617834477038, 0.448215445498904, 0.447091378837127, 0.4491498663683038, 0.46365886015952124, 0.460696941277535, 0.4649930059505163, 0.4590413013282594, 0.4603749351311989, 0.4591266031490783, 0.46180544327113054, 0.46047452919149484, 0.4545790752961069, 0.46230904778272847, 0.4641671495293602, 0.455119324524003, 0.45115949133648825, 0.44747482269302646, 0.456943108930312, 0.46565030553435544, 0.46258503376384974, 0.4516820926966132, 0.4571780737865954, 0.4484049920941271, 0.4633628882255814, 0.4492982798495142, 0.46037004172750035, 0.45142500412292547, 0.4643219546945318, 0.45872869785237347, 0.449694458319881, 0.45316150883728146, 0.45229767020398637, 0.44702095693180494, 0.45634258505093356, 0.4595312932690533, 0.4635177526918468, 0.4601001574164342, 0.4651924015304377, 0.4620219180487368, 0.4653954442215631, 0.4587645345744663, 0.45962685018693555, 0.457610874382636, 0.45484173350548546, 0.4569996822070448, 0.44946585457136373, 0.46050041532667724, 0.4647650455011998, 0.4596759616384166, 0.4631337910403868, 0.45208235389849116, 0.44937213006511717, 0.45331510930507496, 0.45877840998421915, 0.4578707457541087, 0.4643886600696441, 0.46431643454092547, 0.4586594817505916, 0.46225332025119176, 0.45742725674222207, 0.46210121488740685, 0.46166229397805153, 0.4496243683682336, 0.45183359747026364, 0.45616420547774034, 0.4614367170659916, 0.4496608197143448, 0.45413678384448214, 0.4581818663788382, 0.44953023377780593, 0.4472552022363288, 0.4488262031375487, 0.45061079772238816, 0.46039716045629, 0.4535786301280441, 0.44902736934682724, 0.46038819096393857, 0.4533534510860586, 0.46035569066408455, 0.4647789297230909, 0.4664309465802181, 0.44730077173012234, 0.4580741626175864, 0.4653390125247592, 0.44721474718075777, 0.4594868765039651, 0.45553969185285864, 0.4475623227660858, 0.46643919716717097, 0.4655234495264243, 0.46353651527470363, 0.4591493390669378, 0.4595191499048501, 0.44767744689034245, 0.45521073893392017, 0.4497553112531021, 0.44719439126608485, 0.46046915613246986, 0.44914532563326415, 0.4528875489957112, 0.46087630984570105, 0.4658919932228399, 0.4531037710910691, 0.46284827527020056, 0.44785470968366353, 0.4516063040065578, 0.4614618434399913, 0.4567271816220165, 0.45198544298920945, 0.45831396201975827, 0.4532003331063269, 0.4507616394628402, 0.44743944252991696, 0.4482166132361406, 0.457007742632083, 0.45695309122104477, 0.46658434355106404, 0.45597458016854553, 0.45314434858352054, 0.44932550112235303, 0.45468381024432636, 0.45133084815681884, 0.45671684148332553, 0.4493127338919716, 0.463467560484078, 0.4584733129432861, 0.45925071604592316, 0.4597155583224095, 0.4497867362169148, 0.45510025905411455, 0.4659610191741379, 0.4527219288435711, 0.4643841599414032, 0.4557027284344407, 0.46641172170823797, 0.4540420853523137, 0.4558323425422996, 0.452879471661764, 0.4521407070454958, 0.45521252929539824, 0.45492331827202537, 0.45047517944630294, 0.45796064742926446, 0.4491231843503952, 0.4611654219951099, 0.4650753134634772, 0.46198188019670416, 0.4504785672783893, 0.4502191440092435, 0.45438370688584473, 0.4604323993766557, 0.45093791218759544, 0.4514599584313148, 0.4534809266337525, 0.46080851285339364, 0.4653211073283914, 0.4610941624945408, 0.44710824810777083, 0.4581139998822057, 0.450951265498385, 0.45118368872033604, 0.4565513178754599, 0.4640789007124286, 0.4643358399135261, 0.45339452975040684, 0.4593682480993343, 0.46052198636003705, 0.44927116098494224, 0.45434258203542643, 0.45041246968973114, 0.4553190322863029, 0.44863996581251436, 0.45701869902532316, 0.46492436003551446, 0.46057502480405377, 0.4541191350568339, 0.46402528895549217, 0.4583755861494557, 0.4463513464234246, 0.45834114288010114, 0.447217983928476, 0.4608720625617404, 0.4472256838781287, 0.4640594602375921, 0.4496030529419933, 0.4582763212004203, 0.4596059609989956, 0.44834021242947975, 0.4538302864867194, 0.45966846150918067, 0.45623002299491855, 0.45535407106238773, 0.4588082808078879, 0.4608357388213179, 0.4565417459579788, 0.45652750881643855, 0.4628665581247815, 0.4481040484694613, 0.4503931312325753, 0.45010018230873006, 0.4587604815721355, 0.4617776780011588, 0.4493891330001067, 0.45946496575844586, 0.45718578931636294, 0.46226116553922814, 0.4615304012312201, 0.45333538087552105, 0.46055925319197427, 0.44826977939757257, 0.4484218033856443, 0.46205027333012966, 0.45513117528689623, 0.4647523623305059, 0.4553379097470934, 0.447095591106928, 0.4649606368867538, 0.4543333424825119, 0.4525666333941837, 0.462104778863761, 0.4525381887547414, 0.4567836486054929, 0.4666276461371849, 0.44671163076780673, 0.45261409514154904, 0.4554577098313398, 0.46536877989174896, 0.45599133787712076, 0.45497673071946787, 0.4493088765951505, 0.46626053536216716, 0.4619575372230973, 0.4611320098373701, 0.45113750689485366, 0.46618746775598113, 0.4478829748539757, 0.4651721406762966, 0.4633141517506982, 0.4603718317525638, 0.4588730548894494, 0.45618817794935074, 0.4653536971956943, 0.46621621958700504, 0.4494159449558142, 0.45648709281672234, 0.4660494751449127, 0.45728826656724164, 0.46155925204108617, 0.452513602886096, 0.4622073560911063, 0.45610260207146264, 0.46007742179130506, 0.452845449053117, 0.4512272123868488, 0.4624770875944213, 0.4496715278049399, 0.46318930292948646, 0.4625981532347831, 0.45170420916798054, 0.4581951583403212, 0.4545610400849638, 0.46022406942731847, 0.44756107473059037, 0.4630836772784893, 0.4588065113562169, 0.44821676337990723, 0.4585511425387016, 0.46083626663404453, 0.4522322035684196, 0.4515555296034427, 0.4476686904544862, 0.46302058295263887, 0.4642922603947941, 0.44818481421433937, 0.4638022813070031, 0.45849132193055264, 0.4529274758513899, 0.45525258040120575, 0.45695346594441344, 0.46029021009670607, 0.45394960338206547, 0.46345005805552486, 0.4540805726164259, 0.45043531661326375, 0.46275911876402437, 0.44974117837330296, 0.45975600717494414, 0.4595499242074436, 0.45977158016759645, 0.4639782719581884, 0.4582925926966651, 0.46073057843117526, 0.4645787911552048, 0.4642277185353183, 0.46392081348927794, 0.4609175300380956, 0.4561210540740449, 0.4477721287210753, 0.4628669564856412, 0.45254400520420646, 0.4571739124175606, 0.4547165590716598, 0.45866902819765143, 0.45413655522583285, 0.4557947217823006, 0.45975333318890177, 0.4568541271669626, 0.45827287023864444, 0.45049636729740855, 0.45775231227408525, 0.45000082385032514, 0.454085876372656, 0.46605619372403917, 0.4631772087435517, 0.4530930131349445, 0.4525843242467962, 0.4638836185278029, 0.46521077699897706, 0.4557049491224904, 0.4621223925879844, 0.461831765618665, 0.45700396590757986, 0.4650275525953038, 0.4508644098027208, 0.4551018493486275, 0.4589905836043675, 0.44784205287004963, 0.4645612223353998, 0.4574939273774547, 0.4637303223910227, 0.45666326323051304, 0.46443110466952997, 0.45655445537509715, 0.4568579943419384, 0.4552728260609435, 0.4628473384197366, 0.4511883693364586, 0.452933353288197, 0.4622706787883289, 0.4519357053923354, 0.45251774289764457, 0.4548197438465583, 0.4570024686644879, 0.4496871744866297, 0.4598488922078673, 0.45791224676126263, 0.45563706601415616, 0.4552410895612252, 0.4496453643061794, 0.45433783999840843, 0.45141559785042695, 0.46461464144670084, 0.4542936175404344, 0.4604709456696434, 0.4597977804449088, 0.460275813591452, 0.46519527457310333, 0.45727692085164495, 0.4632538974239523, 0.4658108215273369, 0.46658979912713394, 0.45423457768676223, 0.4558171327551847, 0.4480664955229378, 0.46205393082268087, 0.46407155167130776, 0.45238108637874375, 0.4574304420955864, 0.45223413001076385, 0.46138512074315674, 0.4534628395832997, 0.4638246154815634, 0.4648000762750095, 0.46134897668838054, 0.4556713549896527, 0.45970647254305297, 0.4657261097036747, 0.45406856113735417, 0.4585737312814489, 0.45439629495721123, 0.46374800671038424, 0.45717700518029186, 0.4617341195588629, 0.461004714787376, 0.45675030455432325, 0.45992294710361353, 0.45923717799501623, 0.46503877132903887, 0.45120099351667525, 0.45801311428355174, 0.45874759386631414, 0.4580911591283541, 0.4546222918080729, 0.45496212102762124, 0.4518124279384296, 0.45364408593000044, 0.46260190835237647, 0.4501577245435201, 0.458802565129626, 0.4481639767701038, 0.45257466642410843, 0.44842422798263937, 0.4620976062238828, 0.462137109662218, 0.45677829732354314, 0.4648521756964423, 0.45391391934119774, 0.4572933754143758, 0.4617245659220263, 0.4508607169084044, 0.44695891093535967, 0.4658688598649688, 0.44893803179892183, 0.45093930605239213, 0.46541653931826593, 0.46653458458179925, 0.44978930139554707, 0.45216158436920967, 0.4507057902203444, 0.45582358503470155, 0.4473531133799215, 0.4504854640591023, 0.4477617252239237, 0.4511802898603464, 0.462146937694692, 0.45053439277618884, 0.45888124100689454, 0.45956079501181396, 0.4568156180558199, 0.45090179434523336, 0.4571559259000021, 0.4555388134140936, 0.4632065209111393, 0.46486910389153735, 0.4652729260250443, 0.45686592474054816, 0.45647983318044605, 0.44881284155237383, 0.45449536434090243, 0.46296346776633746, 0.4539095800527247, 0.44800240793404017, 0.4572381148369854, 0.45955695963367915, 0.45299016804494774, 0.4610021470821781, 0.46185044275551507, 0.46331619859820417, 0.45670899485230115, 0.46265405142827115, 0.45580234760549504, 0.4659603640071355, 0.4531026914843478, 0.45980534314091226, 0.4467259801597091, 0.45523617420840135, 0.45650914755719363, 0.46031635059538334, 0.4610700796829237, 0.4619146680731119, 0.4548651527858899, 0.46399910836502056, 0.4575267083361115, 0.44728614329446603, 0.45801245797425827, 0.4592529763667225, 0.45270602575651214, 0.4657965837618934, 0.46326950980162535, 0.4631125438469007, 0.46528833473451614, 0.4608620847889826, 0.4477884544276314, 0.4494335400563302, 0.4591125960987823, 0.45747093996278754, 0.4491689950124875, 0.46543700311871017, 0.46218827657611555, 0.4626920853011677, 0.46485589648522474, 0.4615425082889423, 0.45163429055966287, 0.46581309976475915, 0.45159211285657175, 0.4606228288161136, 0.45511336504059896, 0.4565390223372228, 0.4499265220497797, 0.45138442598682865, 0.4592684927051638, 0.45982031975718796, 0.45560549864152416, 0.4568082663882415, 0.4523771657859351, 0.4512628261710855, 0.4534428607382919, 0.44784147674530383, 0.4478803579417854, 0.4499182322427264, 0.4601556661790819, 0.4572400456115361, 0.4618222072877578, 0.4646915573185162, 0.46523842626555634, 0.4542436374462224, 0.44784940228469683, 0.45190024716955496, 0.46051240634370627, 0.45074399369448526, 0.45474078395074335, 0.46611716503123424, 0.4500555774414714, 0.45558973875565656, 0.45813035745995695, 0.4654416567501312, 0.4491609784632078, 0.45156448524440684, 0.46102175237069676, 0.462212449761766, 0.4548214349362015, 0.4656883182984567, 0.4645802453561881, 0.4619709317258737, 0.4581656433681669, 0.45418146113478086, 0.45300046450984877, 0.46324873748296186, 0.4599704528483556, 0.4615882682699882, 0.46096051933526094, 0.46514661488105347, 0.46371029116526236, 0.4656608083487741, 0.45595914885788186, 0.44955930822607004, 0.4590060068510867, 0.4643493616091582, 0.4631007034290681, 0.4473572027886353, 0.4619676438434758, 0.4581899563255415, 0.4484899204454328, 0.46421872863274877, 0.4609934346199115, 0.4585192984110007, 0.44820920254156804, 0.45961742620806156, 0.44911520303762537, 0.4542008692118535, 0.4589495282608544, 0.4486691888917702, 0.4596977706248384, 0.4649969541674987, 0.4487127373442785, 0.4597464028925353, 0.4659700808391299, 0.45991460018245206, 0.44882258755489235, 0.4543688163717391, 0.4593998022211922, 0.45970535880232644, 0.4478561247458883, 0.44829435743011237, 0.45201610624639244, 0.4632525670074821, 0.4547487763719896, 0.4660214660945229, 0.45975239949765356, 0.4602290687816726, 0.458709863819306, 0.4609885701615754, 0.46424417070694596, 0.46335589536803407, 0.4555313948834877, 0.4524648528416304, 0.4626605531887124, 0.4484303368469092, 0.4549433074010834, 0.4644106621749319, 0.4626648479837742, 0.4641838966649647, 0.46579040191310395, 0.4646486962954184, 0.4586671840648207, 0.45255370229959146, 0.44762263794113766, 0.4532656682547054, 0.44783576164209377, 0.45877352207276617, 0.36216613932623887, 0.3459732980383027, 0.361933201027407, 0.36004073009379206, 0.3628718936226427, 0.3577906305455092, 0.3495214225529617, 0.3609799742139687, 0.3530173630958726, 0.34759882632044836]\n",
      "Episode is now: 2\n",
      "n_events_in_last_interval_left = 997\n",
      "n_events_in_last_interval_right = 227\n",
      "ast chosen = left\n",
      "..... episode_number = 2\n",
      "..... steps_per_episode = 1\n",
      "episode_number = [1, 2]\n",
      "steps_per_episode = [10, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38bd6a1e10> <matplotlib.colors.Normalize object at 0x7f38bd778f50>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38bd6a2fd0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 231\n",
      "ast chosen = left\n",
      "..... episode_number = 2\n",
      "..... steps_per_episode = 2\n",
      "episode_number = [1, 2]\n",
      "steps_per_episode = [10, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38be18b7d0> <matplotlib.colors.Normalize object at 0x7f38bd6a1e10>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38640de310>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1003\n",
      "n_events_in_last_interval_right = 231\n",
      "ast chosen = left\n",
      "..... episode_number = 2\n",
      "..... steps_per_episode = 3\n",
      "episode_number = [1, 2]\n",
      "steps_per_episode = [10, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38be0c7590> <matplotlib.colors.Normalize object at 0x7f38be18b7d0>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38bd315710>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1001\n",
      "n_events_in_last_interval_right = 229\n",
      "ast chosen = left\n",
      "..... episode_number = 2\n",
      "..... steps_per_episode = 4\n",
      "episode_number = [1, 2]\n",
      "steps_per_episode = [10, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f3864e906d0> <matplotlib.colors.Normalize object at 0x7f38be0c7590>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38bd3a3fd0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 227\n",
      "ast chosen = left\n",
      "..... episode_number = 2\n",
      "..... steps_per_episode = 5\n",
      "episode_number = [1, 2]\n",
      "steps_per_episode = [10, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f3864ee6710> <matplotlib.colors.Normalize object at 0x7f3864e906d0>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f3864e98890>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 233\n",
      "ast chosen = left\n",
      "..... episode_number = 2\n",
      "..... steps_per_episode = 6\n",
      "episode_number = [1, 2]\n",
      "steps_per_episode = [10, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:colorbar update normal <matplotlib.colors.Normalize object at 0x7f38bd575310> <matplotlib.colors.Normalize object at 0x7f3864ee6710>\n",
      "DEBUG:locator: <matplotlib.ticker.AutoLocator object at 0x7f38bd9b22d0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events_in_last_interval_left = 1000\n",
      "n_events_in_last_interval_right = 231\n",
      "ast chosen = left\n",
      "..... episode_number = 2\n",
      "..... steps_per_episode = 7\n",
      "episode_number = [1, 2]\n",
      "steps_per_episode = [10, 7]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFile.py:518\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[1;32m    519\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..... steps_per_episode = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(steps_per_episode))\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plot_spikes:\u001b[38;5;66;03m# and (steps_per_episode % 10 == 0):\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m         \u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m#plot_spikes = False\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m#     if a.get_state_neuron((p.x, p.w, p.v, p.dw)) == -1:\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mget_state_neuron(p\u001b[38;5;241m.\u001b[39mget_state()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# failure state\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m#TD = -a.Q_new\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [7], line 104\u001b[0m, in \u001b[0;36mSpiking_PlotRenderer.update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime [ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp/cartpole.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mflush_events()\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlifetime_fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/figure.py:3395\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3393\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3394\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[0;32m-> 3395\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/backends/backend_qtagg.py:75\u001b[0m, in \u001b[0;36mFigureCanvasQTAgg.print_figure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_figure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# In some cases, Qt will itself trigger a paint event after closing the file\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# save dialog. When that happens, we need to be sure that the internal canvas is\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# re-drawn. However, if the user is using an automatically-chosen Qt backend but\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# saving with a different backend (such as pgf), we do not want to trigger a\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# full draw in Qt, so just set the flag for next time.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/backend_bases.py:2204\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2201\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2204\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2207\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2208\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2052\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2053\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2054\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:496\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    444\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 445\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/image.py:1676\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1675\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1676\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:2431\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2428\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2431\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/PngImagePlugin.py:1420\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1418\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1420\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFile.py:522\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    520\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 522\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    524\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFile.py:541\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 541\u001b[0m         l, s, d \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(d)\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFile.py\u001b[0m(541)\u001b[0;36m_encode_tile\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    539 \u001b[0;31m                    \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    540 \u001b[0;31m                    \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 541 \u001b[0;31m                        \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    542 \u001b[0;31m                        \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    543 \u001b[0;31m                        \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%pdb\n",
    "import sys\n",
    "\n",
    "r = Renderer(1200, 800, 600, 500, 400)\n",
    "clock = pg.time.Clock()\n",
    "running = True\n",
    "\n",
    "action_taken_times = []\n",
    "action_taken = []\n",
    "\n",
    "p = Physics(0, (np.random.rand() - 1) / 10)\n",
    "\n",
    "a = SpikingAgent(p.get_state(), 0.98)\n",
    "\n",
    "plot = Spiking_PlotRenderer()\n",
    "\n",
    "steps_per_episode = 0\n",
    "\n",
    "window_size = 30\n",
    "window = np.zeros(30)\n",
    "avg_lifetime = 20000\n",
    "\n",
    "toggle_sim = True\n",
    "plot_spikes = True\n",
    "stepping_sim = False\n",
    "while running:\n",
    "    steps_per_episode += 1\n",
    "    force = 0\n",
    "    mouse_x = None\n",
    "   \n",
    "#     if steps_per_episode > 11:\n",
    "#         break\n",
    "\n",
    "    # poll for events\n",
    "    for event in pg.event.get():\n",
    "        if event.type == pg.QUIT:\n",
    "            running = False\n",
    "            pg.quit()\n",
    "            sys.exit()\n",
    "            quit()\n",
    "        elif event.type == pg.MOUSEBUTTONDOWN:\n",
    "            mouse_x = r.get_relative_mouse_x(pg.mouse.get_pos()[0])\n",
    "        elif event.type == pg.KEYDOWN:\n",
    "            #controls if simulation should be shown or not\n",
    "            toggle_sim ^= pg.key.get_pressed()[pg.K_1]\n",
    "            #on button press plots the current spikes\n",
    "            plot_spikes ^= pg.key.get_pressed()[pg.K_2]\n",
    "            #on button press stores the network in ./saved_networks/network.json\n",
    "            if pg.key.get_pressed()[pg.K_3]:\n",
    "                a.save_network()\n",
    "            #toggles step-by-step simulation, updating now by pressing space\n",
    "            stepping_sim ^= pg.key.get_pressed()[pg.K_4]\n",
    "\n",
    "    if stepping_sim:\n",
    "        toggle_sim = True\n",
    "        plot_spikes = True\n",
    "        next_step = False\n",
    "        while not next_step and stepping_sim:\n",
    "            pg.event.wait()\n",
    "            stepping_sim ^= pg.key.get_pressed()[pg.K_4]\n",
    "            next_step ^= pg.key.get_pressed()[pg.K_SPACE]\n",
    "\n",
    "    # Simulate SNN, choose action, simulate physics, receive state\n",
    "    # Since SNN takes 40ms, it reacts only to every 2nd physics step\n",
    "    global action\n",
    "    action, plot_data = a.update(p.get_state())\n",
    "    assert action != AgentAction.FAILURE\n",
    "\n",
    "    action_taken_times.append(nest.biological_time)\n",
    "    action_taken.append(action)\n",
    "    plot_data[\"action_taken_times\"] = action_taken_times\n",
    "    plot_data[\"action_taken\"] = action_taken\n",
    "    \n",
    "#     if action == AgentAction.FAILURE:\n",
    "#         p.reset()\n",
    "#         a.failure_reset(SpikingAgent.cycle_period)\n",
    "#         window = np.roll(window, 1)\n",
    "#         window[0] = steps_per_episode\n",
    "#         steps_per_episode = 0\n",
    "    if action == AgentAction.RIGHT:\n",
    "        force = 10\n",
    "    elif action == AgentAction.LEFT:\n",
    "        force = -10\n",
    "    else:\n",
    "        assert False, \"Unknown action returned\"\n",
    "    \n",
    "    theta, x = p.update(force, mouse_x)\n",
    " \n",
    "    plot_data[\"episode_number\"] = a.episode\n",
    "    plot_data[\"steps_per_episode\"] = steps_per_episode\n",
    "    \n",
    "    print(\"..... episode_number = \" + str(a.episode))\n",
    "    print(\"..... steps_per_episode = \" + str(steps_per_episode))\n",
    "    \n",
    "    if plot_spikes:# and (steps_per_episode % 10 == 0):\n",
    "        plot.update(plot_data)\n",
    "        #plot_spikes = False\n",
    "    \n",
    "#     if a.get_state_neuron((p.x, p.w, p.v, p.dw)) == -1:\n",
    "    if a.get_state_neuron(p.get_state()) == -1:\n",
    "        # failure state\n",
    "        #TD = -a.Q_new\n",
    "        print(\"Failure in main loop!\")\n",
    "        a.failure_reset()\n",
    "        p.reset()\n",
    "        print(\"Episode is now: \" + str(a.episode))\n",
    "        steps_per_episode = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        a.save_prev_syn_wtr()\n",
    "    \n",
    "\n",
    "    #\n",
    "    #    reset synaptic state\n",
    "    #\n",
    "    \n",
    "    syn_to_left = nest.GetConnections(source=a.input_population, target=a.output_population_left)\n",
    "    syn_to_right = nest.GetConnections(source=a.input_population, target=a.output_population_right)\n",
    "    for _syn in [syn_to_left, syn_to_right]:\n",
    "        _syn.wtr = 0.\n",
    "        _syn.pre_trace = 0.\n",
    "        #_syn.post_trace = 0. # need to do this in postsyn. neuron partner...\n",
    "    \n",
    "    a.output_population_left.post_trace__for_neuromodulated_stdp_synapse_nestml = 0.\n",
    "    a.output_population_right.post_trace__for_neuromodulated_stdp_synapse_nestml = 0.\n",
    "    \n",
    "    \n",
    "    #\n",
    "    #    render\n",
    "    #\n",
    "    \n",
    "    if np.mean(window) >= avg_lifetime or toggle_sim:\n",
    "        r.draw_clear()\n",
    "        r.draw_ground(0.2, \"grey\")\n",
    "        r.draw_car(x)\n",
    "        r.draw_pole(x, theta, 2*p.l, 0.02)\n",
    "        r.draw_stats(theta*180/np.pi, p.w*180/np.pi, x, p.v, a.get_episode(),\n",
    "                     a.output_population_spike_recorder_left.n_events, \n",
    "                     a.output_population_spike_recorder_right.n_events,\n",
    "                     a.dopamine_left,\n",
    "                     a.dopamine_right,\n",
    "                     action)\n",
    "        r.display()\n",
    "\n",
    "        clock.tick(50)  # limits FPS to 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4d920",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "[1] Liu Y, Pan W. Spiking Neural-Networks-Based Data-Driven Control. Electronics. 2023; 12(2):310. https://doi.org/10.3390/electronics12020310 \n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "The authors would like to thank Prof. Wei Pan and Dr. Yuxiang Liu for kindly providing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f41ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe34154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74df54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
