{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f763ff4e",
   "metadata": {},
   "source": [
    "# Polebalancing using NESTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c21179",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to build an agent that can successfully solve the classic pole balancing problem using reinforcement learning. We will start with a standard temporal difference learning approach and after that, use NESTML to set up a spiking neural network to perform this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885d90c",
   "metadata": {},
   "source": [
    "# Cart Pole Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c0bfe",
   "metadata": {},
   "source": [
    "For the cart pole environment, we mostly need three things:  \n",
    "    - A renderer to display the simulation  \n",
    "    - The physics system and  \n",
    "    - An input to be able to nudge the pole in both directions  \n",
    "\n",
    "For that, we will need the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame as pg\n",
    "from typing import Tuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283c79f",
   "metadata": {},
   "source": [
    "Let's start with the renderer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af3680-b849-48bb-a653-642b580a01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renders the scene. IMPORTANT: Because ipycanvas uses the html canvas coordinates, the y-axis is inverted.\n",
    "class Renderer():\n",
    "    def __init__(self, width: int, height: int, origin_x: int = 0, origin_y: int = 0, SCALE: int = 1) -> None:\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.origin = (origin_x, origin_y)\n",
    "        self.SCALE = SCALE #1m = SCALE pixels\n",
    "\n",
    "        pg.display.init()\n",
    "        pg.display.set_caption(\"Pole Balancing Simulator\")\n",
    "        pg.font.init()\n",
    "        self.screen = pg.display.set_mode((width, height))\n",
    "    \n",
    "    #Translates global coordinates into screen coordinates\n",
    "    def translate(self, x: int, y: int) -> Tuple[int, int]:\n",
    "        return (x+self.origin[0], -y+self.origin[1])\n",
    "    \n",
    "    #Draws ground. offset is there to shift the ground below the car\n",
    "    def draw_ground(self, offset: int, color) -> None:\n",
    "        ground = pg.Rect(self.translate(-self.width//2, -offset * self.SCALE), (self.width, self.height-self.origin[1]-offset * self.SCALE))\n",
    "        pg.draw.rect(self.screen, color, ground)\n",
    "\n",
    "    #Draws car. pos_y is omitted because the car's center should be at y = 0\n",
    "    def draw_car(self, pos_x: float, car_color = \"blue\", wheel_color = \"black\") -> None:\n",
    "        pos_x *= self.SCALE\n",
    "        #values, hard-coded for now, in meters\n",
    "        width = 0.5 * self.SCALE\n",
    "        height = 0.25 * self.SCALE\n",
    "        wheel_radius = 0.1 * self.SCALE\n",
    "\n",
    "        car_body = pg.Rect(self.translate(pos_x - width/2, height/2), (width, height))\n",
    "        pg.draw.rect(self.screen, car_color, car_body)\n",
    "        pg.draw.circle(self.screen, wheel_color, \n",
    "                           self.translate(pos_x - width/2 + wheel_radius, -height/2), wheel_radius)\n",
    "        pg.draw.circle(self.screen, wheel_color, \n",
    "                           self.translate(pos_x + width/2 - wheel_radius, -height/2), wheel_radius)\n",
    "\n",
    "    #Draws the pole\n",
    "    def draw_pole(self, pos_x: float, theta: float, length: float, width: float = 0.1, color = \"red\") -> None:\n",
    "        pos_x *= self.SCALE\n",
    "        width = int(width * self.SCALE)\n",
    "        pole_end_x = length * np.sin(theta) * self.SCALE + pos_x\n",
    "        pole_end_y = length * np.cos(theta) * self.SCALE\n",
    "        pg.draw.line(self.screen, color, self.translate(pos_x, 0), self.translate(pole_end_x, pole_end_y), width)\n",
    "\n",
    "    #Clears the entire canvas\n",
    "    def draw_clear(self) -> None:\n",
    "        self.screen.fill(\"white\")\n",
    "\n",
    "    #Draws physical values\n",
    "    def draw_stats(self, theta: float, dw: float, a: float, x: float, episode: int) -> None:\n",
    "        font = pg.font.Font(None, 24)\n",
    "        text = font.render(str(theta)[:4] + \" | \" + str(dw)[:4] + \" | \" + str(x)[:4] + \" | \" + str(a)[:4] + \" | episode: \" + str(episode), True, (10,10,10))\n",
    "        textpos = text.get_rect(centerx=self.screen.get_width() / 2, y=10)\n",
    "        self.screen.blit(text, textpos)\n",
    "\n",
    "    #Get the \n",
    "    def get_relative_mouse_x(self, mouse_x:float) -> float:\n",
    "        return (mouse_x-self.origin[0])/self.SCALE\n",
    "    \n",
    "    def display(self) -> None:\n",
    "        pg.display.flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6362d90",
   "metadata": {},
   "source": [
    "## Physics Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74907eaf",
   "metadata": {},
   "source": [
    "For the physics, we use the corrected version of of the original problem derived from V. Florian (CITATION NEEDED), but omit the friction forces.\n",
    "The situation is sketched here:  \n",
    "\n",
    "![alt text](cartpole_illustration.png \"Cartpole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c94e0",
   "metadata": {},
   "source": [
    "We apply Newton's second law of motion to the cart:  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbf{F} + \\mathbf{G}_c - \\mathbf{N} = m_c \\cdot \\mathbf{a}_c\n",
    "\\end{aligned}\n",
    "$$\n",
    "Where:  \n",
    "\n",
    "$\\mathbf{F} = F \\cdot \\mathbf{u_x}$ is the control force acting on the cart,  \n",
    "$\\mathbf{G}_c = m_c \\cdot g \\cdot \\mathbf{u}_y$ is the gravitational component acting on the cart,  \n",
    "$\\mathbf{N} = N_x \\cdot \\mathbf{u}_x - N_y \\cdot \\mathbf{u}_y$ is the negative reaction force that the pole is applying on the cart,  \n",
    "$\\mathbf{a}_c = \\ddot{x} \\cdot \\mathbf{u}_x$ is the accelaration of the cart,  \n",
    "$m_c$ is the cart's mass and  \n",
    "$\\mathbf{u}_x$, $\\mathbf{u}_y$, $\\mathbf{u}_z$ are the unit vectors of the frame of reference given in the illustration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2e429",
   "metadata": {},
   "source": [
    "We can decompose this equation now into the $x$ and $y$ component:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    F - N_x = m_c \\cdot \\ddot{x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    m_c \\cdot g + N_y = 0\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62acf48",
   "metadata": {},
   "source": [
    "Newton's second law of motion applied to the pole gives us:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbf{N} + \\mathbf{G}_p = m_p \\cdot \\mathbf{a}_p\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where $\\mathbf{G}_p = m_p \\cdot g \\cdot \\mathbf{u}_y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38770100",
   "metadata": {},
   "source": [
    "The accelaration $\\mathbf{a}_p$ of the pole's center of mass consists of three components, where $\\mathbf{r}_p = l \\cdot (\\sin{\\theta}\\cdot \\mathbf{u}_x-\\cos{\\theta}\\cdot \\mathbf{u}_y)$ denotes the vector pointing to the pole's center of mass relative to it's rotation center:  \n",
    "1. The accelaration of the cart it is attached to $\\mathbf{a}_c$,\n",
    "2. The pole's angular accelaration $\\mathbf{\\epsilon} = \\ddot{\\theta} \\cdot \\mathbf{u}_z$, which is translated into accelaration by $\\mathbf{\\epsilon} \\times \\mathbf{r}_p$.\n",
    "3. The pole's angular velocity $\\mathbf{\\omega} = \\dot{\\theta} \\cdot \\mathbf{u}_z$, for which the accelaration can be derived by  $\\mathbf{\\omega} \\times (\\mathbf{\\omega} \\times \\mathbf{r}_p)$.\n",
    "\n",
    "Thus we obtain:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbf{a}_p  = \\mathbf{a}_c + \\mathbf{\\epsilon} \\times \\mathbf{r}_p + \\mathbf{\\omega} \\times (\\mathbf{\\omega} \\times \\mathbf{r}_p)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Substituting $\\mathbf{r}_p = l \\cdot (\\sin{\\theta}\\cdot \\mathbf{u}_x-\\cos{\\theta}\\cdot \\mathbf{u}_y)$ and $\\mathbf{a}_p = \\ddot{x} \\cdot \\mathbf{u}_x$ as well as $\\mathbf{u}_z \\times \\mathbf{u}_x = \\mathbf{u}_y$ and $\\mathbf{u}_z \\times \\mathbf{u}_y = -\\mathbf{u}_x$:\n",
    "\\begin{aligned}\n",
    "    \\mathbf{a}_p  = \\ddot{x} \\cdot \\mathbf{u}_x + l \\cdot \\ddot{\\theta} \\cdot (\\sin{\\theta}\\cdot \\mathbf{u}_y + \\cos{\\theta}\\cdot \\mathbf{u}_x) - l \\cdot \\dot{\\theta}^2 \\cdot (\\sin{\\theta}\\cdot \\mathbf{u}_x - \\cos{\\theta}\\cdot \\mathbf{u}_y)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895254eb",
   "metadata": {},
   "source": [
    "Inserting this quation into our equation for the forces of the pole and decomposing on the $x$ and $y$ axis we obtain:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    N_x = m_p \\cdot (\\ddot{x} + l \\cdot \\ddot{\\theta} \\cdot \\cos{\\theta} - l \\cdot \\dot{\\theta}^2 \\cdot \\sin{\\theta})\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    m_p \\cdot g - N_y = m_p \\cdot (l \\cdot \\ddot{\\theta} \\cdot \\sin{\\theta} + l \\cdot \\dot{\\theta}^2 \\cdot \\cos{\\theta})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c6dd1",
   "metadata": {},
   "source": [
    "# TODO: FINISH EQUATION DERIVATION (SOLVE EQUATION REFERENCING?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Physics():\n",
    "    \n",
    "    def __init__(self, x, theta, v = 0, a = 0, w = 0, dw = 0, g = 9.81, m_c = 1, m_p = 0.1, l = 0.5, dt = 0.02) -> None:\n",
    "        self.__dict__.update(vars())\n",
    "\n",
    "    def dw_step(self, cart_force, nudge_force) -> float:\n",
    "        numerator = self.g * np.sin(self.theta) + np.cos(self.theta) * (-cart_force - self.m_p * self.l * self.w**2 * np.sin(self.theta))/(self.m_c+self.m_p) + nudge_force * np.cos(self.theta)/(self.m_p*self.l)\n",
    "        denominator = self.l * (4/3 - (self.m_p*np.cos(self.theta)**2)/(self.m_c+self.m_p))\n",
    "\n",
    "        self.dw = numerator/denominator\n",
    "        self.w += self.dt * self.dw\n",
    "        self.theta += self.dt * self.w\n",
    "\n",
    "        return self.theta\n",
    "    \n",
    "    def a_step(self, force) -> float:\n",
    "        numerator = force + self.m_p * self.l * (self.w**2 * np.sin(self.theta) - self.dw * np.cos(self.theta))\n",
    "        denominator = self.m_c + self.m_p\n",
    "\n",
    "        self.a = numerator/denominator\n",
    "        self.v += self.dt * self.a\n",
    "        self.x += self.dt * self.v\n",
    "\n",
    "        return self.x\n",
    "\n",
    "    def update(self, force, mouse_x) -> Tuple[float, float]:\n",
    "        nudge_force = 0\n",
    "        if mouse_x is not None:\n",
    "            nudge_force = -1 if mouse_x > self.x else 1\n",
    "        return (self.dw_step(force, nudge_force), self.a_step(force))\n",
    "    \n",
    "    #get state of the system that agent can see\n",
    "    def get_state(self) -> Tuple[float,float,float,float]:\n",
    "        return (self.x, self.theta, self.v, self.w)\n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        self.x = 0\n",
    "        self.theta = (np.random.rand() - 1) / 10\n",
    "        self.v = 0\n",
    "        self.a = 0\n",
    "        self.w = 0\n",
    "        self.dw = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76793d12",
   "metadata": {},
   "source": [
    "# The Agent (BOXES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent():\n",
    "    def __init__(self, initial_state: Tuple[float,float,float,float], learning_rate, learning_decay, epsilon, epsilon_decay, discount_factor) -> None:\n",
    "\n",
    "        #learning paramters\n",
    "        self.learning_rate = learning_rate\n",
    "        self. learning_decay = learning_decay\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "        #thresholds for discretizing the state space\n",
    "        self.x_thresholds = np.array([-2.4, -0.8, 0.8, 2.4])\n",
    "        self.theta_thresholds = np.array([-12, -6, -1, 0, 1, 6, 12])\n",
    "        self.theta_thresholds = self.theta_thresholds /180 * np.pi\n",
    "        self.v_thresholds = np.array([float(\"-inf\"), -0.5, 0.5, float(\"+inf\")]) #open intervals ignored here\n",
    "        self.w_thresholds = np.array([float(\"-inf\"), -50, 50, float(\"+inf\")]) #open intervals ignored here\n",
    "        self.w_thresholds = self.w_thresholds /180 * np.pi\n",
    "\n",
    "        self.boxes = np.random.rand(len(self.x_thresholds), \n",
    "                                    len(self.theta_thresholds), \n",
    "                                    len(self.v_thresholds), \n",
    "                                    len(self.w_thresholds), \n",
    "                                    2)\n",
    "        box = self.get_box(initial_state)\n",
    "        self.current_box = self.boxes[box[0], box[1], box[2], box[3], :]\n",
    "\n",
    "        self.episode = 1\n",
    "\n",
    "    #returns 0 if the action is \"left\", else \"1\"\n",
    "    def choose_action(self) -> int:\n",
    "        self.action = np.random.choice([np.argmax(self.current_box), np.argmin(self.current_box)], p=[1-self.epsilon, self.epsilon])\n",
    "        return self.action\n",
    "    \n",
    "    def discretize(self, value, thresholds):\n",
    "        for i, limit in enumerate(thresholds):\n",
    "            if value < limit:\n",
    "                return i - 1\n",
    "        return -1\n",
    "\n",
    "    def get_box(self, state: Tuple[float,float,float,float]) -> Tuple[int,int,int,int]:\n",
    "        return (self.discretize(state[0], self.x_thresholds),\n",
    "                 self.discretize(state[1], self.theta_thresholds),\n",
    "                 self.discretize(state[2], self.v_thresholds), \n",
    "                 self.discretize(state[3], self.w_thresholds))\n",
    "    \n",
    "    def get_episode(self) -> int:\n",
    "        return self.episode\n",
    "    \n",
    "    #returns 0 if no failure occured, else 1\n",
    "    #reward is -1 on failure and 0 else\n",
    "    def update(self, next_state: Tuple[float,float,float,float]) -> int:\n",
    "        box = self.get_box(next_state)\n",
    "        if -1 in box:\n",
    "            self.current_box[self.action] += self.learning_rate * -1\n",
    "            return 1\n",
    "        \n",
    "        next_box = self.boxes[box[0], box[1], box[2], box[3], :]\n",
    "        next_q = np.max(next_box)\n",
    "        self.current_box[self.action] += self.learning_rate * (self.discount_factor * (next_q - self.current_box[self.action]))\n",
    "\n",
    "        self.current_box = next_box\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.learning_rate *= self.learning_decay\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    def failure_reset(self, state: Tuple[float,float,float,float]):\n",
    "        box = self.get_box(state)\n",
    "        self.current_box = self.boxes[box[0], box[1], box[2], box[3], :]\n",
    "        self.episode += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717eda26-e385-494f-bdca-9847eefe01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r = Renderer(1200, 800, 600, 500, 400)\n",
    "clock = pg.time.Clock()\n",
    "running = True\n",
    "\n",
    "p = Physics(0, (np.random.rand() - 1) / 10)\n",
    "\n",
    "a = Agent(p.get_state(), 0.5, 0.9999, 1, 0.995, 0.99)\n",
    "\n",
    "plt.ion()  # turning interactive mode on\n",
    "# preparing the data\n",
    "y_plot = [0]\n",
    "x_plot = [0]\n",
    "\n",
    "# plotting the first frame\n",
    "graph = plt.plot(x_plot,y_plot)[0]\n",
    "plt.pause(1)\n",
    "\n",
    "steps_per_episode = 0\n",
    "max_steps = 0\n",
    "\n",
    "while running:\n",
    "    steps_per_episode += 1\n",
    "\n",
    "    force = 0\n",
    "    mouse_x = None\n",
    "\n",
    "    # poll for events\n",
    "    for event in pg.event.get():\n",
    "        if event.type == pg.QUIT:\n",
    "            running = False\n",
    "            pg.quit()\n",
    "            sys.exit()\n",
    "            quit()\n",
    "        elif event.type == pg.MOUSEBUTTONDOWN:\n",
    "            mouse_x = r.get_relative_mouse_x(pg.mouse.get_pos()[0])\n",
    "\n",
    "    # agent chooses action, simulation is uodated and reward is calculated\n",
    "    force = 10 if a.choose_action() else -10\n",
    "    theta, x = p.update(force, mouse_x)\n",
    "    failure = a.update(p.get_state())\n",
    "\n",
    "    if failure:\n",
    "        p.reset()\n",
    "        a.failure_reset(p.get_state())\n",
    "\n",
    "        if steps_per_episode > max_steps:\n",
    "            max_steps = steps_per_episode\n",
    "        y_plot.append(steps_per_episode)\n",
    "        x_plot.append(a.get_episode())\n",
    "        \n",
    "        # removing the older graph\n",
    "        graph.remove()\n",
    "        \n",
    "        # plotting newer graph\n",
    "        graph = plt.plot(x_plot,y_plot,color = 'g')[0]\n",
    "        plt.xlim(x_plot[0], x_plot[-1])\n",
    "        plt.ylim(0, max_steps)\n",
    "        # calling pause function to let it draw the graoh in between episodes\n",
    "        plt.pause(0.0001)\n",
    "\n",
    "        steps_per_episode = 0\n",
    "    \n",
    "    \n",
    "    if a.get_episode() > 1000:\n",
    "        r.draw_clear()\n",
    "        r.draw_ground(0.2, \"grey\")\n",
    "        r.draw_car(x)\n",
    "        r.draw_pole(x, theta, 2*p.l, 0.02)\n",
    "        r.draw_stats(theta*180/np.pi, p.w*180/np.pi, x, p.a, a.get_episode())\n",
    "        r.display()\n",
    "\n",
    "        clock.tick(50)  # limits FPS to 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2876351",
   "metadata": {},
   "source": [
    "# TODO: clean up code, derive equations and explain renderer briefly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
